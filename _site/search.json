[
  {
    "objectID": "posts/writing-robust-functions/index.html",
    "href": "posts/writing-robust-functions/index.html",
    "title": "Writing Robust R Functions",
    "section": "",
    "text": "Functions in R ( or any other programming language in general) allow us to encapsulate some lines of code that we want to run again and again. Functions are the natural outcome of the DRY1 principle. Functions group together a couple of lines of consistent logic making our code modular and consequently, easy to manage. However, when we write functions, we need to ensure that they behave exactly as we want them to and are able to handle whatever we throw at them. By whatever, I mean any and all kinds of inputs. The idea of creating unbreakable code is idealistic. I say this since creating robust functions requires additional code to handle the unwanted inputs and most useRs write functions during some one-time analysis. Hence we need to be pragmatic about how much time and effort we spend trying to make our functions robust. Maybe, we need our functions to be just robust enough! All I am saying is, if you are creating functions that will be used by you and only you i.e. if you have absolute control over what inputs would be provided to your functions, then you can forego certain checks and the functions need not be unbreakable. But, if you intend to write functions that will be used by a larger audience, you need to ensure that such functions are able to handle all kinds of innocent and malicious intents."
  },
  {
    "objectID": "posts/writing-robust-functions/index.html#introduction",
    "href": "posts/writing-robust-functions/index.html#introduction",
    "title": "Writing Robust R Functions",
    "section": "",
    "text": "Functions in R ( or any other programming language in general) allow us to encapsulate some lines of code that we want to run again and again. Functions are the natural outcome of the DRY1 principle. Functions group together a couple of lines of consistent logic making our code modular and consequently, easy to manage. However, when we write functions, we need to ensure that they behave exactly as we want them to and are able to handle whatever we throw at them. By whatever, I mean any and all kinds of inputs. The idea of creating unbreakable code is idealistic. I say this since creating robust functions requires additional code to handle the unwanted inputs and most useRs write functions during some one-time analysis. Hence we need to be pragmatic about how much time and effort we spend trying to make our functions robust. Maybe, we need our functions to be just robust enough! All I am saying is, if you are creating functions that will be used by you and only you i.e. if you have absolute control over what inputs would be provided to your functions, then you can forego certain checks and the functions need not be unbreakable. But, if you intend to write functions that will be used by a larger audience, you need to ensure that such functions are able to handle all kinds of innocent and malicious intents."
  },
  {
    "objectID": "posts/writing-robust-functions/index.html#what-do-we-mean-by-robust-functions",
    "href": "posts/writing-robust-functions/index.html#what-do-we-mean-by-robust-functions",
    "title": "Writing Robust R Functions",
    "section": "What do we mean by Robust Functions?",
    "text": "What do we mean by Robust Functions?\nYou must be familiar with the Garbage-In-Garbage-Out philosophy of Software engineering. We can think of it in terms of functions, that, given garbage or bad input, you get garbage or bad output. For a function to be robust, it must behave in a consistent manner for known and correct inputs, however, more importantly, it mustn’t give us garbage for bad inputs. Rather, it must provide useful output (as messages or instructions) which can be further used to inform the end-user about possible problems in the inputs to drive proper usage. The useful output/s in case of bad inputs would ideally be a combination of clean early exit and easy-to-understand error messages. So we shall try to implement Garbage-In-Useful-Info-Out by looking at some ways we can build well-behaved and reliable functions.\nInput values passed to a function are more popularly known as arguments or parameters. A robust function must validate the function arguments before proceeding to implement the function logic. If this is not done, then the bad arguments will cause some errors in the logic and display error messages that the end-user may not be familiar with. Worst-case scenario is when the function doesn’t encounter any errors and just gives bad results!! Surely, we do not want this unpredictable behavior.\n\n\n\nSource: imgflip.com"
  },
  {
    "objectID": "posts/writing-robust-functions/index.html#our-sweet-innocent-and-naive-function",
    "href": "posts/writing-robust-functions/index.html#our-sweet-innocent-and-naive-function",
    "title": "Writing Robust R Functions",
    "section": "Our sweet, innocent and naive Function",
    "text": "Our sweet, innocent and naive Function\nConsider the following function make_date that takes 3 numeric inputs yyyy, mm and dd and returns a single `Date` object.\n\nCodemake_date &lt;-  function(yyyy, mm, dd) {\n  \n  # main logic : Concatenate the values and convert to Date\n  as.Date(paste(yyyy, mm, dd, sep = \"-\"), format = \"%Y-%m-%d\")\n}\n\nmy_date &lt;- make_date(yyyy = 2022, mm = 1, dd = 31)\nmy_date\n\n[1] \"2022-01-31\"\n\nCodeclass(my_date)\n\n[1] \"Date\"\n\n\nWe will use make_date to demonstrate a couple of scenarios where this function can fail and the methods to safeguard against such scenarios."
  },
  {
    "objectID": "posts/writing-robust-functions/index.html#scenario-1-missing-arguments",
    "href": "posts/writing-robust-functions/index.html#scenario-1-missing-arguments",
    "title": "Writing Robust R Functions",
    "section": "Scenario 1: Missing Arguments",
    "text": "Scenario 1: Missing Arguments\nThe most basic check we should perform before running the function logic is to confirm if all the required arguments are available. Think about how your function should behave if one of the arguments, suppose mm is missing.\n\nCodemake_date(yyyy = 2022, dd = 31)\nError in paste(yyyy, mm, dd, sep = \"-\"): argument \"mm\" is missing, with no default\n\n\nNote that the error message shown to the user, is triggered, not from our function make_date but from the internal paste function. We do not have any control over what error messages are shown when errors occur. In this case, we know specifically that this error is due to a missing argument.\nThere are two ways to handle missing arguments:\n1.1 Early Exit\nIf a certain required argument is missing, we can stop the execution of the function and show informative error message about which argument is missing. Your friends here are the missing and stop functions. The missing function checks if the given argument is missing or is set to NULL and returns TRUE, else it returns FALSE. The stop function stops the execution and displays the custom error message we provide. Using these functions inside an if condition will let us check for missing arguments. Let us modify our naive function to stop early when required arguments are missing.\n\nCodemake_date &lt;-  function(yyyy, mm, dd) {\n  \n  # check missing arguments\n  if (missing(yyyy)) stop(\"argument `yyyy` is required.\")\n  if (missing(mm))   stop(\"argument `mm` is required.\")\n  if (missing(dd))   stop(\"argument `dd` is required.\")\n  \n  # main logic\n  as.Date(paste(yyyy, mm, dd, sep = \"-\"), format = \"%Y-%m-%d\")\n}\n\n# Calling the function without `mm` argument\nmake_date(yyyy = 2022, dd = 31)\nError in make_date(yyyy = 2022, dd = 31): argument `mm` is required.\n\n\nNote that here, we add three if-missing-stop statements, one for each required argument. We must do this if we want to display specific error messages for each argument. There is another way to do the same but we will look at it later. If we want to display a single error message, we can do so by clubbing the missing functions inside an any which will return TRUE if any one of the arguments is missing. However, providing clear error messages becomes challenging in this method.\n\nCodedummy_fun &lt;- function(a, b, c) { \n  if(any(missing(a), missing(b), missing(c))) {\n    stop(\"One or more required arguments missing.\")\n  }\n  # Do something...\n}\ndummy_fun(a = 1)\nError in dummy_fun(a = 1): One or more required arguments missing.\n\n\n1.2 Sensible defaults with warnings\nIn some cases, we may need the function to use some sensible default value for the required arguments and continue execution. Here, we display a warning message instead of an error message. This is required when the argument value is either considered to be obvious or the argument is not necessarily the most important one and is used only in extreme customization. Providing default values to arguments makes them optional arguments. An example of default argument values can be seen in the paste function we have used earlier. The default value of the separator argument sep is a single whitespace character.\n\nCodeargs(paste)\n\nfunction (..., sep = \" \", collapse = NULL, recycle0 = FALSE) \nNULL\n\n\nSimilarly, we can provide some sensible defaults for the make_date function. Let’s modify the function further to provide defaults for the mm and dd arguments only.\n\nCodemake_date &lt;-  function(yyyy, mm = 1, dd = 1) {\n  \n  # check missing arguments\n  if (missing(yyyy))  stop(\"argument `yyyy` is required.\") \n  if (missing(mm)) warning(\"argument `mm` is missing. Using default value mm = 1 instead\") \n  if (missing(dd)) warning(\"argument `dd` is missing. Using default value dd = 1 instead\")\n  \n  # main logic\n  as.Date(paste(yyyy, mm, dd, sep = \"-\"), format = \"%Y-%m-%d\")\n}\n\n# Calling the function without `mm` and `dd` arguments\nmake_date(yyyy = 2022) # here, only `yyyy` is the required argument.\nWarning in make_date(yyyy = 2022): argument `mm` is missing. Using default value\nmm = 1 instead\n\nWarning in make_date(yyyy = 2022): argument `dd` is missing. Using default value\ndd = 1 instead\n\n\n[1] \"2022-01-01\"\n\n\nThere are a few concerns about using warnings instead of error messages. Some are listed here in this article from RBloggers A Warning About warning."
  },
  {
    "objectID": "posts/writing-robust-functions/index.html#scenario-2-invalid-argument-data-type",
    "href": "posts/writing-robust-functions/index.html#scenario-2-invalid-argument-data-type",
    "title": "Writing Robust R Functions",
    "section": "Scenario 2: Invalid Argument Data Type",
    "text": "Scenario 2: Invalid Argument Data Type\nWe have defined make_date to accept 3 numeric arguments i.e. all 3 must be numbers. What would happen if someone tried to call make_date with character, factor or boolean inputs?\n\nCodemake_date(yyyy = \"2022\", mm = \"5\", dd = \"20\") # works!! why?\n\n[1] \"2022-05-20\"\n\n\nIn this case, the function works because when the arguments are combined into a single string using paste , it matches the format argument of the as.Date function in the main logic of make_date which is as.Date(paste(yyyy, mm, dd, sep = \"-\"), format = \"%Y-%m-%d\")\n\nCodemake_date(yyyy = \"2022\", mm = \"May\", dd = \"1\") # works but shows NA !!!\n\n[1] NA\n\n\nIn this case, all the arguments pass the checks but since we pass 2022-May-1 to as.Date which doesn’t match the format = '%Y-%m-%d' thus giving NA.\nHow do we check if the values provided to the arguments are numbers or number-like? If the values are numbers, we let them pass. But if they are non-numeric, we must check if they can be converted to numbers i.e. we must check if they are number-like. By number-like, I mean, will coercing the value using as.numeric give us a numeric value or NA ? You guessed it right, we will pass the values through as.numeric and check if the output is NA or not.\nWhat are the various data types in R that are not numeric but can look like numbers? We have character, factor and boolean data types which can behave like numbers sometimes. Let’s see a few scenarios.\nCharacter arguments\n\nCodeYear &lt;- c(\"2022\", \"TwentyTwo\")\nYear_num &lt;- as.numeric(Year) # this should show a warning about NAs introduced by coercion\nWarning: NAs introduced by coercion\n\nCodeYear_num # must show the number 2022 without quotes and one NA\n\n[1] 2022   NA\n\n\nAs you can see in above example, when passed through as.numeric, the value “2022” gets converted to the number 2022 but the value “TwentyTwo” does not. Hence we can say “2022” is number-like but “TwentyTwo” is not.\nFactor arguments\n\nCodeYear &lt;- factor(c(\"2022\",\"2021\",\"TwentyTwo\"))\nas.numeric(Year)\n\n[1] 2 1 3\n\nCodeYearX &lt;- factor(c(\"2022\", \"X\"))\nas.numeric(YearX)\n\n[1] 1 2\n\nCodeYearY &lt;- factor(2022)\nas.numeric(YearY)\n\n[1] 1\n\n\nAs you can see from above examples, factor values do get converted to numeric but do not give the right results. So we can safely say that factors are not number-like.\nI will ignore boolean data types hoping that useRs are bright enough to not use Booleans while creating a Date!\nFrom the above examples, we can conclude that numeric values and number-like character values are the only valid data types that should be allowed. Modifying our make_date function to include data type checks.\n\nCodemake_date &lt;-  function(yyyy, mm = 1, dd = 1) {\n  \n  # check missing arguments\n  if (missing(yyyy))  stop(\"argument `yyyy` is required.\") \n  if (missing(mm)) warning(\"argument `mm` is missing. Using default value mm = 1 instead\") \n  if (missing(dd)) warning(\"argument `dd` is missing. Using default value dd = 1 instead\")\n  \n  # Check data types\n  if (!is.numeric(yyyy) & !is.character(yyyy)) {\n    stop(\"argument `yyyy` must be numeric\")\n  } else if (is.character(yyyy) & is.na(as.numeric(yyyy))) {\n    stop(\"argument `yyyy` must be numeric\")\n  }\n  if (!is.numeric(mm) & !is.character(mm)) {\n    stop(\"argument `mm` must be numeric\")\n  } else if (is.character(mm) & is.na(as.numeric(mm))) {\n    stop(\"argument `mm` must be numeric\")\n  }\n  if (!is.numeric(dd) & !is.character(dd)) {\n    stop(\"argument `dd` must be numeric\")\n  } else if (is.character(dd) & is.na(as.numeric(dd))) {\n    stop(\"argument `dd` must be numeric\")\n  }\n  \n  # main logic\n  as.Date(paste(yyyy, mm, dd, sep = \"-\"), format = \"%Y-%m-%d\")\n}\n\n# Calling the function with new datatype checks\nmake_date(yyyy = \"2022\", mm = \"May\", dd = \"1\")\nWarning in make_date(yyyy = \"2022\", mm = \"May\", dd = \"1\"): NAs introduced by\ncoercion\n\nError in make_date(yyyy = \"2022\", mm = \"May\", dd = \"1\"): argument `mm` must be numeric\n\nCodemake_date(yyyy = \"2022\", mm = factor(\"5\"), dd = \"1\")\nError in make_date(yyyy = \"2022\", mm = factor(\"5\"), dd = \"1\"): argument `mm` must be numeric\n\n\nNotice that the datatype check is lengthy and similar for all 3 arguments. We can apply DRY principle again and encapsulate that code into a small function is_numberlike which will return TRUE or FALSE . Note that is_numberlike has no checks because it is an internal function.\n\nCode# This function check if value is number or number-like.\nis_numberlike &lt;- function(x){\n  if (!is.numeric(x) & !is.character(x)) {\n    # Early Exit 1 if value is neither numeric nor character\n    return(FALSE) \n  } else if (is.character(x) & is.na(as.numeric(x))) {\n    # Early Exit 2 if character value is not number-like.\n    return(FALSE) \n  }\n  return(TRUE)\n}\n\n\nThus our make_date function with data types check will look as below.\n\nCodemake_date &lt;-  function(yyyy, mm = 1, dd = 1) {\n  \n  # check missing arguments\n  if (missing(yyyy))  stop(\"argument `yyyy` is required.\") \n  if (missing(mm)) warning(\"argument `mm` is missing. Using default value mm = 1 instead\") \n  if (missing(dd)) warning(\"argument `dd` is missing. Using default value dd = 1 instead\")\n  \n  # Check data types\n  if (!is_numberlike(yyyy)) stop(\"argument `yyyy` must be numeric\")\n  if (!is_numberlike(mm))   stop(\"argument `mm` must be numeric\")\n  if (!is_numberlike(dd))   stop(\"argument `dd` must be numeric\")\n  \n  # main logic\n  as.Date(paste(yyyy, mm, dd, sep = \"-\"), format = \"%Y-%m-%d\")\n}\n\n# Calling the function with new datatype checks\nmake_date(yyyy = \"TwentyTwo\", mm = \"5\", dd = 1)\nWarning in is_numberlike(yyyy): NAs introduced by coercion\n\nError in make_date(yyyy = \"TwentyTwo\", mm = \"5\", dd = 1): argument `yyyy` must be numeric\n\nCodemake_date(yyyy = \"2022\", mm = factor(\"5\"), dd = \"1\")\nError in make_date(yyyy = \"2022\", mm = factor(\"5\"), dd = \"1\"): argument `mm` must be numeric\n\nCodemake_date(yyyy = 2022, mm = 5, dd = \"one\")\nWarning in is_numberlike(dd): NAs introduced by coercion\n\nError in make_date(yyyy = 2022, mm = 5, dd = \"one\"): argument `dd` must be numeric\n\n\nOne of the most interesting features of R is vectorization! Due to this feature, our function make_date behaves in interesting ways. In some cases, it is desirable and sometimes it is not.\n\nCodemake_date(yyyy = 2022, mm = 1:12, dd = \"1\")\nWarning in if (is.character(x) & is.na(as.numeric(x))) {: the condition has\nlength &gt; 1 and only the first element will be used\n\n\n [1] \"2022-01-01\" \"2022-02-01\" \"2022-03-01\" \"2022-04-01\" \"2022-05-01\"\n [6] \"2022-06-01\" \"2022-07-01\" \"2022-08-01\" \"2022-09-01\" \"2022-10-01\"\n[11] \"2022-11-01\" \"2022-12-01\"\n\n\nNote the above warnings. These warnings appear because the if statement checks if the condition provided results in a single TRUE or FALSE value. However, the output of the check is.na(as.numeric(mm)) is a boolean vector of length 12. But if needs only 1 TRUE or FALSE.\nThe output contains 12 date values since paste is vectorised, it recycles the values for yyyy and dd to give us 12 dates!\n\nCodemm &lt;- 1:12\npaste(\"Month\", mm)\n\n [1] \"Month 1\"  \"Month 2\"  \"Month 3\"  \"Month 4\"  \"Month 5\"  \"Month 6\" \n [7] \"Month 7\"  \"Month 8\"  \"Month 9\"  \"Month 10\" \"Month 11\" \"Month 12\"\n\n\nWhat do we do if we want make_date to return just one date?"
  },
  {
    "objectID": "posts/writing-robust-functions/index.html#scenario-3-incorrect-argument-size",
    "href": "posts/writing-robust-functions/index.html#scenario-3-incorrect-argument-size",
    "title": "Writing Robust R Functions",
    "section": "Scenario 3: Incorrect Argument Size",
    "text": "Scenario 3: Incorrect Argument Size\nTo ensure make_date gives you just one date, we must ensure that the arguments have just value and is not a vector of multiple values i.e. length(arg)==1. Let’s further add a few checks for the data size of the arguments and rearrange the checks.\n\nCodemake_date &lt;-  function(yyyy, mm = 1, dd = 1) {\n  \n  # check missing arguments\n  if (missing(yyyy))  stop(\"argument `yyyy` is required.\") \n  if (missing(mm)) warning(\"argument `mm` is missing. Using default value mm = 1 instead\") \n  if (missing(dd)) warning(\"argument `dd` is missing. Using default value dd = 1 instead\")\n  \n  # Check argument lengths\n  if (length(yyyy)!=1) stop(paste0(\"Length of argument `yyyy` is \", length(yyyy),\". Must be only 1.\"))\n  if (length(mm)!=1)   stop(paste0(\"Length of argument `mm` is \", length(mm),\". Must be only 1.\"))\n  if (length(dd)!=1)   stop(paste0(\"Length of argument `dd` is \", length(dd),\". Must be only 1.\"))\n  \n  # Check data types\n  if (!is_numberlike(yyyy)) stop(\"argument `yyyy` must be numeric\")\n  if (!is_numberlike(mm))   stop(\"argument `mm` must be numeric\")\n  if (!is_numberlike(dd))   stop(\"argument `dd` must be numeric\")\n  \n  # main logic\n  as.Date(paste(yyyy, mm, dd, sep = \"-\"), format = \"%Y-%m-%d\")\n}\n\n# Calling function with new data size checks\nmake_date(yyyy = 2022, mm = 1:12, dd = \"01\")\nError in make_date(yyyy = 2022, mm = 1:12, dd = \"01\"): Length of argument `mm` is 12. Must be only 1.\n\nCodemake_date(yyyy = c(\"2021\",\"2022\"), mm = \"1\", dd = 1)\nError in make_date(yyyy = c(\"2021\", \"2022\"), mm = \"1\", dd = 1): Length of argument `yyyy` is 2. Must be only 1.\n\nCodemake_date(yyyy = 2022, mm = 1, dd = c(\"1\",\"2\"))\nError in make_date(yyyy = 2022, mm = 1, dd = c(\"1\", \"2\")): Length of argument `dd` is 2. Must be only 1."
  },
  {
    "objectID": "posts/writing-robust-functions/index.html#a-little-detour",
    "href": "posts/writing-robust-functions/index.html#a-little-detour",
    "title": "Writing Robust R Functions",
    "section": "A little detour…",
    "text": "A little detour…\nSo far we checked for missing arguments, arguments with bad data types and arguments with incorrect sizes. We’ve used the stop function along with if to check for all failure conditions and show appropriate error messages. When we use stop, we must specify all the failure conditions and the number of specific error messages goes up as number of arguments increases.\nIn case of our make_date, if an argument is not missing, it must be a number-like value of length 1. To reduce the number of error messages, we can combine the error messages for data type and length. for eg, the error message could be argument yyyy must be a number-like value of length 1.\nWouldn’t it be easier if we just specify what is the success condition aka the “happy path”, and show error for all other conditions? To do this, we can use the stopifnot function that let’s us specify all the happy paths. See example below.\n\nCodedummy_sum &lt;- function(a, b, c){\n  \n  # check missing\n  stopifnot(!missing(a) & !missing(b) & !missing(c))\n  \n  # check argument values\n  stopifnot(!is.na(a) & is.numeric(a) & length(a)==1,\n            !is.na(b) & is.numeric(b) & length(b)==1,\n            !is.na(c) & is.numeric(c) & length(c)==1\n            )\n  sum(a, b, c)\n}\n\ndummy_sum(b = 2, c = 3) # a is missing\nError in dummy_sum(b = 2, c = 3): !missing(a) & !missing(b) & !missing(c) is not TRUE\n\nCodedummy_sum(a = NA_integer_, b = 2, c = 3) # a has NA value\nError in dummy_sum(a = NA_integer_, b = 2, c = 3): !is.na(a) & is.numeric(a) & length(a) == 1 is not TRUE\n\nCodedummy_sum(a = 1, b = \"2\", c = 3) # b has non-numeric value\nError in dummy_sum(a = 1, b = \"2\", c = 3): !is.na(b) & is.numeric(b) & length(b) == 1 is not TRUE\n\nCodedummy_sum(a = 1, b = 2, c = 5:7)  # c has length != 1\nError in dummy_sum(a = 1, b = 2, c = 5:7): !is.na(c) & is.numeric(c) & length(c) == 1 are not all TRUE\n\n\nNote the error messages above. They are not so user-friendly. Luckily, we can specify error messages in stopifnot by providing the error messages as the names of the “happy path” conditions.\n\nCodedummy_sum &lt;- function(a, b, c){\n  \n  # check missing\n  stopifnot(\"one or more required arguments missing\" = !missing(a) & !missing(b) & !missing(c))\n  \n  # check argument values\n  stopifnot(\"argument `a` must not be NA, must be a number of length 1\" = !is.na(a) & is.numeric(a) & length(a)==1,\n            \"argument `b` must not be NA, must be a number of length 1\" = !is.na(b) & is.numeric(b) & length(b)==1,\n            \"argument `c` must not be NA, must be a number of length 1\" = !is.na(c) & is.numeric(c) & length(c)==1\n            )\n  sum(a, b, c)\n}\n\ndummy_sum(b = 2, c = 3) # a is missing\nError in dummy_sum(b = 2, c = 3): one or more required arguments missing\n\nCodedummy_sum(a = NA_integer_, b = 2, c = 3) # a has NA value\nError in dummy_sum(a = NA_integer_, b = 2, c = 3): argument `a` must not be NA, must be a number of length 1\n\nCodedummy_sum(a = 1, b = \"2\", c = 3) # b has non-numeric value\nError in dummy_sum(a = 1, b = \"2\", c = 3): argument `b` must not be NA, must be a number of length 1\n\nCodedummy_sum(a = 1, b = 2, c = 5:7)  # c has length != 1\nError in dummy_sum(a = 1, b = 2, c = 5:7): argument `c` must not be NA, must be a number of length 1\n\n\nUsing stopifnot in our make_date function to combine the datatype and length checks, we get…\n\nCodemake_date &lt;-  function(yyyy, mm = 1, dd = 1) {\n  \n  # check missing arguments\n  if (missing(yyyy))  stop(\"argument `yyyy` is required.\") \n  if (missing(mm)) warning(\"argument `mm` is missing. Using default value mm = 1 instead\") \n  if (missing(dd)) warning(\"argument `dd` is missing. Using default value dd = 1 instead\")\n  \n  \n  # Check argument types and length\n  stopifnot(\n    \"argument `yyyy` must be numeric with length 1\" = is_numberlike(yyyy) & length(yyyy)==1,\n    \"argument `mm` must be numeric with length 1\"   = is_numberlike(mm)   & length(mm)==1,\n    \"argument `dd` must be numeric with length 1\"   = is_numberlike(dd)   & length(dd)==1\n  )\n  \n  # main logic\n  as.Date(paste(yyyy, mm, dd, sep = \"-\"), format = \"%Y-%m-%d\")\n}\n\nmake_date() # no arguments provided\nError in make_date(): argument `yyyy` is required.\n\nCodemake_date(yyyy = 2022, mm = 1:12, dd = 31) # Length mm not equal to 1\nWarning in if (is.character(x) & is.na(as.numeric(x))) {: the condition has\nlength &gt; 1 and only the first element will be used\n\nError in make_date(yyyy = 2022, mm = 1:12, dd = 31): argument `mm` must be numeric with length 1\n\nCodemake_date(yyyy = 2022, mm = \"Jan\", dd = 31) # mm is not number-like\nWarning in is_numberlike(mm): NAs introduced by coercion\n\nError in make_date(yyyy = 2022, mm = \"Jan\", dd = 31): argument `mm` must be numeric with length 1\n\nCodemake_date(yyyy = 2022, dd = 31) # argument mm is missing but should work using default value\nWarning in make_date(yyyy = 2022, dd = 31): argument `mm` is missing. Using\ndefault value mm = 1 instead\n\n\n[1] \"2022-01-31\""
  },
  {
    "objectID": "posts/writing-robust-functions/index.html#scenario-4-values-of-arguments-that-result-in-invalid-outputs",
    "href": "posts/writing-robust-functions/index.html#scenario-4-values-of-arguments-that-result-in-invalid-outputs",
    "title": "Writing Robust R Functions",
    "section": "Scenario 4: Values of Arguments that result in invalid outputs",
    "text": "Scenario 4: Values of Arguments that result in invalid outputs\nFinally, what do we do when the arguments provided will definitely give us bad results despite passing all checks? In our case, make_date creates a date but if we give it values that will result in an invalid date, it will give us invalid results (remember Garbage-In-Garbage-Out?).\n\nCodemake_date(yyyy = 2022, mm = 13, dd = 1) # is there a 13th month?\n\n[1] NA\n\n\nWe get NA because as.Date returns NA for invalid inputs with no error messages or warnings! We can check the output and provide a generic error message.\n\nCodemake_date &lt;-  function(yyyy, mm = 1, dd = 1) {\n  # check missing arguments\n  if (missing(yyyy))  stop(\"argument `yyyy` is required.\") \n  if (missing(mm)) warning(\"argument `mm` is missing. Using default value mm = 1 instead\") \n  if (missing(dd)) warning(\"argument `dd` is missing. Using default value dd = 1 instead\")\n  \n  \n  # Check argument types and length\n  stopifnot(\n    \"argument `yyyy` must be numeric with length 1\" = is_numberlike(yyyy) & length(yyyy)==1,\n    \"argument `mm` must be numeric with length 1\"   = is_numberlike(mm)   & length(mm)==1,\n    \"argument `dd` must be numeric with length 1\"   = is_numberlike(dd)   & length(dd)==1\n  )\n  \n  # main logic\n  out &lt;- as.Date(paste(yyyy, mm, dd, sep = \"-\"), format = \"%Y-%m-%d\")\n  if (is.na(out)) {\n    stop(\"Invalid values provided. Please check your inputs.\")\n  }\n  return(out)\n}\n\nmake_date(yyyy = 2022, mm = 13, dd = 1) # is there a 13th month?\nError in make_date(yyyy = 2022, mm = 13, dd = 1): Invalid values provided. Please check your inputs.\n\nCodemake_date(yyyy = 2022, mm = 2, dd = 31) # are there 31 days in February?\nError in make_date(yyyy = 2022, mm = 2, dd = 31): Invalid values provided. Please check your inputs.\n\n\nDo you think our function make_date is robust enough?\n\n\n\nAs robust as Superman! Source: Imgur"
  },
  {
    "objectID": "posts/writing-robust-functions/index.html#conclusion",
    "href": "posts/writing-robust-functions/index.html#conclusion",
    "title": "Writing Robust R Functions",
    "section": "Conclusion",
    "text": "Conclusion\nMaking functions robust requires some prior thought about its intended use and audience. Based on this, we can decide what checks to implement, what to skip, whether to stop execution using error messages or to use default values with warnings. Checking for “happy paths” is simpler compared to checking each and every bad input and providing specific error messages. Too many different error messages for the same argument could become a source of frustration of the end user, so consider combining some checks and their error messages to be informative and precise. Robustness, like everything else, in moderation, is good and getting it “just right” takes time and dedicated effort. Happy Coding!"
  },
  {
    "objectID": "posts/writing-robust-functions/index.html#citations-references",
    "href": "posts/writing-robust-functions/index.html#citations-references",
    "title": "Writing Robust R Functions",
    "section": "Citations & References",
    "text": "Citations & References\n\nTechniques for writing robust R programs - LexJansen\nR Programming for Data Science\nA Warning About warning"
  },
  {
    "objectID": "posts/writing-robust-functions/index.html#footnotes",
    "href": "posts/writing-robust-functions/index.html#footnotes",
    "title": "Writing Robust R Functions",
    "section": "Footnotes",
    "text": "Footnotes\n\nDon’t Repeat Yourself!↩︎"
  },
  {
    "objectID": "posts/tidyr-pivot-longer/index.html",
    "href": "posts/tidyr-pivot-longer/index.html",
    "title": "Pivoting your tables with Tidyr: Part I",
    "section": "",
    "text": "One of the primary data manipulation operations is pivoting your tabular data from “wide” format to “long” format and vice-versa.\nThe idea is to make your tabular data “tidy” i.e.\n\nEvery column is a variable.\nEvery row is an observation.\nEvery cell is a single value.\n\nIn other words, every column contains just one type of information, every row in the table is a snapshot or a version of the information your table captures and every cell contains just one piece of information.1\nWhile the wide format is more human-readable, the long format is preferred and is desirable for data and plotting operations using R, Python or other data processing programming languages. The {tidyr} R package has functions that allow you to transform your tabular data between the two formats.\nIn this post, we will see how to convert a wide dataframe to long format using the pivot_longer() function from {tidyr} package."
  },
  {
    "objectID": "posts/tidyr-pivot-longer/index.html#footnotes",
    "href": "posts/tidyr-pivot-longer/index.html#footnotes",
    "title": "Pivoting your tables with Tidyr: Part I",
    "section": "Footnotes",
    "text": "Footnotes\n\nLong vs. Wide Data: What’s the Difference? https://www.statology.org/long-vs-wide-data/↩︎"
  },
  {
    "objectID": "posts/R2VBA2PPT1/index.html",
    "href": "posts/R2VBA2PPT1/index.html",
    "title": "Unholy Trinity of R, Excel VBA and Powerpoint - Part 1 of 2",
    "section": "",
    "text": "One of the most common tasks in most offices, is creating presentations and reports in Microsoft PowerPoint. While the tool is great for creating ad-hoc presentations, editing the same with new data on a periodic basis gets tedious. Now, I know that some wonderful packages like officer and officedown exist that enable us to create PowerPoint presentations with editable charts from R itself. You can read all about this in the amazing Alison Hill’s blog post “Up and running with officedown”.\nSince I discovered R while looking for a better alternative to VBA for data analysis and Excel/PowerPoint automation, the following is an alternative workflow to create multiple PowerPoint presentations using a combination of these technologies. Note that this workflow uses the RDCOMClient package which works in Windows environment only."
  },
  {
    "objectID": "posts/R2VBA2PPT1/index.html#tldr",
    "href": "posts/R2VBA2PPT1/index.html#tldr",
    "title": "Unholy Trinity of R, Excel VBA and Powerpoint - Part 1 of 2",
    "section": "TL;DR",
    "text": "TL;DR\nIn this 2-part blog, we create a PowerPoint template with named placeholders which we populate from an Excel file using VBA. The Excel file is loaded with data using R with the help of openxlsx package and then the macro is triggered using the RDCOMClient package.\nThis solution has great potential to give you the same feeling as those Jurassic Park scientists that Dr. Ian Malcolm remarked about!\nAdvantages of this approach over officer and officedown:\n\nSlide/content/header/footer formatting control is in the PowerPoint template rather than R code.\nAll charts are native and can contain any feature (dual axis, mixed data series like bar + line, line + points). All Excel chart-types are available. Go wild!\nYou can use any PowerPoint template design (Yes, even your sad/weird/exciting corporate template!).\n\nLet’s begin.\nSuppose we want to automate the following PowerPoint presentation. It contains 3 slides with a title slide and 2 content slides having graphs and tables created from the gapminder dataset. This .pptx file also has a custom footer.\n\n\n\n\n\n\nFigure 1: The Gapminder World Population Report. Note the custom footer!\n\n\n\nWe want to create the same presentation with same structure but at a continent-level. gapminder has data for 5 continents and we wish to create 5 presentations by the end of this."
  },
  {
    "objectID": "posts/R2VBA2PPT1/index.html#the-powerpoint-template",
    "href": "posts/R2VBA2PPT1/index.html#the-powerpoint-template",
    "title": "Unholy Trinity of R, Excel VBA and Powerpoint - Part 1 of 2",
    "section": "The PowerPoint Template",
    "text": "The PowerPoint Template\nIn this approach, we start with the PowerPoint presentation file. We will create a template with placeholders and charts with dummy data.\n\n\n\n\n\n\nFigure 2: Save As PowerPoint Template (.potx)\n\n\n\nUsually, you would have a copy of the .pptx file you want to automate. Save a copy of it as a PowerPoint Template (.potx), ideally to your R Project1 folder. In my case, I’ve created a new R Project folder named R2XL2PPT as shown in Figure 2.\nNow let us prep the template. If you open the template file by double-click or right-click &gt; New, it would open a fresh .pptx presentation using the template. Right-Click and click Open in the context menu to open the .potx template file for editing.\n\n\n\n\n\n\nFigure 3: CORRECT: Right-Click &gt; Open\n\n\n\nOnce you have the template open, we will add names to all the text placeholders, tables and graphs we wish to update. To update the placeholder name:\n\nSelect the shape/text-area/table/graph.\nFrom Shape Format, click Selection Pane.\nIn the Selection Pane, change the name of the selected item.\n\n\n\n\n\n\n\nFigure 4: Add shape names from Selection Pane\n\n\n\n\n\n\n\n\n\nAdvisory\n\n\n\nWe use the format NN_[Position]Object where NN is the slide number, [Position] is the either TopLeft, TopRight, BottomLeft, BottomRight or any other position and finally, Object is either Table, Chart, Title, Subtitle, TextBox etc. You can use any fancy identifier here, just make sure that your future self and others can recognise them easily.\n\n\nOnce you set the names of all the items that you want to customise, save the template.\nDownload the GP_template.potx template here."
  },
  {
    "objectID": "posts/R2VBA2PPT1/index.html#the-excel-template",
    "href": "posts/R2VBA2PPT1/index.html#the-excel-template",
    "title": "Unholy Trinity of R, Excel VBA and Powerpoint - Part 1 of 2",
    "section": "The Excel Template",
    "text": "The Excel Template\n\n\n\n\n\n\nFigure 5: PowerPoint item to Excel named range mapping\n\n\n\nTo populate all the named items in the PowerPoint template, we will now create an Excel document which looks identical to the template with respect to the named items. Please see Figure 5.\nFor every named item, depending on whether it is a textbox or chart or table, we will create a named range for that item. For example, for item 01_title in the PowerPoint template, we create a S1_title named range2 (which points to cell C3) as a placeholder for it.\n\n\n\n\n\n\nWarning\n\n\n\nExcel does not allow the names of the named ranges to start with a number, hence 01_title is mapped to S1_title. The S stands for Slide. Just one of those Excel quirks I guess!\n\n\nYou can set a single Excel cell as named range for each textbox in the PowerPoint template. You can copy-paste tables from Powerpoint to the Excel template directly. The entire table must be set as a named range.\n\n\n\n\n\n\nFigure 6: Excel Chart: Right Click &gt; Edit Data\n\n\n\nFor charts, right-click the chart in PowerPoint and select Edit Data. See Figure 6. An excel worksheet is displayed with the underlying data. Copy-paste the entire data into the Excel template.\n\n\n\n\n\n\nFigure 7: XL2PPT design\n\n\n\nFor the GP_template.potx, the corresponding excel template XL2PPT.xlsm is shown in Figure 7. Please note that this template does not have the VBA macro yet."
  },
  {
    "objectID": "posts/R2VBA2PPT1/index.html#the-vba-macro",
    "href": "posts/R2VBA2PPT1/index.html#the-vba-macro",
    "title": "Unholy Trinity of R, Excel VBA and Powerpoint - Part 1 of 2",
    "section": "The VBA Macro",
    "text": "The VBA Macro\nWe want the VBA macro to:\n\nOpen a new instance of PowerPoint presentation using the GP_template.potx file.\nCopy text/numbers from various placeholders and replace existing text/numbers in the PowerPoint presentation.\nSave the presentation with custom file name with .pptx extension.\n\nThe actual mapping of the named ranges in the Excel template to the named shapes in the PowerPoint template happens in the VBA code. However, at this stage, you can actually create the PowerPoint presentation by copying the numbers into the Excel template and hitting the big RUN MACRO button.\nFor your reference, I am embedding the VBA macro code below. You can download the XL2PPT.xlsm file from here.\n\n\n VBA Macro Code"
  },
  {
    "objectID": "posts/R2VBA2PPT1/index.html#r",
    "href": "posts/R2VBA2PPT1/index.html#r",
    "title": "Unholy Trinity of R, Excel VBA and Powerpoint - Part 1 of 2",
    "section": "R",
    "text": "R\nSuppose we want to create a 10 variations of PowerPoint presentation using the same template. While creating the presentation from Excel is now automated, how about creating the numbers for each of those 10 variations? This is where we bring in R with the openxlsx and RDCOMClient packages. We use the tidyverse set of packages to read in data, clean and massage the data into the various formats we need, openxlsx to write the data (single numbers, text or tables of numbers) to the Excel template and RDCOMClient to run the embedded VBA code in the Excel template.\nCheck out Part 2 of this blog to see how to run VBA code using R. Let me know if you find this useful or any corrections required in the comments below."
  },
  {
    "objectID": "posts/R2VBA2PPT1/index.html#footnotes",
    "href": "posts/R2VBA2PPT1/index.html#footnotes",
    "title": "Unholy Trinity of R, Excel VBA and Powerpoint - Part 1 of 2",
    "section": "Footnotes",
    "text": "Footnotes\n\nWhat is an R Project?https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects↩︎\nWhat is a Named Range in Excel? https://support.microsoft.com/en-us/office/define-and-use-names-in-formulas-4d0f13ac-53b7-422e-afd2-abd7ff379c64↩︎"
  },
  {
    "objectID": "posts/programming-with-dplyr/index.html",
    "href": "posts/programming-with-dplyr/index.html",
    "title": "Programming with R {dplyr} - As I Understand It!!",
    "section": "",
    "text": "The purpose of this article is to act as a quick guide for myself and others to understand how to use dplyr effectively to create dynamic functions. The general assumption is that the reader is familiar with the dplyr package and how to use it for data wrangling.\n\nI regularly deal with event-related information with event date and few other columns like event type, root cause etc. Most reports usually involve calculating number of events that took place on a monthly, quarterly or annual basis, sometimes split by event type, root cause and other columns. After a few reports I realized that I am basically writing the same code over and over again to calculate these KPIs. Keeping the DRY1 principle in mind, I managed to write a few functions to calculate these KPIs with a few dynamic variables. Following is an attempt to articulate what I learnt while creating those functions.\n\nWe shall use the Texas Housing Sales data, available as a tibble in the popular ggplot2 package as reference data. It contains monthly information about the housing market in Texas provided by the TAMU real estate center, https://www.recenter.tamu.edu/. It has 8602 observations and 9 variables.\n\nCodetxhousing &lt;- ggplot2::txhousing\ndplyr::glimpse(txhousing)\n\nRows: 8,602\nColumns: 9\n$ city      &lt;chr&gt; \"Abilene\", \"Abilene\", \"Abilene\", \"Abilene\", \"Abilene\", \"Abil~\n$ year      &lt;int&gt; 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, ~\n$ month     &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5, 6, 7, ~\n$ sales     &lt;dbl&gt; 72, 98, 130, 98, 141, 156, 152, 131, 104, 101, 100, 92, 75, ~\n$ volume    &lt;dbl&gt; 5380000, 6505000, 9285000, 9730000, 10590000, 13910000, 1263~\n$ median    &lt;dbl&gt; 71400, 58700, 58100, 68600, 67300, 66900, 73500, 75000, 6450~\n$ listings  &lt;dbl&gt; 701, 746, 784, 785, 794, 780, 742, 765, 771, 764, 721, 658, ~\n$ inventory &lt;dbl&gt; 6.3, 6.6, 6.8, 6.9, 6.8, 6.6, 6.2, 6.4, 6.5, 6.6, 6.2, 5.7, ~\n$ date      &lt;dbl&gt; 2000.000, 2000.083, 2000.167, 2000.250, 2000.333, 2000.417, ~\n\n\nWe shall refer the above data in all the following sections."
  },
  {
    "objectID": "posts/programming-with-dplyr/index.html#footnotes",
    "href": "posts/programming-with-dplyr/index.html#footnotes",
    "title": "Programming with R {dplyr} - As I Understand It!!",
    "section": "Footnotes",
    "text": "Footnotes\n\nDon’t Repeat Yourself↩︎"
  },
  {
    "objectID": "posts/date-format/index.html",
    "href": "posts/date-format/index.html",
    "title": "Beyond 01/31/2024",
    "section": "",
    "text": "Intro\n\n\n\nSource: XKCD\n\n\nDates are everywhere!!! They appear in documents, digital displays, our phones and conversations. In day-to-day life, outside of work, most of us are usually aware of which month and year is going on. However, at work, for communication, file-management, meeting scheduling, reporting, especially with International clients and MNCs, choosing the right date format can make a significant difference in clarity, consistency, and ease of use. Among various formats like MM/DD/YYYY, DD/MM/YYYY, and others, the YYYY-MM-DD format stands out as the best choice. While some might argue it’s just a matter of preference, there’s actually a strong case for one format reigning supreme.\n\n\nAmbiguity and Confusion\nFormats like DD/MM/YYYY and MM/DD/YYYY cause confusion, especially in Orgs. that operate across geographies and multi-national companies (MNC) At a smaller scale, individual gig-workers working with MS Excel files from different clients get confused if the date format is different.\n\n\n\nSource: Reddit\n\n\nThe YYYY-MM-DD format follows a logical order: Year, &gt; Month &gt; Day, from largest to smallest unit. The logic is similar to geographical hierarchy i.e. Earth (Planet) &gt; Asia (Continent) &gt; India (Country) &gt; Karnataka (State) &gt; Bengaluru (City). Largest to Smallest!\nThis logical structure ensures clarity and consistency in understanding dates across different cultures and languages. For instance:\n\nJanuary 31, 2024 is represented as 2024-01-31. The sequence is intuitive and unambiguous, reducing the risk of misinterpretation.\nIn contrast, formats like MM/DD/YYYY or DD/MM/YYYY can lead to confusion, especially in international communication. For example, 02/03/2024 can mean February 3rd or March 2nd, depending on the chosen format, leading to potential errors.\n\n\n\nSorting and Organization\nThe YYYY-MM-DD format facilitates sorting dates effortlessly, both alphabetically and chronologically. Whether it’s arranging files on a computer, organizing data in spreadsheets, or storing information in databases, the YYYY-MM-DD format simplifies the process.\n\nAlphabetical sorting aligns with chronological order, making it easier for computers and humans to process information consistently.\nOther formats may pose challenges in sorting, especially when combining different date formats within the same dataset. Ambiguities arise, leading to errors and confusion during analysis.\n\nSorting is done based on the Alphabetical order of the characters in the filenames. Let’s evaluate each format on the basis of sorting.\n\nMM-DD-YYYYDD-MM-YYYYMMM-DD-YYYYDD-MMM-YYYY👑 YYYY-MM-DD 👑\n\n\nThe MM-DD-YYYY format in filenames pulls Month and Days for different years together.\n\n\n\n\n\n\n\nDD-MM-YYYY format in filenames pulls the days together for all months and years. This is worse than MM-DD-YYYY in this case!\n\n\n\nMonth Names cause bigger problems due to Alphabetical ordering. Shows all days of April first followed by all days of August, December, February and so on...\n\n\n\n\n\n\n\nMonth Names cause bigger problems due to Alphabetical ordering. Shows same day of April first followed by same of August, December, February and so on...\n\n\n\n\n\n\n\nYYYY-MM-DD gives the best sorting as per chronological order. No other format gives this order.\n\n\n\n\n\n\n\n\n\n\nCompatibility and Standardization\nYYYY-MM-DD format is widely recognized and accepted in various industries, including technology, finance, and healthcare. Its standardized nature promotes interoperability and data exchange across different systems and platforms.\nMany programming languages like  and , databases, and software applications prefer the YYYY-MM-DD format for date handling and manipulation. This consistency streamlines development and integration processes. International standards bodies like ISO (International Organization for Standardization) endorse the YYYY-MM-DD format (ISO 8601), further solidifying its status as a global standard.\n\n\nBut, I only work in Microsoft’s Excel!! How does this matter?\nWell, you are right!\nSpreadsheet applications like MS Excel store Dates as numbers behind the scenes and display them as per the system’s Locale. An Excel file containing Dates (formatted as proper Dates, not dates stored as Text!!! 😱 ) will change the date format accordingly because the underlying number doesn’t change. However, at one glance, it is not possible to guess if a date-like text is a proper Date or Text. Dates stored as text will not change as per system’s Locale and hence may cause errors in calculations and sorting issues. While the YYYY-MM-DD format will resolve sorting issues (due to its inherent alphabetical order) even if stored as text, calculation errors will still occur if dates are stored as text.\n\n\n\nExcel stores dates as numbers!! A date 20th Feb 2024 represented by the number 45342 means it is 45342 days since 1st Jan 1900.\n\n\nExploring date-related horrors in MS Excel is a topic for a whole other post, which will come soon!\n\n\nIncidents\nWhile there might not be a single major incident directly caused by unambiguous date formats, the lack of standardized date formats has contributed to numerous misunderstandings, errors, and inefficiencies in various contexts. Here are a few examples:\n\nY2K Bug: One of the most well-known incidents related to date formatting issues is the Y2K (Year 2000) bug. Many computer systems used a two-digit representation for the year, assuming the first two digits were “19” by default (e.g., “98” for 1998). As the year 2000 approached, there was concern that these systems would interpret “00” as 1900 instead of 2000, potentially causing malfunctions or system failures. While not directly caused by unambiguous date formats, the Y2K issue highlighted the importance of standardized and unambiguous date representations in computer systems.\nMedical Errors: In healthcare settings, incorrect interpretation of dates can lead to medical errors, missed appointments, and treatment delays. For example, confusion between MM/DD/YYYY and DD/MM/YYYY formats could result in misinterpreting appointment dates, prescription refills, or test results, potentially compromising patient care and safety.\nFinancial Transactions: In the financial sector, accurate date representations are crucial for transactions, accounting, and regulatory compliance. Ambiguous date formats can lead to errors in financial reporting, billing, and tax calculations, causing financial discrepancies and regulatory violations.\nLegal Documents: Ambiguous date formats in legal documents such as contracts, agreements, and court filings can lead to disputes, legal challenges, and contract breaches. Inconsistencies in date interpretation may affect the validity and enforceability of legal agreements, resulting in costly litigation and legal proceedings.\n\n\n\nClosing\nWhile these incidents may not be directly attributed to unambiguous date formats, they underscore the importance of standardized date representations in ensuring accuracy, clarity, and interoperability across different systems, industries, and domains. Standardized date formats, such as those defined in ISO 8601, help mitigate the risk of errors, misunderstandings, and disruptions caused by inconsistent date representations, promoting efficiency, reliability, and trust in data exchange and communication.\nWhile it is highly doubtful that this article says anything new compared to already existing literature, the switch to using YYYY-MM-DD format consistently is a small step towards a more inclusive and unambiguous system of time-keeping!\nGuess, I woke up and chose violence today!\n\n\n\nReferences\nWikipedia - ISO 8601\nWikipedia - Y2K Bug\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{katti2024,\n  author = {Katti, Vishal},\n  title = {Beyond 01/31/2024},\n  date = {2024-02-20},\n  url = {https://vishalkatti.com/posts/date-format},\n  langid = {en},\n  abstract = {This post talks about the superiority of ISO 8601 Date\n    format and why it matters in our day-to-day life.}\n}\nFor attribution, please cite this work as:\nKatti, Vishal. 2024. “Beyond 01/31/2024.” February 20,\n2024. https://vishalkatti.com/posts/date-format."
  },
  {
    "objectID": "courses.html",
    "href": "courses.html",
    "title": "Courses",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Author\n        \n     \n  \n\n\n\n\n\n\n\n\n\n\nEssential IT Skills for Everyone\n\n\nLive, Online and Multi-lingual Course\n\n\n\nExcel\n\n\nPowerPoint\n\n\nWord\n\n\nAI Tools\n\n\nLive Course\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Vishal Katti",
    "section": "",
    "text": "Vishal Katti resides in Bengaluru, India with his wife and 5yo daughter, but constantly longs for the sun and sands of Goa 🌞🏖️🌴 where he spent most of his childhood."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Vishal Katti",
    "section": "Education",
    "text": "Education\nDr. B. R. Ambedkar National Institute of Technology (NIT) Jalandhar, Punjab, India\nBachelor of Technology in Instrumentation & Control Engineering | Aug 2005 - Apr 2010\n\nSmt. Parvatibai Chowgule College of Arts & Science Margao, Goa, India\nH.S.S.C. in Physics, Chemistry and Mathematics | Jun 2003 - Apr 2005"
  },
  {
    "objectID": "about.html#work",
    "href": "about.html#work",
    "title": "Vishal Katti",
    "section": "Work",
    "text": "Work\nLTIMindtree Ltd. Bengaluru, India\nAssociate Principal - Data Sciences | Sep 2021 to Present\nExxonMobil Services & Technology Pvt. Ltd. Bengaluru, India\nBusiness Analytics Advisor | Jun 2018 - Aug 2021\nTata Consultancy Services Mumbai, India\nFunctional Consultant/Data Analyst | Sep 2010 - Jun 2018"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Katti’s Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n\n\n\n\n\n\n\n\n\n\nBeyond 01/31/2024\n\n\nDate Formats and why YYYY-MM-DD is the Goat!!\n\n\n\nDate\n\n\nISO8601\n\n\nR\n\n\nPython\n\n\nExcel\n\n\n\nThis post talks about the superiority of ISO 8601 Date format and why it matters in our day-to-day life.\n\n\n\n\n\nFeb 20, 2024\n\n\nVishal Katti\n\n\n\n\n\n\n\n\n\n\n\n\nPython - List Comprehension\n\n\nCrafting Concise Lists with Python’s List Comprehensions\n\n\n\nPython\n\n\nList\n\n\n\nThis post demonstrates Python’s List Comprehension compared with the for loop and its usage.\n\n\n\n\n\nJan 6, 2024\n\n\nVishal Katti\n\n\n\n\n\n\n\n\n\n\n\n\nPivoting your tables with Tidyr: Part II\n\n\nConverting “long” to “wide” format\n\n\n\nR\n\n\nfunctions\n\n\ntidyr\n\n\npivot\n\n\n\nThis post demonstrates how to use pivot_wider() to convert your long data to wide data. This is part 2 of the Pivoting your tables with Tidyr series.\n\n\n\n\n\nAug 29, 2022\n\n\nVishal Katti\n\n\n\n\n\n\n\n\n\n\n\n\nPivoting your tables with Tidyr: Part I\n\n\nConverting “wide” to “long” format\n\n\n\nR\n\n\nfunctions\n\n\ntidyr\n\n\npivot\n\n\n\nThis post demonstrates how to use pivot_longer() to convert your wide data to long data. This is part 1 of the Pivoting your tables with Tidyr series.\n\n\n\n\n\nJul 8, 2022\n\n\nVishal Katti\n\n\n\n\n\n\n\n\n\n\n\n\nWriting Robust R Functions\n\n\nSome designs to validate function arguments.\n\n\n\nR\n\n\nfunctions\n\n\n\nThis post demonstrates some techniques to make your R user-defined functions unbreakable (well, almost!) by checking if function arguments are missing, incorrect data type or just down-right invalid values and how to return meaningful error messages.\n\n\n\n\n\nJan 18, 2022\n\n\nVishal Katti\n\n\n\n\n\n\n\n\n\n\n\n\nUnholy Trinity of R, Excel VBA and Powerpoint - Part 2 of 2\n\n\nUsing R to trigger Excel VBA macros to create PowerPoint presentations\n\n\n\nR\n\n\nExcel\n\n\nVBA\n\n\nPowerPoint\n\n\nopenxlsx\n\n\nRDCOMClient\n\n\n\nThis post demonstrates how to run VBA macros in Excel which in turn creates Presentations based off PowerPoint Templates.\n\n\n\n\n\nDec 29, 2021\n\n\nVishal Katti\n\n\n\n\n\n\n\n\n\n\n\n\nUnholy Trinity of R, Excel VBA and Powerpoint - Part 1 of 2\n\n\nUsing R to trigger Excel VBA macros to create PowerPoint presentations!\n\n\n\nR\n\n\nExcel\n\n\nVBA\n\n\nPowerPoint\n\n\n\nThis post demonstrates how to create a PowerPoint template based off your custom/corporate Presentation/Report and VBA-enabled Excel file that would populate the report.\n\n\n\n\n\nOct 19, 2021\n\n\nVishal Katti\n\n\n\n\n\n\n\n\n\n\n\n\nInteractive Drill-down Tables using {reactable}\n\n\nHow to create multi-level tables with hidden rows\n\n\n\nR\n\n\nreactable\n\n\ndrill-down\n\n\n\nThis post demonstrates how to use the {reactable} package to create multi-level drill-down tables having hidden rows\n\n\n\n\n\nJul 27, 2021\n\n\nVishal Katti\n\n\n\n\n\n\n\n\n\n\n\n\nProgramming with R {dplyr} - As I Understand It!!\n\n\nHow to create your own functions using {dplyr}\n\n\n\nR\n\n\ndplyr\n\n\nfunctions\n\n\n\nThis post demonstrates how to write your own dynamic functions using popular dplyr verbs like select(), filter(), mutate(), arrange() and group_by() with summarise(). \n\n\n\n\n\nJul 17, 2021\n\n\nVishal Katti\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/drilldown-with-reactable/index.html",
    "href": "posts/drilldown-with-reactable/index.html",
    "title": "Interactive Drill-down Tables using {reactable}",
    "section": "",
    "text": "We often come across denormalized data that has 2 or more levels of information. For example, top-level info like course info with data fields like course id, course name, description, start/end date and second-level info like student info with data fields like with student id, student name, age and gender. We may also have these two groups of data as separate tables with a primary-key foreign-key design, usually from a well-designed SQL database.\nLet us create some data."
  },
  {
    "objectID": "posts/drilldown-with-reactable/index.html#top-level-data-course",
    "href": "posts/drilldown-with-reactable/index.html#top-level-data-course",
    "title": "Interactive Drill-down Tables using {reactable}",
    "section": "Top-Level data: course\n",
    "text": "Top-Level data: course\n\n\nCodelibrary(dplyr, quietly = TRUE, warn.conflicts = FALSE)\nlibrary(rmarkdown, quietly = TRUE, warn.conflicts = FALSE)\n\ncourse &lt;- tibble(course_id   = 1:4,\n                 course_name = paste(\"Course\", LETTERS[1:4]),\n                 start_date  = seq.Date(from = lubridate::as_date(\"2021-01-01\"), by = \"month\", length.out = 4),\n                 end_date    = lubridate::ceiling_date(start_date, unit = \"month\") - 1)\n\npaged_table(course)"
  },
  {
    "objectID": "posts/drilldown-with-reactable/index.html#second-level-data-student",
    "href": "posts/drilldown-with-reactable/index.html#second-level-data-student",
    "title": "Interactive Drill-down Tables using {reactable}",
    "section": "Second Level Data: student\n",
    "text": "Second Level Data: student\n\n\nCodeset.seed(42)\nstudent &lt;- tibble(s_id      = 1:20,\n                  s_name    = paste(\"Student\", LETTERS[1:20]),\n                  gender    = sample(c(\"X\",\"Y\",\"Z\"), 20, replace = TRUE),\n                  age       = sample(18:35, 20, replace = TRUE),\n                  course_id = sample(1:4, 20, replace = TRUE))\n\npaged_table(student)\n\n\n  \n\n\n\nIf we are sourcing data from a database, it is probable that you would see these 2 levels of data in 2 separate tables/views, but most business users are comfortable with MS Excel and want all the data in one sheet!!\nSo the data actually looks something like this.\n\nCodecombined_df &lt;- left_join(course, student, by = \"course_id\")\n\npaged_table(combined_df)\n\n\n  \n\n\n\nDisplaying such data in a table causes all the top-level data fields to repeat for every second-level record. You can see that course_id, course_name, start_date and end_date columns repeat for all students who enrolled in the same course. Take a moment to think about how would you display such data in an interactive table in a web page, HTML report or Shiny app.\nIt is advisable to split such denormalized data into normalized data i.e. create the original top-level and second level tables from the combined_df."
  },
  {
    "objectID": "posts/drilldown-with-reactable/index.html#vanilla-reactable",
    "href": "posts/drilldown-with-reactable/index.html#vanilla-reactable",
    "title": "Interactive Drill-down Tables using {reactable}",
    "section": "Vanilla reactable\n",
    "text": "Vanilla reactable\n\nOne of my favorite R packages is reactable. The default output creates a neat interactive table with pagination (if data has more than 10 rows) and ability to sort columns.\n\nCodelibrary(reactable, quietly = TRUE, warn.conflicts = FALSE)\n\nreactable(data = combined_df)"
  },
  {
    "objectID": "posts/drilldown-with-reactable/index.html#basic-formatting",
    "href": "posts/drilldown-with-reactable/index.html#basic-formatting",
    "title": "Interactive Drill-down Tables using {reactable}",
    "section": "Basic Formatting",
    "text": "Basic Formatting\nWith some additional tweaks, we can make it look better.\n\nCodereactable(\n  data       = combined_df,\n  compact    = TRUE, # for minimum row height\n  filterable = TRUE, # for individual column filters\n  striped    = TRUE, # banded rows\n  resizable  = TRUE, # for resizable column widths\n  columns    = list( # define custom header name, width, alignment etc.\n    course_id   = colDef(name = \"CID\",         width = 50,  align = \"center\"),\n    course_name = colDef(name = \"Course Name\", width = 140),\n    start_date  = colDef(name = \"Start Date\",  width = 120, align = \"center\"),\n    end_date    = colDef(name = \"End Date\",    width = 120, align = \"center\"),\n    s_id        = colDef(name = \"SID\",         width = 70,  align = \"center\"),\n    s_name      = colDef(name = \"Student Name\"),\n    gender      = colDef(name = \"Gender\",      width = 80,  align = \"center\"),\n    age         = colDef(name = \"Age\",         width = 50)\n  )\n)\n\n\n\n\n\nHowever, the problem of repeating top-level fields still persists."
  },
  {
    "objectID": "posts/drilldown-with-reactable/index.html#grouping-and-aggregating",
    "href": "posts/drilldown-with-reactable/index.html#grouping-and-aggregating",
    "title": "Interactive Drill-down Tables using {reactable}",
    "section": "Grouping and Aggregating",
    "text": "Grouping and Aggregating\nreactable has a groupBy argument which lets us combined rows with common data fields and the aggregate argument inside colDef lets us define what aggregation to be used for each column of the top-level data.\n\nCodereactable(\n  data       = combined_df,\n  compact    = TRUE, # for minimum row height\n  filterable = TRUE, # for individual column filters\n  striped    = TRUE, # banded rows\n  resizable  = TRUE, # for resizable column widths\n  groupBy    = \"course_id\",\n  columns    = list(\n    # show count of students in each course\n    course_id   = colDef(name = \"CID\",         width = 100,  align = \"left\",    aggregate = \"count\"),  \n    # show unique course name\n    course_name = colDef(name = \"Course Name\", width = 140,                     aggregate = \"unique\"), \n    # show unique start date\n    start_date  = colDef(name = \"Start Date\",  width = 120,  align = \"center\",  aggregate = \"unique\"), \n    # show unique end date\n    end_date    = colDef(name = \"End Date\",    width = 120,  align = \"center\",  aggregate = \"unique\"), \n    s_id        = colDef(name = \"SID\",         width = 70,   align = \"center\"),\n    s_name      = colDef(name = \"Student Name\"),\n    gender      = colDef(name = \"Gender\",      width = 80,   align = \"center\"),\n    age         = colDef(name = \"Age\",         width = 50)\n  )\n)\n\n\n\n\n\nIn this case, all the columns which are not aggregated remain hidden. Clicking the little triangle in the CID column displays the hidden rows. Looks better, but again, the issue of duplicated data remains.\nYou can aggregate the second-level columns too, but this distorts the table and frankly, looks ugly. Here I aggregate the SID column in addition to all the other top-level columns.\n\nCodereactable(\n  data       = combined_df,\n  compact    = TRUE, # for minimum row height\n  filterable = TRUE, # for individual column filters\n  striped    = TRUE, # banded rows\n  resizable  = TRUE, # for resizable column widths\n  groupBy    = \"course_id\",\n  columns    = list(\n    course_id   = colDef(name = \"CID\",         width = 100,  align = \"left\",    aggregate = \"count\"),\n    course_name = colDef(name = \"Course Name\", width = 140,                     aggregate = \"unique\"),\n    start_date  = colDef(name = \"Start Date\",  width = 120,  align = \"center\",  aggregate = \"unique\"),\n    end_date    = colDef(name = \"End Date\",    width = 120,  align = \"center\",  aggregate = \"unique\"),\n    # YIKES!! Aggregating Student ID to show unique ids in each course.\n    s_id        = colDef(name = \"SID\",         width = 70,   align = \"center\",  aggregate = \"unique\"), \n    s_name      = colDef(name = \"Student Name\"),\n    gender      = colDef(name = \"Gender\",      width = 80,   align = \"center\"),\n    age         = colDef(name = \"Age\",         width = 50)\n  )\n)\n\n\n\n\n\nWouldn’t it be nice if we could display only the top-level columns by default and on clicking the small triangle for a row, show all the second-level columns corresponding to that row only, like a drill-down table?\nTo do this we need 2 separate tables. Earlier in this post, I said it is advisable to split such denormalized data into normalized data i.e. create the original top-level and second level tables from the combined_df. Let’s recreate the 2 tables.\nI want to demonstrate how we go from the combined data to the 2 tables. Hence I will not use the course and student tables created earlier.\nCreating the top_level table using just the columns in course. Let’s also create a new column n_students depicting count of students in each course.\n\nCodetop_level &lt;- combined_df %&gt;% \n  # Only course info columns\n  count(course_id, course_name, start_date, end_date, name = \"n_students\") \n\npaged_table(top_level)\n\n\n  \n\n\n\n\nCodesecond_level &lt;- combined_df %&gt;% \n  # Only Student info columns with unique identifier for Course\n  select(course_id, s_id, s_name, gender, age) %&gt;% \n  arrange(s_id)\n\npaged_table(second_level)"
  },
  {
    "objectID": "posts/drilldown-with-reactable/index.html#the-final-drill-down-table",
    "href": "posts/drilldown-with-reactable/index.html#the-final-drill-down-table",
    "title": "Interactive Drill-down Tables using {reactable}",
    "section": "The final Drill-down Table",
    "text": "The final Drill-down Table\nNow that we have the 2 tables ready, let us now create the final reactable. The trick here is to use the details argument to which we pass another reactable of just the rows with students data corresponding to given course.\n\nCodereactable(\n  data       = top_level,\n  compact    = TRUE, # for minimum row height\n  filterable = TRUE, # for individual column filters\n  striped    = TRUE, # banded rows\n  resizable  = TRUE, # for resizable column widths\n  columns    = list(\n    course_id   = colDef(name = \"CID\",             width = 50,  align = \"center\"),\n    course_name = colDef(name = \"Course Name\"), \n    start_date  = colDef(name = \"Start Date\",      width = 120, align = \"center\"),\n    end_date    = colDef(name = \"End Date\",        width = 120, align = \"center\"),\n    n_students  = colDef(name = \"No. of Students\", width = 130, align = \"center\")\n  ),\n  details = function(index) { # index is the row number of current row.\n    # sub-table of only those students for current row.\n    sec_lvl = second_level[second_level$course_id == top_level$course_id[index], ] \n    reactable(data       = sec_lvl,\n              compact    = TRUE, \n              filterable = TRUE,\n              bordered   = TRUE, \n              resizable  = TRUE,\n              columns    = list(\n                course_id   = colDef(show = FALSE), # hide the course id column\n                s_id        = colDef(name = \"SID\",    width = 70, align = \"center\"),\n                s_name      = colDef(name = \"Student Name\"),\n                gender      = colDef(name = \"Gender\", width = 90, align = \"center\"),\n                age         = colDef(name = \"Age\",    width = 50, align = \"center\")\n              )\n              )\n  }\n)\n\n\n\n\n\nSince the sub-table is also a reactable, you can go another level down… and another, but please do consider the usability aspect of this feature before taking that decision. I haven’t tried going beyond 2 levels of data myself. Maybe a part 2 to this post??"
  },
  {
    "objectID": "posts/drilldown-with-reactable/index.html#conclusion",
    "href": "posts/drilldown-with-reactable/index.html#conclusion",
    "title": "Interactive Drill-down Tables using {reactable}",
    "section": "Conclusion",
    "text": "Conclusion\nDrill-down tables let you pack a lot of data in a compact manner and allow use by multiple audiences interested in varying degrees/levels of information. reactable can help create an interactive data table from tabular data with sorting and pagination by default. The data table is an HTML widget that can be used in R Markdown documents and Shiny applications, or viewed from an R console. A lot of features can be enabled/disabled using the basic arguments of the reactable() function and much more using custom JavaScript."
  },
  {
    "objectID": "posts/drilldown-with-reactable/index.html#references-citations",
    "href": "posts/drilldown-with-reactable/index.html#references-citations",
    "title": "Interactive Drill-down Tables using {reactable}",
    "section": "References & Citations",
    "text": "References & Citations\n\nGreg Lin (2020). reactable: Interactive Data Tables Based on ‘React Table’. R package version 0.2.3. https://CRAN.R-project.org/package=reactable"
  },
  {
    "objectID": "posts/python-list-comprehension/index.html",
    "href": "posts/python-list-comprehension/index.html",
    "title": "Python - List Comprehension",
    "section": "",
    "text": "Intro\nIn the world of Python, lists are the most versatile containers for managing data. While for loops offer a traditional approach to creating and manipulating lists, Python offers a more elegant and efficient alternative: list comprehensions. Let’s dive into this concise syntax and explore its advantages over traditional for loops.\n\n\nBasic Syntax\nList comprehensions pack a powerful punch in a compact syntax. They allow you to create lists in a single line, combining iteration and expression evaluation within square brackets. Here’s the most basic structure:\nnew_list = [expression for item in iterable]\nwhere\n\nexpression is the value or logic applied to each item, which will create the items of the new list\nitem is the variable that represents each element of the iterable\niterable is the variable over which we iterate or ‘loop’. This could be a list, tuple, dictionary, string or anything which can be considered an iterable in Python.\n\nThe equivalent for loop for the above operation is as follows:\nnew_list = []\nfor item in iterable:\n    new_list.append(expression)\nLet’s understand this with some working code. Suppose I have a list of numbers and I want a list that contains the same numbers multipled by 2 i.e. doubled.\n\n\nCode\nmy_nums = [1, 2, 3, 4, 5]\ndoubled_nums = [num*2 for num in my_nums]\n\n# Same operation using `for` loop\ndoubled_nums_for = []\nfor num in my_nums:\n  doubled_nums_for.append(num*2)\n\n\nprint(doubled_nums)\nprint(doubled_nums_for) # identical to `doubled_nums`\n\n\n[2, 4, 6, 8, 10]\n[2, 4, 6, 8, 10]\n\n\nIn the above Python code, my_nums is the iterable, the num variable in 2nd line represents each item in my_nums and num*2 is the expression or logic that we apply to each num.\nlet’s take one more example with a dictionary.\n\n\nCode\nmy_dict = {'Actor':'Tom', 'Director':'Tony', 'Writer':'Jim'}  \n# Bonus for guessing the movie!\n\n# new_list = [expression for item in iterable]\nroles = [role for role in my_dict.keys()]\npeople = [person for person in my_dict.values()]\n\nprint(roles)\nprint(people)\n\n\n['Actor', 'Director', 'Writer']\n['Tom', 'Tony', 'Jim']\n\n\nAs you can see, the item variable can be named anything as this variable is active only within the scope of the list comprehension.\n\n\nAdvanced Syntax: Filtering\nWe use the following syntax when we want to create a new list with items that satisfy some condition.\nfiltered_list = [expression for item in iterable if condition]\nwhere\n\ncondition is any logical expression that return True or False\n\nLet’s see an example. Suppose I have a list of sentences and I want to filtered list which has the word ‘whisper’ in them.\n\n\nCode\nsentence_list = [\n   \"Sunrise paints the clouds in fiery hues, a silent alarm\",\n   \"Raindrops pitter-patter on cobblestones, a playful melo\",\n   \"Ocean waves whisper secrets to the sandy shore, tales o\",\n   \"Owl's amber eyes pierce the moonlit forest, a silent gu\",\n   \"Butterfly wings, stained glass windows fluttering throu\",\n   \"Laughter spills from a cozy cafe window, a warm invitat\",\n   \"Cracked pavement whispers forgotten stories, echoes of \",\n   \"Starry sky, a canvas splashed with diamonds, whispers o\",\n   \"Spice-laden wind dances through the market, teasing the\",\n   \"Tiny snail embarks on a grand journey, a blade of grass\"\n]\n\n\nfiltered_list = [sen for sen in sentence_list if 'whisper' in sen]\n\n# Same operation using `for` loop\nfiltered_list_for = []\nfor sen in sentence_list:\n  if 'whisper' in sen:\n    filtered_list_for.append(sen)\n\n\nprint(filtered_list)\nprint(filtered_list_for) # identical to `filtered_list`\n\n\n['Ocean waves whisper secrets to the sandy shore, tales o', 'Cracked pavement whispers forgotten stories, echoes of ', 'Starry sky, a canvas splashed with diamonds, whispers o']\n['Ocean waves whisper secrets to the sandy shore, tales o', 'Cracked pavement whispers forgotten stories, echoes of ', 'Starry sky, a canvas splashed with diamonds, whispers o']\n\n\nIn the above code, the condition is 'whisper' in sen which returns True or False for every sen sentence.\nLet’s look at a more useful example. Here we create a JSON-formatted string using List Comprehension\n\n\nCode\nimport pandas as pd\nimport json\n\n# Sample DataFrame\ndata = {'name': ['Alice', 'Bob', 'Charlie'], \n        'age': [25, 30, 20], \n        'city': ['New York', 'London', 'Paris']\n        }\ndf = pd.DataFrame(data)\n\n# Convert DataFrame to JSON using list comprehension\njson_list = [row.to_json() for index, row in df.iterrows()]\n\n# Convert list to JSON and print\nfor json_string in json_list:\n  print(json.dumps(json.loads(json_string), indent=4))\n\n\n{\n    \"name\": \"Alice\",\n    \"age\": 25,\n    \"city\": \"New York\"\n}\n{\n    \"name\": \"Bob\",\n    \"age\": 30,\n    \"city\": \"London\"\n}\n{\n    \"name\": \"Charlie\",\n    \"age\": 20,\n    \"city\": \"Paris\"\n}\n\n\nHere’s what is happening in the code above.\n\nImport Libraries:\nimport pandas as pd: Imports the pandas library for working with DataFrames.\nimport json: Imports the json library for working with JSON data.\nCreate DataFrame:\ndata = {...}: Creates a dictionary containing data for three columns: ‘name’, ‘age’, and ‘city’.\ndf = pd.DataFrame(data): Creates a DataFrame df from the dictionary data.\nConvert DataFrame to JSON List:\njson_list = [row.to_json() for index, row in df.iterrows()]: This line uses list comprehension to convert each row of the DataFrame into a JSON string and stores them in a list called json_list.\niterrows() iterates over the DataFrame, yielding index and row pairs.\nrow.to_json() converts each row into a JSON string.\nPrint Pretty-Printed JSON:\nfor json_string in json_list:: This loop iterates over each JSON string in the json_list.\nprint(json.dumps(json.loads(json_string), indent=4)): This line prints the JSON string with proper indentation:\njson.loads(json_string) parses the JSON string into a Python dictionary.\njson.dumps() re-serializes the dictionary back into a JSON string, applying indentation for readability.\n\n\n\nAdvanced Syntax: If-Else\nThe If-Else syntax allows us to take one action if the item satisfies a condition and another action if it does not. The syntax is as follows:\nnew_list = [true_expr if condition else false_expr for item in iterable] \nwhere\n\ntrue_expr is the expression which is evaluated when the item satisfies the condition\nfalse_expr is the expression which is evaluated when the item does not satisfy the condition\n\nLet’s look at an example of this If-Else syntax. Suppose I have list of numbers with missing values. I want replace the missing values with the average value of the numbers.\n\n\nCode\nimport statistics\n\nnum_list = [10, 20, None, 40, None, 20, 10]\n\n# Filtering Syntax: Calculate mean with only the numbers which are not None\nmean = statistics.mean(num for num in num_list if num is not None)\nprint(f\"{mean=}\")\n\n# If-Else Syntax\nclean_list = [num if num is not None else mean for num in num_list]\n\n# This can also be written as\nclean_list2 = [mean if num is None else num for num in num_list]\n\n\n# Same operation using `for` loop\nclean_list_for = []\nfor num in num_list:\n  if num is None:\n    clean_list_for.append(mean)\n  else:\n    clean_list_for.append(num)\n\nprint(clean_list)\nprint(clean_list2)\nprint(clean_list_for) # Identical to `clean_list` and `clean_list2`\n\n\nmean=20\n[10, 20, 20, 40, 20, 20, 10]\n[10, 20, 20, 40, 20, 20, 10]\n[10, 20, 20, 40, 20, 20, 10]\n\n\n\n\nReal-world Usage\nI have personally encountered various scenarios in my data journey where I have come across List of Lists! List comprehension is a great way to quickly flatten list of lists in one line of code.\n\n\nCode\n# Create a list of lists containing strings\nwords = [[\"hello\", \"world\"], [\"how\", \"are\", \"you\"], [\"today\"]]\n\n# Nested Syntax\nflattened_words = [word for sublist in words for word in sublist]\n\n# Same Operation using `for` loop\nflattened_words_for = []\nfor sublist in words:\n  for word in sublist:\n    flattened_words_for.append(word)\n\nprint(flattened_words)\nprint(flattened_words_for) # Identical to `flattened_words`\n\n\n['hello', 'world', 'how', 'are', 'you', 'today']\n['hello', 'world', 'how', 'are', 'you', 'today']\n\n\n\n\nSo what’s best?\nList comprehensions are ideal when:\n\nCreating a new list based on an existing iterable.\nApplying simple transformations or filtering to elements.\nPrioritizing concise and readable code.\n\nFor loops are preferable when:\n\nPerforming complex operations within the loop.\nNeeding more control over the iteration process.\nRequiring side effects beyond list creation (e.g., printing, modifying variables).\n\n\n\nConclusion\nWhile list comprehensions offer a concise approach to list creation, for loops remain essential for broader iteration tasks in Python. For new developers, for loops are easier to understand and make far more sense than list comprehensions. They provide greater flexibility and control, allowing for complex operations, multiple statements within each iteration, and handling side effects (like printing, logging) that go beyond mere list creation. However, when the goal is straightforward list generation with simple transformations or filtering, list comprehensions often deliver a more elegant and efficient solution.\n\n\nReferences\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{katti2024,\n  author = {Katti, Vishal},\n  title = {Python - {List} {Comprehension}},\n  date = {2024-01-06},\n  url = {https://vishalkatti.com/posts/python-list-comprehension},\n  langid = {en},\n  abstract = {This post demonstrates Python’s List Comprehension\n    compared with the `for` loop and its usage.}\n}\nFor attribution, please cite this work as:\nKatti, Vishal. 2024. “Python - List Comprehension.” January\n6, 2024. https://vishalkatti.com/posts/python-list-comprehension."
  },
  {
    "objectID": "posts/R2VBA2PPT2/index.html",
    "href": "posts/R2VBA2PPT2/index.html",
    "title": "Unholy Trinity of R, Excel VBA and Powerpoint - Part 2 of 2",
    "section": "",
    "text": "This is part 2 of 2. Read part 1 here."
  },
  {
    "objectID": "posts/R2VBA2PPT2/index.html#quick-recap",
    "href": "posts/R2VBA2PPT2/index.html#quick-recap",
    "title": "Unholy Trinity of R, Excel VBA and Powerpoint - Part 2 of 2",
    "section": "Quick Recap",
    "text": "Quick Recap\nIn the previous post, we create the .potx template from the .pptx file we wanted to automate and the Excel template with the macro .xlsm that uses the PowerPoint template to create a new .pptx file with given data using VBA.\nThe report we want to automate is…\n\n\n\n\n\n\nFigure 1: The Gapminder Report : The PowerPoint presentation we want to automate\n\n\n\n…and the Excel and PowerPoint template we created are shown in Figure 2.\n\n\n\n\n\n\nFigure 2: Excel Template with VBA macro\n\n\n\nIn this post, we will write the R script that will first massage the data into desired format and then load the data for one region into the Excel template and execute the VBA macro that will create the PowerPoint file with that data."
  },
  {
    "objectID": "posts/R2VBA2PPT2/index.html#strategy",
    "href": "posts/R2VBA2PPT2/index.html#strategy",
    "title": "Unholy Trinity of R, Excel VBA and Powerpoint - Part 2 of 2",
    "section": "Strategy",
    "text": "Strategy\nBefore we dive into code, we need to check a few things. We wish to create a presentation for each continent in the Gapminder data. A closer look at the Presentation will tell you what kind of data we need for each slide/graph/table while the Excel template will reveal what should the structure of each dataset should be. While looking into this structure, some questions will pop-up. The idea here is to create the datasets in such a way that they can be easily filtered for each continent and the resultant table can be written to the Excel template without any or very little modification. Let us proceed slide-by-slide."
  },
  {
    "objectID": "posts/R2VBA2PPT2/index.html#creating-the-datasets",
    "href": "posts/R2VBA2PPT2/index.html#creating-the-datasets",
    "title": "Unholy Trinity of R, Excel VBA and Powerpoint - Part 2 of 2",
    "section": "Creating the datasets",
    "text": "Creating the datasets\nSlide 1\nSlide 1 is the title page and needs 2 strings; one for Title, one for Subtitle. The Title for the base presentation is “World Population”. For each continent, it could be “&lt;continent_name&gt; Population”. The subtitle is a combination of Author Name and Created Date. So we need a string like “&lt;author_name&gt; | &lt;created_date&gt;” where created_date is the formatted system date.\nThese strings can be created while writing the data to the Excel template.\nSlide 2\nThe chart on slide 2 needs raw data structured as below. You will notice that at a continent-level, this table needs a minimum of 5 countries. Do we have any continents in the Gapminder data with less than 5 countries? Yes, we have Oceania with only Australia and New Zealand. For ease of use, let us include these countries along with Asian countries in a new Region variable.\n\n\n\n\n\n\nFigure 3: 02_chart\n\n\n\nWe will create the region variable in the gapminder data. But first, let us load some relevant packages.\n\nCodeoptions(tidyverse.quiet = TRUE)\nlibrary(tidyverse) # duh!\nlibrary(rmarkdown) # to display the tables interactively in this post. Not really needed for the final solution.\nlibrary(openxlsx) # to write the data to the Excel Template.\n# library(RDCOMClient) # to load and run the Excel macro post data load.\n\n\n\nCode# Read in Gapminder data\ngp &lt;- gapminder::gapminder\n\n# Create new region variable\ngp &lt;- gp %&gt;%\n  mutate(region = if_else(as.character(continent) %in% c(\"Asia\",\"Oceania\"),\n                          \"Asia-Pacific\", \n                          as.character(continent)),\n         country = as.character(country))\n\n# Keep only relevant columns\ngp &lt;- gp %&gt;% select(region, country, year, pop)\n\n# View details\nglimpse(gp)\n\nRows: 1,704\nColumns: 4\n$ region  &lt;chr&gt; \"Asia-Pacific\", \"Asia-Pacific\", \"Asia-Pacific\", \"Asia-Pacific\"~\n$ country &lt;chr&gt; \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"A~\n$ year    &lt;int&gt; 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 20~\n$ pop     &lt;int&gt; 8425333, 9240934, 10267083, 11537966, 13079460, 14880372, 1288~\n\n\nNow that we have the source data available, we must now create the datasets we need that we can write to the Excel template for each region.\nThe required table in Figure 3 shows the top 4 countries (based on 2007 population) and all other countries clubbed into ‘others’ in a given region and then the total population of the region on a yearly basis. This table has to be created for all 4 regions.\n\nCodepop_trend &lt;- gp %&gt;%\n  group_by(region, country, year) %&gt;% \n  summarise(pop = sum(pop, na.rm = TRUE),\n            .groups = 'drop') %&gt;%\n  mutate(pop = round(pop/1E6, 0)) %&gt;% # population in millions\n  pivot_wider(names_from = year, values_from = pop, names_sort = TRUE) %&gt;% \n  arrange(desc(`2007`)) # sort by max pop to min pop in latest year i.e. 2007\n\npaged_table(pop_trend)\n\n\n  \n\n\n\nNow that we have the required columns, let’s plan the row order. We notice that, for each region, we have the top 4 countries (as per 2007) , followed by ‘Others’. Let’s create the top-4 dataset.\n\nCodetop4 &lt;- pop_trend %&gt;% \n  group_by(region) %&gt;% \n  slice_max(`2007`, n = 4, with_ties = FALSE) %&gt;% \n  ungroup()\n\npaged_table(top4)\n\n\n  \n\n\n\nTo create the others dataset, we exclude all countries that are present in the top-4.\n\nCodeothers &lt;- pop_trend %&gt;% \n  filter(!country %in% top4$country) %&gt;% \n  group_by(region) %&gt;% \n  summarise(across(.cols = -country, .fns = sum),\n            .groups = 'drop') %&gt;% \n  mutate(country = \"Others\") %&gt;% \n  select(region, country, everything())\n\npaged_table(others)\n\n\n  \n\n\n\nWhile we create the top-4 and others datasets separately, we will combine them later at the very last moment before writing them to the Excel template.\nNow that we have the datasets needed for 02_chart, let’s proceed to the create 02_table . This table gives you the count of countries that fall under various population ranges.\n\n\n\n\n\n\nFigure 4: 02_table on Slide 2\n\n\n\nLet’s create 02_table. To create this table, we first create a new variable called pop_range.\n\nCodepop_levels &lt;- c('Less than 500K','500K - 1 Million',\n                '1M - 10 Million', '10M - 100 Million',\n                '100M - 1 Billion', 'More than 1 Billion')\n\ngp2007 &lt;- gp %&gt;% \n  filter(year == 2007) %&gt;% \n  mutate(pop_range = case_when(pop &lt; 5E5 ~ pop_levels[1],\n                               pop &lt; 1E6 ~ pop_levels[2],\n                               pop &lt; 1E7 ~ pop_levels[3],\n                               pop &lt; 1E8 ~ pop_levels[4],\n                               pop &lt; 1E9 ~ pop_levels[5],\n                               TRUE      ~ pop_levels[6]),\n         pop_range = factor(pop_range, levels = pop_levels))\n\npop_groups &lt;- gp2007 %&gt;% \n  group_by(region, pop_range, .drop = FALSE) %&gt;% \n  summarise(`# of Countries` = n(),\n            .groups = 'drop') %&gt;% \n  arrange(region, pop_range) %&gt;% \n  rename(`Population Category` = pop_range)\n\npaged_table(pop_groups)\n\n\n  \n\n\n\nSlide 3\nSlide 3 contains 2 strings and one chart. The data for the chart looks as shown below.\n\n\n\n\n\n\nFigure 5: 03_chart table for Slide 3\n\n\n\nThe data for 03_chart is the list of top 10 countries in each region as per latest record i.e. 2007. Let’s create the top10 table.\n\nCodetop10 &lt;- gp %&gt;% \n  filter(year == 2007) %&gt;% \n  group_by(region) %&gt;% \n  slice_max(pop, n = 10, with_ties = FALSE) %&gt;% \n  ungroup() %&gt;% \n  select(-year) %&gt;% \n  mutate(pop = round(pop/1E6, 4)) %&gt;% # population in millions\n  set_names(c(\"region\",\"country\",\"population\"))\n\npaged_table(top10)"
  },
  {
    "objectID": "posts/R2VBA2PPT2/index.html#the-for-loop",
    "href": "posts/R2VBA2PPT2/index.html#the-for-loop",
    "title": "Unholy Trinity of R, Excel VBA and Powerpoint - Part 2 of 2",
    "section": "The for loop!",
    "text": "The for loop!\nWe now have to load the Excel template with the data at appropriate cell locations for one region at a time. Since we have about 4 regions, we will create a vector of unique regions to iterate over.\n\nCodeunique_regions &lt;- gp %&gt;% distinct(region) %&gt;% pull()\ncat(unique_regions, sep = \"\\n\")\n\nAsia-Pacific\nEurope\nAfrica\nAmericas\n\n\nAs our last step, we will create the for loop that will iterate over unique_regions , filter the datasets for each region, write them to the Excel Template, save the template with temporary name. We save the file with different name to prevent unintentionally corrupting the Excel macro template. Finally, we run the macro in the renamed file.\nThe code will look something like this\n\nCodefor (region in unique_regions) {\n  \n  # Step 1: filter the data sets\n  # Step 2: write the data sets\n  # Step 3: save the excel template with different name\n  # Step 4: load the renamed Excel file\n  # Step 5: run macro\n}\n\n\nLet’s populate the above for loop with the code we need.\n\nCodefor (curr_region in unique_regions) {\n  \n  # Step 1: filter the data sets\n  \n  # Slide 1\n  S1_title &lt;- paste(curr_region, \"Population\")\n  S1_subtitle &lt;- paste(\"Vishal Katti\",\"|\",format(Sys.Date(),\"%b %d, %Y\"), sep = \"   \")\n  \n  # Slide 2\n  S2_title &lt;- paste(curr_region, \"Population since 1952\")\n  \n  S2_top4 &lt;- top4        %&gt;% filter(region == all_of(curr_region)) %&gt;% select(-region) %&gt;% arrange(desc(`2007`))\n  S2_others &lt;- others    %&gt;% filter(region == all_of(curr_region)) %&gt;% select(-region)\n  S2_top5 &lt;- bind_rows(S2_top4, S2_others)\n  \n  S2_table &lt;- pop_groups %&gt;% filter(region == all_of(curr_region)) %&gt;% select(-region)\n  \n  # Slide 3\n  S3_title &lt;- paste(\"Top 10 most populated countries in\", curr_region)\n  \n  S3_chart &lt;- top10      %&gt;% filter(region == all_of(curr_region)) %&gt;% select(-region)\n  \n  S3_factoid &lt;- paste(\"The population of\", S3_chart$country[1], \"is approx.\",\n                      round(S3_chart$population[1]/S3_chart$population[10], 0),\n                      \"times that of\", S3_chart$country[10])\n  \n  # Step 2: write the data sets\n  \n  # Load the template\n  wb &lt;- loadWorkbook(\"path/to/template/XL2PPT.xlsm\") # relative to this R script\n  sht &lt;- \"Sheet1\"\n  \n  # write data to coordinate (col, row)\n  writeData(wb, sht, S1_title,    xy = c(3, 3),  colNames = FALSE)\n  writeData(wb, sht, S1_subtitle, xy = c(3, 4),  colNames = FALSE)\n  writeData(wb, sht, S2_title,    xy = c(3, 7),  colNames = FALSE)\n  writeData(wb, sht, S2_top5,     xy = c(3, 9),  colNames = TRUE)\n  writeData(wb, sht, S2_table,    xy = c(18, 9), colNames = TRUE)\n  writeData(wb, sht, S3_title,    xy = c(3, 18), colNames = FALSE)\n  writeData(wb, sht, S3_factoid,  xy = c(3, 19), colNames = FALSE)\n  writeData(wb, sht, S3_chart,    xy = c(3, 21), colNames = TRUE)\n  \n  # Step 3: save the excel template with different name\n  saveWorkbook(wb, \"path/to/template/XL2PPT_edited.xlsm\", overwrite = TRUE)\n  gc(verbose = TRUE)\n  Sys.sleep(2)\n  \n  # Step 4: load the renamed Excel file\n  # Create Excel Application\n  xlApp &lt;- COMCreate(\"Excel.Application\")\n\n  # Open the Macro Excel book\n  xlWbk &lt;- xlApp$Workbooks()$Open(normalizePath(\"path/to/template/XL2PPT_edited.xlsm\", winslash = \"/\")) # Change to your directory\n  # its ok to run macro without visible excel application\n  # If you want to see your workbook, please set it to TRUE\n  xlApp[[\"Visible\"]] &lt;- FALSE\n  \n  # Step 5: run macro\n  xlApp$Run(\"Create_Continental_Deck\") # Name of Macro to run\n\n  xlWbk$Close(TRUE) # save and close excel book\n  xlApp$Quit()\n  gc(verbose = TRUE)\n  Sys.sleep(2)\n}\n\n\nOnce the code runs completely, you will see 4 new PowerPoint Presentations in your working folder.\n\n\n\n\n\n\nFigure 6: Output Files\n\n\n\nYou can download the full R script from here."
  },
  {
    "objectID": "posts/R2VBA2PPT2/index.html#references-citations",
    "href": "posts/R2VBA2PPT2/index.html#references-citations",
    "title": "Unholy Trinity of R, Excel VBA and Powerpoint - Part 2 of 2",
    "section": "References & Citations",
    "text": "References & Citations\n\nJennifer Bryan (2017). gapminder: Data from Gapminder. R package version 0.3.0. https://CRAN.R-project.org/package=gapminder\nHadley Wickham, Romain Francois, Lionel Henry and Kirill Muller (2021). dplyr: A Grammar of Data Manipulation. R package version 1.0.7. https://CRAN.R-project.org/package=dplyr\nHadley Wickham (2021). tidyr: Tidy Messy Data. R package version 1.1.3. https://CRAN.R-project.org/package=tidyr\nGreg Lin (2020). reactable: Interactive Data Tables Based on ‘React Table’. R package version 0.2.3. https://CRAN.R-project.org/package=reactable\nPhilipp Schauberger and Alexander Walker (2021). openxlsx: Read, Write and Edit xlsx Files. R package version 4.2.4. https://CRAN.R-project.org/package=openxlsx\nDuncan Temple Lang (NA). RDCOMClient: R-DCOM client. http://www.omegahat.net/RDCOMClient, http://www.omegahat.net http://www.omegahat.net/bugs.\nhttps://docs.microsoft.com/en-us/office/vba/api/overview/excel\nhttps://docs.microsoft.com/en-us/office/vba/api/overview/powerpoint"
  },
  {
    "objectID": "posts/tidyr-pivot-wider/index.html",
    "href": "posts/tidyr-pivot-wider/index.html",
    "title": "Pivoting your tables with Tidyr: Part II",
    "section": "",
    "text": "Intro\nWe discussed the advantages of using the long format during data analysis, most users feel that the wide format is more readable by human. This is why most reports tend to have the data arranged in the wide format.\nThe wide format has at least one column which acts as a primary key i.e. it is unique and each value appears only once. It can also have multiple column whose unique combination acts as a primary key i.e. each combination appears only once.\nRead more about wide vs. long formats here.\nWhile the long format is preferred and is desirable for data and plotting operations using R, Python or other data processing programming languages, the wide format is more human-readable. The {tidyr} R package has functions that allow you to transform your tabular data between the two formats.\nIn this post, we will see how to convert a long dataframe to wide format using the pivot_wider() function from {tidyr} package.\nThe long one\nConsider the following data table. It has been created from the famous Gapminder dataset. This table shows the average life expectancy in each continent for 2 years. While some of you may say that Gapminder data contains records for a lot more number of years, here we consider just the latest 2 years for ease of explanation and visual purposes. We have added an extra id column for teaching purpose.\n\n\n\n\n\n\nFigure 1: Continent-wise Average Life-expectancy over last 2 years, in Long format\n\n\n\nmy_data is in the long format as we have continent names and year in their own column and average life expectancy values for each unique combination of year and continent. If we want to compare life expectancy across years for each continent, we need to have the life expectancy values for each continent side-by-side for easier viewing i.e. we need to convert to the wide format. To convert this tibble to the wide format, we need to push the year values into the headers and the average_life_expectancy values under the corresponding year column.\nThe wide one\nThe wide format of this table would ideally have only continent and columns having each unique value in the year column as a header. In this case, the wide one would look something like the table below.\n\n\n\n\n\n\nFigure 2: Same as Figure 1 but in Wide format\n\n\n\nThe wide format has unique values of the column that are not pushed into headers. In this case, the continent column becomes unique for each row.\nLet’s recreate the above transformation in R. First, we create the my_data table.\n\nCodemy_data &lt;- data.frame(\n  id = 1:10,\n  year = c(2002L, 2002L, 2002L, 2002L, 2002L, 2007L, 2007L, 2007L, 2007L, 2007L),\n  continent = c(\"Africa\", \"Americas\", \"Asia\", \"Europe\", \"Oceania\", \"Africa\", \n                \"Americas\", \"Asia\", \"Europe\", \"Oceania\"),\n  average_life_expectancy = c(53.33, 72.42, 69.23, 76.7, 79.74, 54.81, 73.61, 70.73, 77.65, 80.72)\n)\n\nknitr::kable(my_data)\n\n\n\nid\nyear\ncontinent\naverage_life_expectancy\n\n\n\n1\n2002\nAfrica\n53.33\n\n\n2\n2002\nAmericas\n72.42\n\n\n3\n2002\nAsia\n69.23\n\n\n4\n2002\nEurope\n76.70\n\n\n5\n2002\nOceania\n79.74\n\n\n6\n2007\nAfrica\n54.81\n\n\n7\n2007\nAmericas\n73.61\n\n\n8\n2007\nAsia\n70.73\n\n\n9\n2007\nEurope\n77.65\n\n\n10\n2007\nOceania\n80.72\n\n\n\n\n\nTo convert this table into wide format, we use the pivot_wider() function from {tidyr} R package. Let us see how to use this function.\n\n\n\n\n\n\nTip\n\n\n\nUse formals to view all the formal arguments of a function and their default values. formals returns a named list.\n\n\n\nCodelibrary(tidyr, quietly = TRUE, warn.conflicts = FALSE)\n\nformals(pivot_wider)\n\n$data\n\n\n$id_cols\nNULL\n\n$id_expand\n[1] FALSE\n\n$names_from\nname\n\n$names_prefix\n[1] \"\"\n\n$names_sep\n[1] \"_\"\n\n$names_glue\nNULL\n\n$names_sort\n[1] FALSE\n\n$names_vary\n[1] \"fastest\"\n\n$names_expand\n[1] FALSE\n\n$names_repair\n[1] \"check_unique\"\n\n$values_from\nvalue\n\n$values_fill\nNULL\n\n$values_fn\nNULL\n\n$unused_fn\nNULL\n\n$...\n\n\nThe result of formals(pivot_wider) tells us that the minimum information needed to use this function is to provide values to the data,names_from and values_from arguments as all other arguments have default values and hence, are optional.\nUsing only the minimum arguments with pivot_wider(), we get a wide formatted tibble but with missing data!\n\nCodewide_minimal &lt;- pivot_wider(\n                        data        = my_data,\n                        names_from  = year,\n                        values_from = average_life_expectancy\n                        )\n\nknitr::kable(wide_minimal)\n\n\n\nid\ncontinent\n2002\n2007\n\n\n\n1\nAfrica\n53.33\nNA\n\n\n2\nAmericas\n72.42\nNA\n\n\n3\nAsia\n69.23\nNA\n\n\n4\nEurope\n76.70\nNA\n\n\n5\nOceania\n79.74\nNA\n\n\n6\nAfrica\nNA\n54.81\n\n\n7\nAmericas\nNA\n73.61\n\n\n8\nAsia\nNA\n70.73\n\n\n9\nEurope\nNA\n77.65\n\n\n10\nOceania\nNA\n80.72\n\n\n\n\n\nSo why did NAs appear in the result?\npivot_wider() creates unique combinations of all columns not included in names_from or values_from argument. Therefore, if your dataframe/tibble had a primary key prior to the transformation, the primary key of your transformed “wide” dataframe is your old primary key + unique combinations of all columns not included in names_from or values_from argument. We do have id column as a primary key in the original tibble. This gives an unusable output with NAs for each combination.\nTo specify which column/s to be made unique, pass their name to the id_cols argument. Here we pass the continent column to the id_cols argument.\n\nCodemy_data_longer &lt;- pivot_wider(\n                        data        = my_data,\n                        id_cols     = continent, \n                        names_from  = year,\n                        values_from = average_life_expectancy\n                        )\n\nknitr::kable(my_data_longer)\n\n\n\ncontinent\n2002\n2007\n\n\n\nAfrica\n53.33\n54.81\n\n\nAmericas\n72.42\n73.61\n\n\nAsia\n69.23\n70.73\n\n\nEurope\n76.70\n77.65\n\n\nOceania\n79.74\n80.72\n\n\n\n\n\nIf you are a visual person like me and wish to see this transformation with explanations, check out this GIF I made using good ol’ PowerPoint.\n\n\n\n{tidyr} pivot_wider() explained\n\n\nConclusion\npivot_wider() is the successor for the great spread() function and has many advantages over the latter. This function has many other arguments that allow some truly great transformations. Mastering this function (and its long counterpart) is a great skill upgrade while massaging your data to make it “tidy”.\nHappy Spreading!\nReferences\n\nLong vs. Wide Data: What’s the Difference?\nHadley Wickham and Maximilian Girlich (2022). tidyr: Tidy Messy Data. R package version 1.2.0. https://CRAN.R-project.org/package=tidyr\n\nYihui Xie (2022). knitr: A General-Purpose Package for Dynamic Report Generation in R. R package version 1.39.\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{katti2022,\n  author = {Katti, Vishal},\n  title = {Pivoting Your Tables with {Tidyr:} {Part} {II}},\n  date = {2022-08-29},\n  url = {https://vishalkatti.com/posts/tidyr-pivot-wider},\n  langid = {en},\n  abstract = {This post demonstrates how to use `pivot\\_wider()` to\n    convert your long data to wide data. This is part 2 of the Pivoting\n    your tables with Tidyr series.}\n}\nFor attribution, please cite this work as:\nKatti, Vishal. 2022. “Pivoting Your Tables with Tidyr: Part\nII.” August 29, 2022. https://vishalkatti.com/posts/tidyr-pivot-wider."
  },
  {
    "objectID": "courses/essential-it-skills-for-everyone/index.html",
    "href": "courses/essential-it-skills-for-everyone/index.html",
    "title": "Essential IT Skills for Everyone",
    "section": "",
    "text": "Learn to effectively use Excel, PowerPoint and Word to zoom past your peers!\nIt doesn’t matter if you are an under-graduate or working professional.\nIt doesn’t matter if you are in an IT or a Non-IT profession.\nIt doesn’t matter if you are a businessperson or working professional.\nIt doesn’t matter if you know nothing about Excel, PowerPoint or Word.\nBy the end of this course, you will understand how to leverage these tools to effectively bump up your productivity, and save hours of precious time for yourself.\n\n\nBut Why these tools?\n\n\n\nWhy Should You Take This Course?\n❓There are many online courses on Udemy, Coursera etc, which probably cost almost the same or even less than this course. Then why should you take this course❓\n\n\n\n\n\n\n\n\nTopic\nOther Online Courses\nEssential IT Skills for Everyone\n\n\n\n\nMode of Instruction\n💢 Recorded Videos\n✅ Live and Online\n\n\nInteraction with Instructor\n💢 Minimal or None. No scope to get real-time answers to specific problems\n✅ Full Fledged Video Interaction with real-time answers addressing your specific questions\n\n\nInteraction with other participants\n💢 Limited or through comments only or self-learning only.\n✅ Batch-wise WhatsApp group for collaborative learning and sharing of experiences\n\n\nLanguage of Instruction\n💢 Single Language (usually English)\n✅ Multi-lingual (English, Hindi, Marathi and/or Kannada)\n\n\nCourse Content\n💢 Fixed and sometimes outdated!\n✅ Latest Features and techniques, syllabus gets updated with every new feature launched for Excel, PowerPoint or Word\n\n\nBest Practices\n💢 Minimal or non-existent\n✅ Special attention to inculcate industry-approved best practices at every step\n\n\nIndividual Attention\n💢 Minimal\n✅ Guaranteed Individual attention due to small batch size (20 pax only)\n\n\nHelpful Add-ins and AI Tools\n💢 Minimal\n✅ Curated list of Add-Ins and AI Tools for enhanced learning and Productivity\n\n\nCareer Guidance\n💢 Non Existent\n✅ Individual advice for all participants\n\n\n\nThis course aims to establish a strong foundation in Excel, PowerPoint and Word along with Industry-certified best practices and helpful AI tools. This course will also ignite your brain with ideas about report automation and documentation.\n\nAwesome! Sign me up! –&gt;\n\n\n\nWhat will you get?\n🎓 Expert-Curated Curriculum\n🚀 LIVE Webinar with Hands-On Experience with Labs.\n💬 Multilingual Interaction (English, Hindi, Marathi, and Kannada)\n🌟 Personalized Attention (only 10 seats per batch)\n💡 1-on-1 support via WhatsApp during office-hours (T&C Apply)\n😎 AI Tools and Bonus Resources\n\n\nWhen does this course happen?\nThis course is conducted in the first full-week of every month.\n\n\nRegister Now!\nClick here (https://rzp.io/l/EITS4E) to register and to secure your spot.\nPlease share in other groups too. 🙏🏼"
  }
]