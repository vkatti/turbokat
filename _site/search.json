[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Vishal Katti",
    "section": "",
    "text": "Vishal Katti resides in Bengaluru, India with his wife and 4yo daughter, but constantly longs for the sun and sands of Goa üåûüèñÔ∏èüå¥ where he spent most of his childhood."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Vishal Katti",
    "section": "Education",
    "text": "Education\nDr.¬†B. R. Ambedkar National Institute of Technology (NIT) Jalandhar, Punjab, India\nBachelor of Technology in Instrumentation & Control Engineering | Aug 2005 - Apr 2010\n\nSmt. Parvatibai Chowgule College of Arts & Science Margao, Goa, India\nH.S.S.C. in Physics, Chemistry and Mathematics | Jun 2003 - Apr 2005"
  },
  {
    "objectID": "about.html#work",
    "href": "about.html#work",
    "title": "Vishal Katti",
    "section": "Work",
    "text": "Work\nMindtree Ltd. Bengaluru, India\nBusiness Data Analyst | Sep 2021 to Present\nExxonMobil Services & Technology Pvt. Ltd. Bengaluru, India\nBusiness Analytics Advisor | Jun 2018 - Aug 2021\nTata Consultancy Services Mumbai, India\nFunctional Consultant/Data Analyst | Sep 2010 - Jun 2018"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Katti‚Äôs Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n\n\n\n\n  \n\n\n\n\n\nConverting ‚Äúlong‚Äù to ‚Äúwide‚Äù format\n\n\n\n\nR\n\n\nfunctions\n\n\ntidyr\n\n\npivot\n\n\n\n\nThis post demonstrates how to use pivot_wider() to convert your long data to wide data. This is part 2 of the Pivoting your tables with Tidyr series.\n\n\n\n\n\n\nAug 29, 2022\n\n\nVishal Katti\n\n\n\n\n\n\n  \n\n\n\n\n\nConverting ‚Äúwide‚Äù to ‚Äúlong‚Äù format\n\n\n\n\nR\n\n\nfunctions\n\n\ntidyr\n\n\npivot\n\n\n\n\nThis post demonstrates how to use pivot_longer() to convert your wide data to long data. This is part 1 of the Pivoting your tables with Tidyr series.\n\n\n\n\n\n\nJul 8, 2022\n\n\nVishal Katti\n\n\n\n\n\n\n  \n\n\n\n\n\nSome designs to validate function arguments.\n\n\n\n\nR\n\n\nfunctions\n\n\n\n\nThis post demonstrates some techniques to make your R user-defined functions unbreakable (well, almost!) by checking if function arguments are missing, incorrect data type or just down-right invalid values and how to return meaningful error messages.\n\n\n\n\n\n\nJan 18, 2022\n\n\nVishal Katti\n\n\n\n\n\n\n  \n\n\n\n\n\nUsing R to trigger Excel VBA macros to create PowerPoint presentations\n\n\n\n\nR\n\n\nExcel\n\n\nVBA\n\n\nPowerPoint\n\n\nopenxlsx\n\n\nRDCOMClient\n\n\n\n\nThis post demonstrates how to run VBA macros in Excel which in turn creates Presentations based off PowerPoint Templates.\n\n\n\n\n\n\nDec 29, 2021\n\n\nVishal Katti\n\n\n\n\n\n\n  \n\n\n\n\n\nUsing R to trigger Excel VBA macros to create PowerPoint presentations!\n\n\n\n\nR\n\n\nExcel\n\n\nVBA\n\n\nPowerPoint\n\n\n\n\nThis post demonstrates how to create a PowerPoint template based off your custom/corporate Presentation/Report and VBA-enabled Excel file that would populate the report.\n\n\n\n\n\n\nOct 19, 2021\n\n\nVishal Katti\n\n\n\n\n\n\n  \n\n\n\n\n\nHow to create multi-level tables with hidden rows\n\n\n\n\nR\n\n\nreactable\n\n\ndrill-down\n\n\n\n\nThis post demonstrates how to use the {reactable} package to create multi-level drill-down tables having hidden rows\n\n\n\n\n\n\nJul 27, 2021\n\n\nVishal Katti\n\n\n\n\n\n\n  \n\n\n\n\n\nHow to create your own functions using {dplyr}\n\n\n\n\nR\n\n\ndplyr\n\n\nfunctions\n\n\n\n\nThis post demonstrates how to write your own dynamic functions using popular dplyr verbs like select(), filter(), mutate(), arrange() and group_by() with summarise().\n\n\n\n\n\n\nJul 17, 2021\n\n\nVishal Katti\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/drilldown-with-reactable/index.html",
    "href": "posts/drilldown-with-reactable/index.html",
    "title": "Interactive Drill-down Tables using {reactable}",
    "section": "",
    "text": "We often come across denormalized data that has 2 or more levels of information. For example, top-level info like course info with data fields like course id, course name, description, start/end date and second-level info like student info with data fields like with student id, student name, age and gender. We may also have these two groups of data as separate tables with a primary-key foreign-key design, usually from a well-designed SQL database.\nLet us create some data."
  },
  {
    "objectID": "posts/drilldown-with-reactable/index.html#top-level-data-course",
    "href": "posts/drilldown-with-reactable/index.html#top-level-data-course",
    "title": "Interactive Drill-down Tables using {reactable}",
    "section": "Top-Level data: course\n",
    "text": "Top-Level data: course\n\n\nCodelibrary(dplyr, quietly = TRUE, warn.conflicts = FALSE)\nlibrary(rmarkdown, quietly = TRUE, warn.conflicts = FALSE)\n\ncourse <- tibble(course_id   = 1:4,\n                 course_name = paste(\"Course\", LETTERS[1:4]),\n                 start_date  = seq.Date(from = lubridate::as_date(\"2021-01-01\"), by = \"month\", length.out = 4),\n                 end_date    = lubridate::ceiling_date(start_date, unit = \"month\") - 1)\n\npaged_table(course)"
  },
  {
    "objectID": "posts/drilldown-with-reactable/index.html#second-level-data-student",
    "href": "posts/drilldown-with-reactable/index.html#second-level-data-student",
    "title": "Interactive Drill-down Tables using {reactable}",
    "section": "Second Level Data: student\n",
    "text": "Second Level Data: student\n\n\nCodeset.seed(42)\nstudent <- tibble(s_id      = 1:20,\n                  s_name    = paste(\"Student\", LETTERS[1:20]),\n                  gender    = sample(c(\"X\",\"Y\",\"Z\"), 20, replace = TRUE),\n                  age       = sample(18:35, 20, replace = TRUE),\n                  course_id = sample(1:4, 20, replace = TRUE))\n\npaged_table(student)\n\n\n\n  \n\n\n\nIf we are sourcing data from a database, it is probable that you would see these 2 levels of data in 2 separate tables/views, but most business users are comfortable with MS Excel and want all the data in one sheet!!\nSo the data actually looks something like this.\n\nCodecombined_df <- left_join(course, student, by = \"course_id\")\n\npaged_table(combined_df)\n\n\n\n  \n\n\n\nDisplaying such data in a table causes all the top-level data fields to repeat for every second-level record. You can see that course_id, course_name, start_date and end_date columns repeat for all students who enrolled in the same course. Take a moment to think about how would you display such data in an interactive table in a web page, HTML report or Shiny app.\nIt is advisable to split such denormalized data into normalized data i.e.¬†create the original top-level and second level tables from the combined_df."
  },
  {
    "objectID": "posts/drilldown-with-reactable/index.html#vanilla-reactable",
    "href": "posts/drilldown-with-reactable/index.html#vanilla-reactable",
    "title": "Interactive Drill-down Tables using {reactable}",
    "section": "Vanilla reactable\n",
    "text": "Vanilla reactable\n\nOne of my favorite R packages is reactable. The default output creates a neat interactive table with pagination (if data has more than 10 rows) and ability to sort columns.\n\nCodelibrary(reactable, quietly = TRUE, warn.conflicts = FALSE)\n\nreactable(data = combined_df)"
  },
  {
    "objectID": "posts/drilldown-with-reactable/index.html#basic-formatting",
    "href": "posts/drilldown-with-reactable/index.html#basic-formatting",
    "title": "Interactive Drill-down Tables using {reactable}",
    "section": "Basic Formatting",
    "text": "Basic Formatting\nWith some additional tweaks, we can make it look better.\n\nCodereactable(\n  data       = combined_df,\n  compact    = TRUE, # for minimum row height\n  filterable = TRUE, # for individual column filters\n  striped    = TRUE, # banded rows\n  resizable  = TRUE, # for resizable column widths\n  columns    = list( # define custom header name, width, alignment etc.\n    course_id   = colDef(name = \"CID\",         width = 50,  align = \"center\"),\n    course_name = colDef(name = \"Course Name\", width = 140),\n    start_date  = colDef(name = \"Start Date\",  width = 120, align = \"center\"),\n    end_date    = colDef(name = \"End Date\",    width = 120, align = \"center\"),\n    s_id        = colDef(name = \"SID\",         width = 70,  align = \"center\"),\n    s_name      = colDef(name = \"Student Name\"),\n    gender      = colDef(name = \"Gender\",      width = 80,  align = \"center\"),\n    age         = colDef(name = \"Age\",         width = 50)\n  )\n)\n\n\n\n\n\n\nHowever, the problem of repeating top-level fields still persists."
  },
  {
    "objectID": "posts/drilldown-with-reactable/index.html#grouping-and-aggregating",
    "href": "posts/drilldown-with-reactable/index.html#grouping-and-aggregating",
    "title": "Interactive Drill-down Tables using {reactable}",
    "section": "Grouping and Aggregating",
    "text": "Grouping and Aggregating\nreactable has a groupBy argument which lets us combined rows with common data fields and the aggregate argument inside colDef lets us define what aggregation to be used for each column of the top-level data.\n\nCodereactable(\n  data       = combined_df,\n  compact    = TRUE, # for minimum row height\n  filterable = TRUE, # for individual column filters\n  striped    = TRUE, # banded rows\n  resizable  = TRUE, # for resizable column widths\n  groupBy    = \"course_id\",\n  columns    = list(\n    # show count of students in each course\n    course_id   = colDef(name = \"CID\",         width = 100,  align = \"left\",    aggregate = \"count\"),  \n    # show unique course name\n    course_name = colDef(name = \"Course Name\", width = 140,                     aggregate = \"unique\"), \n    # show unique start date\n    start_date  = colDef(name = \"Start Date\",  width = 120,  align = \"center\",  aggregate = \"unique\"), \n    # show unique end date\n    end_date    = colDef(name = \"End Date\",    width = 120,  align = \"center\",  aggregate = \"unique\"), \n    s_id        = colDef(name = \"SID\",         width = 70,   align = \"center\"),\n    s_name      = colDef(name = \"Student Name\"),\n    gender      = colDef(name = \"Gender\",      width = 80,   align = \"center\"),\n    age         = colDef(name = \"Age\",         width = 50)\n  )\n)\n\n\n\n\n\n\nIn this case, all the columns which are not aggregated remain hidden. Clicking the little triangle in the CID column displays the hidden rows. Looks better, but again, the issue of duplicated data remains.\nYou can aggregate the second-level columns too, but this distorts the table and frankly, looks ugly. Here I aggregate the SID column in addition to all the other top-level columns.\n\nCodereactable(\n  data       = combined_df,\n  compact    = TRUE, # for minimum row height\n  filterable = TRUE, # for individual column filters\n  striped    = TRUE, # banded rows\n  resizable  = TRUE, # for resizable column widths\n  groupBy    = \"course_id\",\n  columns    = list(\n    course_id   = colDef(name = \"CID\",         width = 100,  align = \"left\",    aggregate = \"count\"),\n    course_name = colDef(name = \"Course Name\", width = 140,                     aggregate = \"unique\"),\n    start_date  = colDef(name = \"Start Date\",  width = 120,  align = \"center\",  aggregate = \"unique\"),\n    end_date    = colDef(name = \"End Date\",    width = 120,  align = \"center\",  aggregate = \"unique\"),\n    # YIKES!! Aggregating Student ID to show unique ids in each course.\n    s_id        = colDef(name = \"SID\",         width = 70,   align = \"center\",  aggregate = \"unique\"), \n    s_name      = colDef(name = \"Student Name\"),\n    gender      = colDef(name = \"Gender\",      width = 80,   align = \"center\"),\n    age         = colDef(name = \"Age\",         width = 50)\n  )\n)\n\n\n\n\n\n\nWouldn‚Äôt it be nice if we could display only the top-level columns by default and on clicking the small triangle for a row, show all the second-level columns corresponding to that row only, like a drill-down table?\nTo do this we need 2 separate tables. Earlier in this post, I said it is advisable to split such denormalized data into normalized data i.e.¬†create the original top-level and second level tables from the combined_df. Let‚Äôs recreate the 2 tables.\nI want to demonstrate how we go from the combined data to the 2 tables. Hence I will not use the course and student tables created earlier.\nCreating the top_level table using just the columns in course. Let‚Äôs also create a new column n_students depicting count of students in each course.\n\nCodetop_level <- combined_df %>% \n  # Only course info columns\n  count(course_id, course_name, start_date, end_date, name = \"n_students\") \n\npaged_table(top_level)\n\n\n\n  \n\n\n\n\nCodesecond_level <- combined_df %>% \n  # Only Student info columns with unique identifier for Course\n  select(course_id, s_id, s_name, gender, age) %>% \n  arrange(s_id)\n\npaged_table(second_level)"
  },
  {
    "objectID": "posts/drilldown-with-reactable/index.html#the-final-drill-down-table",
    "href": "posts/drilldown-with-reactable/index.html#the-final-drill-down-table",
    "title": "Interactive Drill-down Tables using {reactable}",
    "section": "The final Drill-down Table",
    "text": "The final Drill-down Table\nNow that we have the 2 tables ready, let us now create the final reactable. The trick here is to use the details argument to which we pass another reactable of just the rows with students data corresponding to given course.\n\nCodereactable(\n  data       = top_level,\n  compact    = TRUE, # for minimum row height\n  filterable = TRUE, # for individual column filters\n  striped    = TRUE, # banded rows\n  resizable  = TRUE, # for resizable column widths\n  columns    = list(\n    course_id   = colDef(name = \"CID\",             width = 50,  align = \"center\"),\n    course_name = colDef(name = \"Course Name\"), \n    start_date  = colDef(name = \"Start Date\",      width = 120, align = \"center\"),\n    end_date    = colDef(name = \"End Date\",        width = 120, align = \"center\"),\n    n_students  = colDef(name = \"No. of Students\", width = 130, align = \"center\")\n  ),\n  details = function(index) { # index is the row number of current row.\n    # sub-table of only those students for current row.\n    sec_lvl = second_level[second_level$course_id == top_level$course_id[index], ] \n    reactable(data       = sec_lvl,\n              compact    = TRUE, \n              filterable = TRUE,\n              bordered   = TRUE, \n              resizable  = TRUE,\n              columns    = list(\n                course_id   = colDef(show = FALSE), # hide the course id column\n                s_id        = colDef(name = \"SID\",    width = 70, align = \"center\"),\n                s_name      = colDef(name = \"Student Name\"),\n                gender      = colDef(name = \"Gender\", width = 90, align = \"center\"),\n                age         = colDef(name = \"Age\",    width = 50, align = \"center\")\n              )\n              )\n  }\n)\n\n\n\n\n\n\nSince the sub-table is also a reactable, you can go another level down‚Ä¶ and another, but please do consider the usability aspect of this feature before taking that decision. I haven‚Äôt tried going beyond 2 levels of data myself. Maybe a part 2 to this post??"
  },
  {
    "objectID": "posts/drilldown-with-reactable/index.html#conclusion",
    "href": "posts/drilldown-with-reactable/index.html#conclusion",
    "title": "Interactive Drill-down Tables using {reactable}",
    "section": "Conclusion",
    "text": "Conclusion\nDrill-down tables let you pack a lot of data in a compact manner and allow use by multiple audiences interested in varying degrees/levels of information. reactable can help create an interactive data table from tabular data with sorting and pagination by default. The data table is an HTML widget that can be used in R Markdown documents and Shiny applications, or viewed from an R console. A lot of features can be enabled/disabled using the basic arguments of the reactable() function and much more using custom JavaScript."
  },
  {
    "objectID": "posts/drilldown-with-reactable/index.html#references-citations",
    "href": "posts/drilldown-with-reactable/index.html#references-citations",
    "title": "Interactive Drill-down Tables using {reactable}",
    "section": "References & Citations",
    "text": "References & Citations\n\nGreg Lin (2020). reactable: Interactive Data Tables Based on ‚ÄòReact Table‚Äô. R package version 0.2.3. https://CRAN.R-project.org/package=reactable"
  },
  {
    "objectID": "posts/programming-with-dplyr/index.html",
    "href": "posts/programming-with-dplyr/index.html",
    "title": "Programming with R {dplyr} - As I Understand It!!",
    "section": "",
    "text": "select()\nWhen using dplyr functions, the two most popular ways to pass column names is either as bare names i.e.¬†column names without enclosing them in quotes like sales or volume OR pass them as a character string like double-quote ‚Äúsales‚Äù or single-quote ‚Äòvolume‚Äô. You could also pass a character vector like c(\"sales\", \"volume\"). In this section we will explore the 3 ways to dynamically select the columns we want.\nPassing raw column names\nIn this method, we pass the raw name of the column we want to select and use the embrace of curly-curly brackets to pass the raw name. For multiple columns, we can pass the raw names as a single vector.\n\nCodeselect_raw <- function(df, var) {\n  \n  # embrace of curly-curly {{}} brackets\n  dplyr::select(.data = df, {{var}}) %>%     \n    head()\n}\n\n# pass single raw name\nselect_raw(txhousing, sales)\n\n# A tibble: 6 x 1\n  sales\n  <dbl>\n1    72\n2    98\n3   130\n4    98\n5   141\n6   156\n\nCode# pass a vector of raw names for multiple columns\nselect_raw(txhousing, c(sales, volume))      \n\n# A tibble: 6 x 2\n  sales   volume\n  <dbl>    <dbl>\n1    72  5380000\n2    98  6505000\n3   130  9285000\n4    98  9730000\n5   141 10590000\n6   156 13910000\n\n\nIf passing multiple raw names as vector as in the select_raw() feels like an unnecessary complication, try the next method.\nPassing multiple raw column names using ... argument\nIn this method, we use the ... argument to pass the raw names of the columns we want to select.\n\nCodemy_select <- function(df, ...) {\n  dplyr::select(.data = df, ...) %>% \n    head()\n}\n\n# pass multiple raw names directly\nmy_select(txhousing, sales, volume)          \n\n# A tibble: 6 x 2\n  sales   volume\n  <dbl>    <dbl>\n1    72  5380000\n2    98  6505000\n3   130  9285000\n4    98  9730000\n5   141 10590000\n6   156 13910000\n\n\nPassing a character vector of column names\nIf we have the column names as a character vector, we use the all_of function to pass the character vector to the internal select function.\n\nCodemy_select_char <- function(df, cols) {\n  dplyr::select(.data = df, dplyr::all_of(cols)) %>% \n    head()\n}\n\nmy_cols <- c(\"sales\",\"volume\")\nmy_select_char(txhousing, my_cols)\n\n# A tibble: 6 x 2\n  sales   volume\n  <dbl>    <dbl>\n1    72  5380000\n2    98  6505000\n3   130  9285000\n4    98  9730000\n5   141 10590000\n6   156 13910000\n\n\nfilter()\nIn the previous section, we passed column names either as bare names or character strings. filter() takes one or more expressions/conditions that result in a logical vector, with same length as number of rows in the data.frame/tibble and returns only those rows for which the expression/condition returns TRUE. Following are 2 ways to pass these logical expressions/conditions. I‚Äôm using expression and condition interchangeably here. In this context, a condition is an expression that results in a boolean TRUE/FALSE result.\nPassing single raw criteria\nIn this method, we pass the condition sales > 8000 as a raw/bare expression.\n\nCodefilter_raw <- function(df, cond) {\n  \n  # embrace of curly-curly {{}} brackets\n  dplyr::filter(.data = df, {{cond}})        \n}\n\n# Pass a single raw criterion\nfilter_raw(txhousing, sales > 8000)\n\n# A tibble: 10 x 9\n   city     year month sales     volume median listings inventory  date\n   <chr>   <int> <int> <dbl>      <dbl>  <dbl>    <dbl>     <dbl> <dbl>\n 1 Houston  2006     5  8040 1602621368 151200    35398       5.5 2006.\n 2 Houston  2006     6  8628 1795898108 155200    36281       5.6 2006.\n 3 Houston  2013     5  8439 2121508529 186100    20526       3.3 2013.\n 4 Houston  2013     7  8468 2168720825 187800    21497       3.3 2014.\n 5 Houston  2013     8  8155 2083377894 186700    21366       3.3 2014.\n 6 Houston  2014     6  8391 2342443127 211200    19725       2.9 2014.\n 7 Houston  2014     7  8391 2278932511 199700    20214       3   2014.\n 8 Houston  2014     8  8167 2195184825 202400    20007       2.9 2015.\n 9 Houston  2015     6  8449 2490238594 222400    22311       3.2 2015.\n10 Houston  2015     7  8945 2568156780 217600    23875       3.4 2016.\n\n\nDo you think we can pass multiple bare conditions as a vector, like we did for select_raw() in the previous section? Let us try passing multiple raw criteria as a vector.\n\nCodefilter_raw(txhousing, c(sales > 8000, year > 2010))\nError in `dplyr::filter()`:\n! Problem while computing `..1 = c(sales > 8000, year > 2010)`.\nx Input `..1` must be of size 8602 or 1, not size 17204.\n\n\n\n\n\n\n\n\nVector Concatenation\n\n\n\nPassing multiple raw criteria as a vector doesn‚Äôt work like it works for select_raw() function. Let us understand why. Consider the following code:\n\nCodeA <- c(TRUE, TRUE)      # boolean vector of length = 2\nB <- c(FALSE, FALSE)    # boolean vector of length = 2\nX <- c(A, B)\nX\n\n[1]  TRUE  TRUE FALSE FALSE\n\n\nNotice that length of X is 4. Similarly, sales > 8000 evaluates to a TRUE/FALSE boolean vector of length 8602 (equal to number of rows in txhousing) and so does year > 2010. So the vector c(sales > 8000, year > 2010) becomes a TRUE/FALSE boolean vector of length 17204, which results in an error.\n\n\nPassing multiple raw criteria using ‚Ä¶ argument\nTo pass multiple raw criteria, we can use the ... argument.\n\nCodemy_filter <- function(df, ...) { \n  \n  # pass the dots argument\n  dplyr::filter(.data = df, ...)\n  }\n\n# pass multiple raw criteria\nmy_filter(txhousing, sales > 8000, year > 2010) \n\n# A tibble: 8 x 9\n  city     year month sales     volume median listings inventory  date\n  <chr>   <int> <int> <dbl>      <dbl>  <dbl>    <dbl>     <dbl> <dbl>\n1 Houston  2013     5  8439 2121508529 186100    20526       3.3 2013.\n2 Houston  2013     7  8468 2168720825 187800    21497       3.3 2014.\n3 Houston  2013     8  8155 2083377894 186700    21366       3.3 2014.\n4 Houston  2014     6  8391 2342443127 211200    19725       2.9 2014.\n5 Houston  2014     7  8391 2278932511 199700    20214       3   2014.\n6 Houston  2014     8  8167 2195184825 202400    20007       2.9 2015.\n7 Houston  2015     6  8449 2490238594 222400    22311       3.2 2015.\n8 Houston  2015     7  8945 2568156780 217600    23875       3.4 2016.\n\n\nPassing single criteria as a character string\nBy default, dplyr::filter() does not accept conditions as character strings. Following is an example which results in error\n\nCodedplyr::filter(txhousing, \"sales > 8000\")\nError in `dplyr::filter()`:\n! Problem while computing `..1 = \"sales > 8000\"`.\nx Input `..1` must be a logical vector, not a character.\n\n\nWe need to convert the character condition into a raw expression.\n\nCodemy_filter_string <- function(df, cond) {\n  \n  # convert text to raw criterion\n  dplyr::filter(.data = df, eval(parse(text = cond))) \n}\n\n# pass single text string as criteria\nmy_filter_string(txhousing, \"sales > 8000\")  \n\n# A tibble: 10 x 9\n   city     year month sales     volume median listings inventory  date\n   <chr>   <int> <int> <dbl>      <dbl>  <dbl>    <dbl>     <dbl> <dbl>\n 1 Houston  2006     5  8040 1602621368 151200    35398       5.5 2006.\n 2 Houston  2006     6  8628 1795898108 155200    36281       5.6 2006.\n 3 Houston  2013     5  8439 2121508529 186100    20526       3.3 2013.\n 4 Houston  2013     7  8468 2168720825 187800    21497       3.3 2014.\n 5 Houston  2013     8  8155 2083377894 186700    21366       3.3 2014.\n 6 Houston  2014     6  8391 2342443127 211200    19725       2.9 2014.\n 7 Houston  2014     7  8391 2278932511 199700    20214       3   2014.\n 8 Houston  2014     8  8167 2195184825 202400    20007       2.9 2015.\n 9 Houston  2015     6  8449 2490238594 222400    22311       3.2 2015.\n10 Houston  2015     7  8945 2568156780 217600    23875       3.4 2016.\n\n\nThe special sauce here is the eval(parse(text = ...)) combo that converts the long text criteria into a single raw criteria and passes it to the internal filter() function.\nPassing multiple criteria as character vector\nWhat if want to pass multiple criteria as a string vector? In such a situation, we must combine all the string conditions into a single long string condition using paste0(..., collapse = \" & \"). The paste0(\"(\", cond, \")\", collapse = \" & \") combines all the criteria into a single long criteria, but still a text string.\n\nCodemy_filter_strings <- function(df, cond) { \n  \n  # combine all criteria\n  filter_text <- paste0(\"(\", cond, \")\", collapse = \" & \")\n  \n  # (OPTIONAL) show the combined filter string\n  message(\"Filter Condition: \", filter_text)\n  \n  # convert text to raw criterion\n  dplyr::filter(.data = df, eval(parse(text = filter_text)))\n  }\n\nmy_filter_criteria <- c(\"sales > 8000\", \"year > 2010\")\nmy_filter_strings(txhousing, my_filter_criteria)\n\nFilter Condition: (sales > 8000) & (year > 2010)\n\n\n# A tibble: 8 x 9\n  city     year month sales     volume median listings inventory  date\n  <chr>   <int> <int> <dbl>      <dbl>  <dbl>    <dbl>     <dbl> <dbl>\n1 Houston  2013     5  8439 2121508529 186100    20526       3.3 2013.\n2 Houston  2013     7  8468 2168720825 187800    21497       3.3 2014.\n3 Houston  2013     8  8155 2083377894 186700    21366       3.3 2014.\n4 Houston  2014     6  8391 2342443127 211200    19725       2.9 2014.\n5 Houston  2014     7  8391 2278932511 199700    20214       3   2014.\n6 Houston  2014     8  8167 2195184825 202400    20007       2.9 2015.\n7 Houston  2015     6  8449 2490238594 222400    22311       3.2 2015.\n8 Houston  2015     7  8945 2568156780 217600    23875       3.4 2016.\n\n\n\n\n\n\n\n\nOR Condition\n\n\n\nTo create an OR condition, the expression must be a single string separated by pipe ‚Äò|‚Äô as in example below.\n\n\n\nCodemy_filter_criteria_with_OR <- c(\"sales > 8000 | sales < 50\", \"year > 2010\")\nmy_filter_strings(txhousing, my_filter_criteria_with_OR)\n\nFilter Condition: (sales > 8000 | sales < 50) & (year > 2010)\n\n\n# A tibble: 315 x 9\n   city         year month sales  volume median listings inventory  date\n   <chr>       <int> <int> <dbl>   <dbl>  <dbl>    <dbl>     <dbl> <dbl>\n 1 Brownsville  2011     1    48 4974408  83300      784      12.6 2011 \n 2 Brownsville  2011     2    47 5558575 101400      776      12.7 2011.\n 3 Brownsville  2011     7    47 4807019  91200      749      13.1 2012.\n 4 Brownsville  2011    12    39 4203440  86800      726      12.4 2012.\n 5 Brownsville  2012     1    43 3892348  85000      791      13.6 2012 \n 6 Brownsville  2012     3    27 2976148  93800      734      13.3 2012.\n 7 Brownsville  2012    11    41 5115393  99000      807      14   2013.\n 8 Brownsville  2013    11    38 4824930 108000      859      13.4 2014.\n 9 Brownsville  2015     1    41 5400796  97000      733      10.7 2015 \n10 Galveston    2011     1    43 8882961 170000     1015      13.7 2011 \n# ... with 305 more rows\n\n\nmutate()\nmutate() allows you to add new columns or modify existing columns. In the example below, we will create a new column volume_in_millions from the existing column volume. The names of both the columns can be passed to the function either as raw names or character strings.\nPassing the column name as raw name\n\nCodemutate_raw <- function(df, new_col_raw, old_col_raw, num = 1) { \n  dplyr::mutate(.data = df, {{new_col_raw}} := {{old_col_raw}}/num) %>% \n    head()\n}\n\ntxhousing %>% \n  select(city, year, month, volume) %>% \n  # pass raw column names w/o quotes\n  mutate_raw(vol_in_millions, volume, 1E6) \n\n# A tibble: 6 x 5\n  city     year month   volume vol_in_millions\n  <chr>   <int> <int>    <dbl>           <dbl>\n1 Abilene  2000     1  5380000            5.38\n2 Abilene  2000     2  6505000            6.50\n3 Abilene  2000     3  9285000            9.28\n4 Abilene  2000     4  9730000            9.73\n5 Abilene  2000     5 10590000           10.6 \n6 Abilene  2000     6 13910000           13.9 \n\n\nPassing the new variable name as character string (direct)\n\nCodemutate_text <- function(df, new_col_str, old_col_str, num = 1) { \n  dplyr::mutate(.data = df, {{new_col_str}} := df[[old_col_str]]/num) %>% \n    head()\n}\n\ntxhousing %>% \n  select(city, year, month, volume) %>%\n  # pass column names as strings\n  mutate_text(\"vol_in_millions\", \"volume\", 1E6) \n\n# A tibble: 6 x 5\n  city     year month   volume vol_in_millions\n  <chr>   <int> <int>    <dbl>           <dbl>\n1 Abilene  2000     1  5380000            5.38\n2 Abilene  2000     2  6505000            6.50\n3 Abilene  2000     3  9285000            9.28\n4 Abilene  2000     4  9730000            9.73\n5 Abilene  2000     5 10590000           10.6 \n6 Abilene  2000     6 13910000           13.9 \n\n\nPassing the new variable name as character string (indirect)\nInstead of passing the name of the variable as a character string as an argument, we can pass a variable containing the name of the variable. In the below example, the name of the new variable is stored in new_var. Using the new glue syntax, enabled by the walrus operator :=, we substitute the new_var variable with its value.\n\nCodemutate_var <- function(df, new_col_var, old_col_var, num = 1) {\n  dplyr::mutate(.data = df, \"{new_col_var}\" := df[[old_col_var]]/num) %>% \n    head()\n}\n\nnew_var <- \"vol_in_millions\"\nold_var <- \"volume\"\n\ntxhousing %>% \n  select(city, year, month, volume) %>%\n  # pass column names as variables\n  mutate_var(new_var, old_var, 1E6)  \n\n# A tibble: 6 x 5\n  city     year month   volume vol_in_millions\n  <chr>   <int> <int>    <dbl>           <dbl>\n1 Abilene  2000     1  5380000            5.38\n2 Abilene  2000     2  6505000            6.50\n3 Abilene  2000     3  9285000            9.28\n4 Abilene  2000     4  9730000            9.73\n5 Abilene  2000     5 10590000           10.6 \n6 Abilene  2000     6 13910000           13.9 \n\n\narrange()\narrange() sorts the rows of a data frame by the values of selected columns. By default, it sorts in Ascending order. To force a column to sort in Descending order, we must use the desc() function.\nPassing single raw name\n\nCodearrange_raw <- function(df, var) {\n  \n  # embrace of curly-curly {{}} brackets\n  dplyr::arrange(.data = df, {{var}}) %>%    \n    head()\n}\n\narrange_raw(txhousing, sales)\n\n# A tibble: 6 x 9\n  city                year month sales  volume median listings inventory  date\n  <chr>              <int> <int> <dbl>   <dbl>  <dbl>    <dbl>     <dbl> <dbl>\n1 San Marcos          2011    10     6 1156999 180000      163       8.3 2012.\n2 Harlingen           2000     7     9 1110000  87500      719      30.8 2000.\n3 South Padre Island  2011     1     9 2088500 225000     1258      55.7 2011 \n4 San Marcos          2011     1    10 1482310 140000      165       7.5 2011 \n5 San Marcos          2011    12    10 1561250 140000      148       8   2012.\n6 San Marcos          2014    11    10 1506878 146700       96       4   2015.\n\nCodearrange_raw(txhousing, desc(sales))\n\n# A tibble: 6 x 9\n  city     year month sales     volume median listings inventory  date\n  <chr>   <int> <int> <dbl>      <dbl>  <dbl>    <dbl>     <dbl> <dbl>\n1 Houston  2015     7  8945 2568156780 217600    23875       3.4 2016.\n2 Houston  2006     6  8628 1795898108 155200    36281       5.6 2006.\n3 Houston  2013     7  8468 2168720825 187800    21497       3.3 2014.\n4 Houston  2015     6  8449 2490238594 222400    22311       3.2 2015.\n5 Houston  2013     5  8439 2121508529 186100    20526       3.3 2013.\n6 Houston  2014     6  8391 2342443127 211200    19725       2.9 2014.\n\n\narrange_raw() fails when we pass multiple raw names as a vector.\n\nCodearrange_raw(txhousing, c(sales, volume))\nError in `dplyr::arrange()`:\n! Problem with the implicit `transmute()` step.\nx Problem while computing `..1 = c(sales, volume)`.\nx `..1` must be size 8602 or 1, not 17204.\n\n\nPassing multiple raw names using ... argument\nTo pass multiple raw names, we must use the ... argument.\n\nCodearrange_raw_multiple <- function(df, ...) {\n  dplyr::arrange(.data = df, ...) %>% \n    head()\n}\n\narrange_raw_multiple(txhousing, city, sales)\n\n# A tibble: 6 x 9\n  city     year month sales  volume median listings inventory  date\n  <chr>   <int> <int> <dbl>   <dbl>  <dbl>    <dbl>     <dbl> <dbl>\n1 Abilene  2003     1    68 5385000  70000      668       5.4  2003\n2 Abilene  2011     1    68 8834493 123300      809       6.1  2011\n3 Abilene  2009     1    70 8414801  92900      861       6.3  2009\n4 Abilene  2000     1    72 5380000  71400      701       6.3  2000\n5 Abilene  2010     1    73 9130783 112200      868       6.4  2010\n6 Abilene  2001     1    75 5730000  64500      779       6.8  2001\n\nCodearrange_raw_multiple(txhousing, city, desc(sales))\n\n# A tibble: 6 x 9\n  city     year month sales   volume median listings inventory  date\n  <chr>   <int> <int> <dbl>    <dbl>  <dbl>    <dbl>     <dbl> <dbl>\n1 Abilene  2015     7   268 45845730 148700      986       5   2016.\n2 Abilene  2015     6   260 41396230 141500      965       5   2015.\n3 Abilene  2007     7   239 29315000 114300      940       5.2 2008.\n4 Abilene  2013     8   236 30777727 120000      976       5.4 2014.\n5 Abilene  2014     7   231 35861350 145800     1033       5.8 2014.\n6 Abilene  2005     6   230 24050000  92500      664       4.1 2005.\n\n\nPass single column name as string\n\nCodearrange_str <- function(df, var, .desc = FALSE) {\n  if (.desc) {\n    dplyr::arrange(.data = df, desc(df[[var]])) %>% head()\n  } else {\n    dplyr::arrange(.data = df, df[[var]]) %>% head()\n  }\n}\n\narrange_str(txhousing, \"sales\")\n\n# A tibble: 6 x 9\n  city                year month sales  volume median listings inventory  date\n  <chr>              <int> <int> <dbl>   <dbl>  <dbl>    <dbl>     <dbl> <dbl>\n1 San Marcos          2011    10     6 1156999 180000      163       8.3 2012.\n2 Harlingen           2000     7     9 1110000  87500      719      30.8 2000.\n3 South Padre Island  2011     1     9 2088500 225000     1258      55.7 2011 \n4 San Marcos          2011     1    10 1482310 140000      165       7.5 2011 \n5 San Marcos          2011    12    10 1561250 140000      148       8   2012.\n6 San Marcos          2014    11    10 1506878 146700       96       4   2015.\n\nCodearrange_str(txhousing, \"sales\", .desc = TRUE)\n\n# A tibble: 6 x 9\n  city     year month sales     volume median listings inventory  date\n  <chr>   <int> <int> <dbl>      <dbl>  <dbl>    <dbl>     <dbl> <dbl>\n1 Houston  2015     7  8945 2568156780 217600    23875       3.4 2016.\n2 Houston  2006     6  8628 1795898108 155200    36281       5.6 2006.\n3 Houston  2013     7  8468 2168720825 187800    21497       3.3 2014.\n4 Houston  2015     6  8449 2490238594 222400    22311       3.2 2015.\n5 Houston  2013     5  8439 2121508529 186100    20526       3.3 2013.\n6 Houston  2014     6  8391 2342443127 211200    19725       2.9 2014.\n\n\nPass multiple column name as string\n\nCodearrange_str_multiple <- function(df, var, desc = FALSE) {\n  if (desc) {\n    dplyr::arrange(.data = df, desc(df[var])) %>% head()\n  } else {\n    dplyr::arrange(.data = df, df[var]) %>% head()\n  }\n}\n\n# This function arranges the dataframe either all ascending\n# or all descending. Definitely need a better example.\n\narrange_str_multiple(txhousing, c(\"year\", \"month\", \"sales\"))\n\n# A tibble: 6 x 9\n  city         year month sales  volume median listings inventory  date\n  <chr>       <int> <int> <dbl>   <dbl>  <dbl>    <dbl>     <dbl> <dbl>\n1 Paris        2000     1    19 1440000  71700      286       7.5  2000\n2 San Marcos   2000     1    22 2380000 106700      190       6.3  2000\n3 Lufkin       2000     1    28 2280000  68000       NA      NA    2000\n4 Harlingen    2000     1    31 3910000  87500      644      24.9  2000\n5 Galveston    2000     1    37 4555000  95000      636       9.1  2000\n6 Port Arthur  2000     1    40 3090000  68300      314       5.6  2000\n\nCodearrange_str_multiple(txhousing, c(\"year\", \"month\", \"sales\"), desc = TRUE)\n\n# A tibble: 6 x 9\n  city           year month sales     volume median listings inventory  date\n  <chr>         <int> <int> <dbl>      <dbl>  <dbl>    <dbl>     <dbl> <dbl>\n1 Houston        2015     7  8945 2568156780 217600    23875       3.4 2016.\n2 Dallas         2015     7  7038 2021907410 233000    12292       2.4 2016.\n3 Austin         2015     7  3466 1150381553 264600     7913       3   2016.\n4 San Antonio    2015     7  2962  704891602 198100     9462       4.1 2016.\n5 Collin County  2015     7  1861  613669702 292600     2809       2.1 2016.\n6 Fort Bend      2015     7  1372  431875327 280400     3328       3.1 2016.\n\n\ngroup_by()\nIn group_by(), we select which columns to, well, group by! (Damn these well-named functions!). So one can use the same techniques as select() to choose the columns.\nIn the following examples, we will create only one summarised value total_sales for simplicity.\nPassing single raw name\n\nCodegroup_raw <- function(df, grp) {\n  df %>% \n    group_by({{grp}}) %>% \n    summarise(total_sales = sum(sales, na.rm = TRUE),\n              .groups = 'drop')  %>% \n    head(n=5)\n}\n\n# Sum of sales per year\ngroup_raw(txhousing, year)\n\n# A tibble: 5 x 2\n   year total_sales\n  <int>       <dbl>\n1  2000      222483\n2  2001      231453\n3  2002      234600\n4  2003      253909\n5  2004      283999\n\nCode# Sum of sales per month\ngroup_raw(txhousing, month)       \n\n# A tibble: 5 x 2\n  month total_sales\n  <int>       <dbl>\n1     1      245924\n2     2      296410\n3     3      386909\n4     4      397332\n5     5      448968\n\n\nPassing multiple raw names using the ... operator\n\nCodegroup_raw_multiple <- function(df, ...) {\n  df %>% \n    group_by(...) %>% \n    summarise(total_sales = sum(sales, na.rm = TRUE),\n              .groups = 'drop')  %>% \n    head(n = 5)\n}\n\n# Sum of sales per year\ngroup_raw_multiple(txhousing, year)\n\n# A tibble: 5 x 2\n   year total_sales\n  <int>       <dbl>\n1  2000      222483\n2  2001      231453\n3  2002      234600\n4  2003      253909\n5  2004      283999\n\nCode# Sum of sales per month\ngroup_raw_multiple(txhousing, year, month)     \n\n# A tibble: 5 x 3\n   year month total_sales\n  <int> <int>       <dbl>\n1  2000     1       11411\n2  2000     2       15674\n3  2000     3       20202\n4  2000     4       18658\n5  2000     5       22388\n\n\nPassing single or multiple column names as character string\n\nCodegroup_str <- function(df, grp) {\n  df %>% \n    group_by(df[grp]) %>% \n    summarise(total_sales = sum(sales, na.rm = TRUE),\n              .groups = 'drop')  %>% \n    head(n=5)\n}\n\n# Sum of sales per year\ngroup_str(txhousing, \"year\")\n\n# A tibble: 5 x 2\n   year total_sales\n  <int>       <dbl>\n1  2000      222483\n2  2001      231453\n3  2002      234600\n4  2003      253909\n5  2004      283999\n\nCode# Sum of sales per month\ngroup_str(txhousing, c(\"year\", \"month\"))       \n\n# A tibble: 5 x 3\n   year month total_sales\n  <int> <int>       <dbl>\n1  2000     1       11411\n2  2000     2       15674\n3  2000     3       20202\n4  2000     4       18658\n5  2000     5       22388\n\nCode# The same column names can be passed as variables containing the character names\nyr <- \"year\"\ngroup_str(txhousing, yr)\n\n# A tibble: 5 x 2\n   year total_sales\n  <int>       <dbl>\n1  2000      222483\n2  2001      231453\n3  2002      234600\n4  2003      253909\n5  2004      283999\n\nCodeyrmon <- c(\"year\", \"month\")\ngroup_str(txhousing, yrmon)\n\n# A tibble: 5 x 3\n   year month total_sales\n  <int> <int>       <dbl>\n1  2000     1       11411\n2  2000     2       15674\n3  2000     3       20202\n4  2000     4       18658\n5  2000     5       22388\n\n\nIf you want the summarised column to have a custom name like total_<sumvar>, then you can wrap the value in quotes as below. This method uses the glue syntax enabled by the := walrus operator. The walrus operator takes either a raw name or a character string on its LHS.\n\nCodegroup_raw2 <- function(df, grp, sumvar) {\n  df %>% \n    group_by({{grp}}) %>% \n    summarise(\"total_{{sumvar}}\" := sum({{sumvar}}, na.rm = TRUE),\n              .groups = 'drop')  %>% \n    head(n=5)\n}\n\n# Sum of sales per year\ngroup_raw2(txhousing, year, sales)\n\n# A tibble: 5 x 2\n   year total_sales\n  <int>       <dbl>\n1  2000      222483\n2  2001      231453\n3  2002      234600\n4  2003      253909\n5  2004      283999\n\nCode# Sum of listings per month\ngroup_raw2(txhousing, month, listings)\n\n# A tibble: 5 x 2\n  month total_listings\n  <int>          <dbl>\n1     1        1854661\n2     2        1888104\n3     3        1949187\n4     4        1991278\n5     5        2038932\n\n\nAfter writing so many examples, I see a pattern. group_by() works with techniques similar to select() while summarise() works with techniques similar to mutate().\n(Slightly Better) Examples\nThe txhousing is a city-wise monthly sales and volume dataset. It has a year and month column. Let us create a date column and keep only those columns relevant for our custom tx_summary() function.\n\nCodesmall_df <- txhousing %>% \n  mutate(date = lubridate::as_date(glue::glue(\"{year}-{month}-01\"))) %>% \n  select(city, date, sales, volume)\n\n\n\nmutate() example\nNow let us create the create_ymq() function. This function would take 2 arguments, a data frame df and a raw name of a date column.\n\nCodecreate_ymq <- function(df, date_col) {\n  stopifnot(inherits(df, \"data.frame\"))\n  stopifnot(class(df %>% dplyr::pull({{date_col}})) == 'Date')\n  mutate(df,\n         Year = lubridate::year({{date_col}}),\n         nHalf = lubridate::semester({{date_col}}),\n         yHalf = lubridate::semester({{date_col}}, with_year = TRUE),\n         dHalf = paste0(lubridate::semester({{date_col}}), \"H\", format({{date_col}},\"%y\")),\n         nQtr = lubridate::quarter({{date_col}}),\n         yQtr = lubridate::quarter({{date_col}}, with_year = TRUE),\n         dQtr = paste0(lubridate::quarter({{date_col}}),\"Q\", format({{date_col}},\"%y\")),\n         Month = lubridate::month({{date_col}}),\n         yMonth = as.numeric(format({{date_col}}, \"%Y.%m\")),\n         dMonth = format({{date_col}}, \"%b %Y\")\n         )\n}\n\ncreate_ymq(df = small_df, date_col = date) %>% glimpse()\n\nRows: 8,602\nColumns: 14\n$ city   <chr> \"Abilene\", \"Abilene\", \"Abilene\", \"Abilene\", \"Abilene\", \"Abilene~\n$ date   <date> 2000-01-01, 2000-02-01, 2000-03-01, 2000-04-01, 2000-05-01, 20~\n$ sales  <dbl> 72, 98, 130, 98, 141, 156, 152, 131, 104, 101, 100, 92, 75, 112~\n$ volume <dbl> 5380000, 6505000, 9285000, 9730000, 10590000, 13910000, 1263500~\n$ Year   <dbl> 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 200~\n$ nHalf  <int> 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, ~\n$ yHalf  <dbl> 2000.1, 2000.1, 2000.1, 2000.1, 2000.1, 2000.1, 2000.2, 2000.2,~\n$ dHalf  <chr> \"1H00\", \"1H00\", \"1H00\", \"1H00\", \"1H00\", \"1H00\", \"2H00\", \"2H00\",~\n$ nQtr   <int> 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 1, 1, 1, 2, 2, 2, 3, 3, 3, ~\n$ yQtr   <dbl> 2000.1, 2000.1, 2000.1, 2000.2, 2000.2, 2000.2, 2000.3, 2000.3,~\n$ dQtr   <chr> \"1Q00\", \"1Q00\", \"1Q00\", \"2Q00\", \"2Q00\", \"2Q00\", \"3Q00\", \"3Q00\",~\n$ Month  <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5, 6, 7, 8, ~\n$ yMonth <dbl> 2000.01, 2000.02, 2000.03, 2000.04, 2000.05, 2000.06, 2000.07, ~\n$ dMonth <chr> \"Jan 2000\", \"Feb 2000\", \"Mar 2000\", \"Apr 2000\", \"May 2000\", \"Ju~\n\n\n\ngroup_by() example\nNow that we have a function that creates various date-related columns, let us create a function that let‚Äôs you create summary tables like annual sales per city, quarterly volumes per city etc.\n\nCodetx_summary <- function(df, grp_col, sum_col) {\n  df %>% \n    group_by(city, {{grp_col}}) %>% \n    summarise(\"total_{{sum_col}}\" := sum({{sum_col}}, na.rm = TRUE), .groups = 'drop')\n}\n\n\nUsing these 2 functions, we can now create multiple summary tables\n\nCodesmall_df_with_date_cols <- small_df %>% \n  create_ymq(date_col = date)\n\n# Annual Sales per city\nsmall_df_with_date_cols %>% \n  tx_summary(grp_col = Year, sum_col = sales)\n\n# A tibble: 736 x 3\n   city     Year total_sales\n   <chr>   <dbl>       <dbl>\n 1 Abilene  2000        1375\n 2 Abilene  2001        1431\n 3 Abilene  2002        1516\n 4 Abilene  2003        1632\n 5 Abilene  2004        1830\n 6 Abilene  2005        1977\n 7 Abilene  2006        1997\n 8 Abilene  2007        2003\n 9 Abilene  2008        1651\n10 Abilene  2009        1634\n# ... with 726 more rows\n\nCode# Half Yearly volumes per city\nsmall_df_with_date_cols %>% \n  tx_summary(grp_col = yHalf, sum_col = volume)\n\n# A tibble: 1,472 x 3\n   city    yHalf total_volume\n   <chr>   <dbl>        <dbl>\n 1 Abilene 2000.     55400000\n 2 Abilene 2000.     53175000\n 3 Abilene 2001.     55795000\n 4 Abilene 2001.     58570000\n 5 Abilene 2002.     55305000\n 6 Abilene 2002.     63370000\n 7 Abilene 2003.     58175000\n 8 Abilene 2003.     77500000\n 9 Abilene 2004.     74205000\n10 Abilene 2004.     85465000\n# ... with 1,462 more rows\n\nCode# Quarterly Sales per city\nsmall_df_with_date_cols %>% \n  tx_summary(grp_col = yQtr, sum_col = sales)\n\n# A tibble: 2,898 x 3\n   city     yQtr total_sales\n   <chr>   <dbl>       <dbl>\n 1 Abilene 2000.         300\n 2 Abilene 2000.         395\n 3 Abilene 2000.         387\n 4 Abilene 2000.         293\n 5 Abilene 2001.         305\n 6 Abilene 2001.         394\n 7 Abilene 2001.         401\n 8 Abilene 2001.         331\n 9 Abilene 2002.         295\n10 Abilene 2002.         425\n# ... with 2,888 more rows\n\nCode# Monthly Volumes per city\nsmall_df_with_date_cols %>% \n  tx_summary(grp_col = yMonth, sum_col = volume)\n\n# A tibble: 8,602 x 3\n   city    yMonth total_volume\n   <chr>    <dbl>        <dbl>\n 1 Abilene  2000.      5380000\n 2 Abilene  2000.      6505000\n 3 Abilene  2000.      9285000\n 4 Abilene  2000.      9730000\n 5 Abilene  2000.     10590000\n 6 Abilene  2000.     13910000\n 7 Abilene  2000.     12635000\n 8 Abilene  2000.     10710000\n 9 Abilene  2000.      7615000\n10 Abilene  2000.      7040000\n# ... with 8,592 more rows\n\n\nMore ideas\nYou could further extend this by creating a custom filtering function that gives you, say, the rows with the highest or lowest total_sales or total_volume.\nConclusion\nThe ability to create such dynamic functions, enabled by the wonderful {dplyr} package, allows us to level-up in terms of programming with R and helps make our code neat and tidy.\n\n\n\nHow I feel while creating custom functions with {dplyr}! I can almost hear the music! Source: imgur.com\n\n\n\nReferences\n\nHadley Wickham, Romain Fran√ßois, Lionel Henry and Kirill M√ºller (2022). dplyr: A Grammar of Data Manipulation. R package version 1.0.9. https://CRAN.R-project.org/package=dplyr\nhttps://dplyr.tidyverse.org/articles/programming.html\nH. Wickham. ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York, 2016. https://ggplot2.tidyverse.org\nJim Hester and Jennifer Bryan (2022). glue: Interpreted String Literals. R package version 1.6.2. https://CRAN.R-project.org/package=glue\n\n\n\nFootnotes\n\nDon‚Äôt Repeat Yourself‚Ü©Ô∏é\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{katti2021,\n  author = {Vishal Katti},\n  editor = {},\n  title = {Programming with {R} \\{Dplyr\\} - {As} {I} {Understand}\n    {It!!}},\n  date = {2021-07-17},\n  url = {https://vishalkatti.com/posts/programming-with-dplyr},\n  langid = {en},\n  abstract = {This post demonstrates how to write your own dynamic\n    functions using popular `dplyr` verbs like `select()`, `filter()`,\n    `mutate()`, `arrange()` and `group\\_by()` with `summarise()`.}\n}\nFor attribution, please cite this work as:\nVishal Katti. 2021. ‚ÄúProgramming with R {Dplyr} - As I Understand\nIt!!‚Äù July 17, 2021. https://vishalkatti.com/posts/programming-with-dplyr."
  },
  {
    "objectID": "posts/R2VBA2PPT1/index.html",
    "href": "posts/R2VBA2PPT1/index.html",
    "title": "Unholy Trinity of R, Excel VBA and Powerpoint - Part 1 of 2",
    "section": "",
    "text": "One of the most common tasks in most offices, is creating presentations and reports in Microsoft PowerPoint. While the tool is great for creating ad-hoc presentations, editing the same with new data on a periodic basis gets tedious. Now, I know that some wonderful packages like officer and officedown exist that enable us to create PowerPoint presentations with editable charts from R itself. You can read all about this in the amazing Alison Hill‚Äôs blog post ‚ÄúUp and running with officedown‚Äù.\nSince I discovered R while looking for a better alternative to VBA for data analysis and Excel/PowerPoint automation, the following is an alternative workflow to create multiple PowerPoint presentations using a combination of these technologies. Note that this workflow uses the RDCOMClient package which works in Windows environment only."
  },
  {
    "objectID": "posts/R2VBA2PPT1/index.html#tldr",
    "href": "posts/R2VBA2PPT1/index.html#tldr",
    "title": "Unholy Trinity of R, Excel VBA and Powerpoint - Part 1 of 2",
    "section": "TL;DR",
    "text": "TL;DR\nIn this 2-part blog, we create a PowerPoint template with named placeholders which we populate from an Excel file using VBA. The Excel file is loaded with data using R with the help of openxlsx package and then the macro is triggered using the RDCOMClient package.\nThis solution has great potential to give you the same feeling as those Jurassic Park scientists that Dr.¬†Ian Malcolm remarked about!\nAdvantages of this approach over officer and officedown:\n\nSlide/content/header/footer formatting control is in the PowerPoint template rather than R code.\nAll charts are native and can contain any feature (dual axis, mixed data series like bar + line, line + points). All Excel chart-types are available. Go wild!\nYou can use any PowerPoint template design (Yes, even your sad/weird/exciting corporate template!).\n\nLet‚Äôs begin.\nSuppose we want to automate the following PowerPoint presentation. It contains 3 slides with a title slide and 2 content slides having graphs and tables created from the gapminder dataset. This .pptx file also has a custom footer.\n\n\nFigure¬†1: The Gapminder World Population Report. Note the custom footer!\n\n\n\nWe want to create the same presentation with same structure but at a continent-level. gapminder has data for 5 continents and we wish to create 5 presentations by the end of this."
  },
  {
    "objectID": "posts/R2VBA2PPT1/index.html#the-powerpoint-template",
    "href": "posts/R2VBA2PPT1/index.html#the-powerpoint-template",
    "title": "Unholy Trinity of R, Excel VBA and Powerpoint - Part 1 of 2",
    "section": "The PowerPoint Template",
    "text": "The PowerPoint Template\nIn this approach, we start with the PowerPoint presentation file. We will create a template with placeholders and charts with dummy data.\n\n\nFigure¬†2: Save As PowerPoint Template (.potx)\n\n\n\nUsually, you would have a copy of the .pptx file you want to automate. Save a copy of it as a PowerPoint Template (.potx), ideally to your R Project1 folder. In my case, I‚Äôve created a new R Project folder named R2XL2PPT as shown in Figure¬†2.\nNow let us prep the template. If you open the template file by double-click or right-click > New, it would open a fresh .pptx presentation using the template. Right-Click and click Open in the context menu to open the .potx template file for editing.\n\n\n\nFigure¬†3: CORRECT: Right-Click > Open\n\n\n\nOnce you have the template open, we will add names to all the text placeholders, tables and graphs we wish to update. To update the placeholder name:\n\nSelect the shape/text-area/table/graph.\nFrom Shape Format, click Selection Pane.\nIn the Selection Pane, change the name of the selected item.\n\n\n\nFigure¬†4: Add shape names from Selection Pane\n\n\n\n\n\n\n\n\n\nAdvisory\n\n\n\nWe use the format NN_[Position]Object where NN is the slide number, [Position] is the either TopLeft, TopRight, BottomLeft, BottomRight or any other position and finally, Object is either Table, Chart, Title, Subtitle, TextBox etc. You can use any fancy identifier here, just make sure that your future self and others can recognise them easily.\n\n\nOnce you set the names of all the items that you want to customise, save the template.\nDownload the GP_template.potx template here."
  },
  {
    "objectID": "posts/R2VBA2PPT1/index.html#the-excel-template",
    "href": "posts/R2VBA2PPT1/index.html#the-excel-template",
    "title": "Unholy Trinity of R, Excel VBA and Powerpoint - Part 1 of 2",
    "section": "The Excel Template",
    "text": "The Excel Template\n\n\nFigure¬†5: PowerPoint item to Excel named range mapping\n\n\n\nTo populate all the named items in the PowerPoint template, we will now create an Excel document which looks identical to the template with respect to the named items. Please see Figure¬†5.\nFor every named item, depending on whether it is a textbox or chart or table, we will create a named range for that item. For example, for item 01_title in the PowerPoint template, we create a S1_title named range2 (which points to cell C3) as a placeholder for it.\n\n\n\n\n\n\nWarning\n\n\n\nExcel does not allow the names of the named ranges to start with a number, hence 01_title is mapped to S1_title. The S stands for Slide. Just one of those Excel quirks I guess!\n\n\nYou can set a single Excel cell as named range for each textbox in the PowerPoint template. You can copy-paste tables from Powerpoint to the Excel template directly. The entire table must be set as a named range.\n\n\nFigure¬†6: Excel Chart: Right Click > Edit Data\n\n\n\nFor charts, right-click the chart in PowerPoint and select Edit Data. See Figure¬†6. An excel worksheet is displayed with the underlying data. Copy-paste the entire data into the Excel template.\n\n\nFigure¬†7: XL2PPT design\n\n\n\nFor the GP_template.potx, the corresponding excel template XL2PPT.xlsm is shown in Figure¬†7. Please note that this template does not have the VBA macro yet."
  },
  {
    "objectID": "posts/R2VBA2PPT1/index.html#the-vba-macro",
    "href": "posts/R2VBA2PPT1/index.html#the-vba-macro",
    "title": "Unholy Trinity of R, Excel VBA and Powerpoint - Part 1 of 2",
    "section": "The VBA Macro",
    "text": "The VBA Macro\nWe want the VBA macro to:\n\nOpen a new instance of PowerPoint presentation using the GP_template.potx file.\nCopy text/numbers from various placeholders and replace existing text/numbers in the PowerPoint presentation.\nSave the presentation with custom file name with .pptx extension.\n\nThe actual mapping of the named ranges in the Excel template to the named shapes in the PowerPoint template happens in the VBA code. However, at this stage, you can actually create the PowerPoint presentation by copying the numbers into the Excel template and hitting the big RUN MACRO button.\nFor your reference, I am embedding the VBA macro code below. You can download the XL2PPT.xlsm file from here.\n\n\n VBA Macro Code"
  },
  {
    "objectID": "posts/R2VBA2PPT1/index.html#r",
    "href": "posts/R2VBA2PPT1/index.html#r",
    "title": "Unholy Trinity of R, Excel VBA and Powerpoint - Part 1 of 2",
    "section": "R",
    "text": "R\nSuppose we want to create a 10 variations of PowerPoint presentation using the same template. While creating the presentation from Excel is now automated, how about creating the numbers for each of those 10 variations? This is where we bring in R with the openxlsx and RDCOMClient packages. We use the tidyverse set of packages to read in data, clean and massage the data into the various formats we need, openxlsx to write the data (single numbers, text or tables of numbers) to the Excel template and RDCOMClient to run the embedded VBA code in the Excel template.\nCheck out Part 2 of this blog to see how to run VBA code using R. Let me know if you find this useful or any corrections required in the comments below."
  },
  {
    "objectID": "posts/R2VBA2PPT2/index.html",
    "href": "posts/R2VBA2PPT2/index.html",
    "title": "Unholy Trinity of R, Excel VBA and Powerpoint - Part 2 of 2",
    "section": "",
    "text": "This is part 2 of 2. Read part 1 here."
  },
  {
    "objectID": "posts/R2VBA2PPT2/index.html#quick-recap",
    "href": "posts/R2VBA2PPT2/index.html#quick-recap",
    "title": "Unholy Trinity of R, Excel VBA and Powerpoint - Part 2 of 2",
    "section": "Quick Recap",
    "text": "Quick Recap\nIn the previous post, we create the .potx template from the .pptx file we wanted to automate and the Excel template with the macro .xlsm that uses the PowerPoint template to create a new .pptx file with given data using VBA.\nThe report we want to automate is‚Ä¶\n\n\nFigure¬†1: The Gapminder Report : The PowerPoint presentation we want to automate\n\n\n\n‚Ä¶and the Excel and PowerPoint template we created are shown in Figure¬†2.\n\n\nFigure¬†2: Excel Template with VBA macro\n\n\n\nIn this post, we will write the R script that will first massage the data into desired format and then load the data for one region into the Excel template and execute the VBA macro that will create the PowerPoint file with that data."
  },
  {
    "objectID": "posts/R2VBA2PPT2/index.html#strategy",
    "href": "posts/R2VBA2PPT2/index.html#strategy",
    "title": "Unholy Trinity of R, Excel VBA and Powerpoint - Part 2 of 2",
    "section": "Strategy",
    "text": "Strategy\nBefore we dive into code, we need to check a few things. We wish to create a presentation for each continent in the Gapminder data. A closer look at the Presentation will tell you what kind of data we need for each slide/graph/table while the Excel template will reveal what should the structure of each dataset should be. While looking into this structure, some questions will pop-up. The idea here is to create the datasets in such a way that they can be easily filtered for each continent and the resultant table can be written to the Excel template without any or very little modification. Let us proceed slide-by-slide."
  },
  {
    "objectID": "posts/R2VBA2PPT2/index.html#creating-the-datasets",
    "href": "posts/R2VBA2PPT2/index.html#creating-the-datasets",
    "title": "Unholy Trinity of R, Excel VBA and Powerpoint - Part 2 of 2",
    "section": "Creating the datasets",
    "text": "Creating the datasets\nSlide 1\nSlide 1 is the title page and needs 2 strings; one for Title, one for Subtitle. The Title for the base presentation is ‚ÄúWorld Population‚Äù. For each continent, it could be ‚Äú<continent_name> Population‚Äù. The subtitle is a combination of Author Name and Created Date. So we need a string like ‚Äú<author_name> | <created_date>‚Äù where created_date is the formatted system date.\nThese strings can be created while writing the data to the Excel template.\nSlide 2\nThe chart on slide 2 needs raw data structured as below. You will notice that at a continent-level, this table needs a minimum of 5 countries. Do we have any continents in the Gapminder data with less than 5 countries? Yes, we have Oceania with only Australia and New Zealand. For ease of use, let us include these countries along with Asian countries in a new Region variable.\n\n\nFigure¬†3: 02_chart\n\n\n\nWe will create the region variable in the gapminder data. But first, let us load some relevant packages.\n\nCodeoptions(tidyverse.quiet = TRUE)\nlibrary(tidyverse) # duh!\nlibrary(rmarkdown) # to display the tables interactively in this post. Not really needed for the final solution.\nlibrary(openxlsx) # to write the data to the Excel Template.\n# library(RDCOMClient) # to load and run the Excel macro post data load.\n\n\n\nCode# Read in Gapminder data\ngp <- gapminder::gapminder\n\n# Create new region variable\ngp <- gp %>%\n  mutate(region = if_else(as.character(continent) %in% c(\"Asia\",\"Oceania\"),\n                          \"Asia-Pacific\", \n                          as.character(continent)),\n         country = as.character(country))\n\n# Keep only relevant columns\ngp <- gp %>% select(region, country, year, pop)\n\n# View details\nglimpse(gp)\n\nRows: 1,704\nColumns: 4\n$ region  <chr> \"Asia-Pacific\", \"Asia-Pacific\", \"Asia-Pacific\", \"Asia-Pacific\"~\n$ country <chr> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"A~\n$ year    <int> 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 20~\n$ pop     <int> 8425333, 9240934, 10267083, 11537966, 13079460, 14880372, 1288~\n\n\nNow that we have the source data available, we must now create the datasets we need that we can write to the Excel template for each region.\nThe required table in Figure¬†3 shows the top 4 countries (based on 2007 population) and all other countries clubbed into ‚Äòothers‚Äô in a given region and then the total population of the region on a yearly basis. This table has to be created for all 4 regions.\n\nCodepop_trend <- gp %>%\n  group_by(region, country, year) %>% \n  summarise(pop = sum(pop, na.rm = TRUE),\n            .groups = 'drop') %>%\n  mutate(pop = round(pop/1E6, 0)) %>% # population in millions\n  pivot_wider(names_from = year, values_from = pop, names_sort = TRUE) %>% \n  arrange(desc(`2007`)) # sort by max pop to min pop in latest year i.e. 2007\n\npaged_table(pop_trend)\n\n\n\n  \n\n\n\nNow that we have the required columns, let‚Äôs plan the row order. We notice that, for each region, we have the top 4 countries (as per 2007) , followed by ‚ÄòOthers‚Äô. Let‚Äôs create the top-4 dataset.\n\nCodetop4 <- pop_trend %>% \n  group_by(region) %>% \n  slice_max(`2007`, n = 4, with_ties = FALSE) %>% \n  ungroup()\n\npaged_table(top4)\n\n\n\n  \n\n\n\nTo create the others dataset, we exclude all countries that are present in the top-4.\n\nCodeothers <- pop_trend %>% \n  filter(!country %in% top4$country) %>% \n  group_by(region) %>% \n  summarise(across(.cols = -country, .fns = sum),\n            .groups = 'drop') %>% \n  mutate(country = \"Others\") %>% \n  select(region, country, everything())\n\npaged_table(others)\n\n\n\n  \n\n\n\nWhile we create the top-4 and others datasets separately, we will combine them later at the very last moment before writing them to the Excel template.\nNow that we have the datasets needed for 02_chart, let‚Äôs proceed to the create 02_table . This table gives you the count of countries that fall under various population ranges.\n\n\nFigure¬†4: 02_table on Slide 2\n\n\n\nLet‚Äôs create 02_table. To create this table, we first create a new variable called pop_range.\n\nCodepop_levels <- c('Less than 500K','500K - 1 Million',\n                '1M - 10 Million', '10M - 100 Million',\n                '100M - 1 Billion', 'More than 1 Billion')\n\ngp2007 <- gp %>% \n  filter(year == 2007) %>% \n  mutate(pop_range = case_when(pop < 5E5 ~ pop_levels[1],\n                               pop < 1E6 ~ pop_levels[2],\n                               pop < 1E7 ~ pop_levels[3],\n                               pop < 1E8 ~ pop_levels[4],\n                               pop < 1E9 ~ pop_levels[5],\n                               TRUE      ~ pop_levels[6]),\n         pop_range = factor(pop_range, levels = pop_levels))\n\npop_groups <- gp2007 %>% \n  group_by(region, pop_range, .drop = FALSE) %>% \n  summarise(`# of Countries` = n(),\n            .groups = 'drop') %>% \n  arrange(region, pop_range) %>% \n  rename(`Population Category` = pop_range)\n\npaged_table(pop_groups)\n\n\n\n  \n\n\n\nSlide 3\nSlide 3 contains 2 strings and one chart. The data for the chart looks as shown below.\n\n\nFigure¬†5: 03_chart table for Slide 3\n\n\n\nThe data for 03_chart is the list of top 10 countries in each region as per latest record i.e.¬†2007. Let‚Äôs create the top10 table.\n\nCodetop10 <- gp %>% \n  filter(year == 2007) %>% \n  group_by(region) %>% \n  slice_max(pop, n = 10, with_ties = FALSE) %>% \n  ungroup() %>% \n  select(-year) %>% \n  mutate(pop = round(pop/1E6, 4)) %>% # population in millions\n  set_names(c(\"region\",\"country\",\"population\"))\n\npaged_table(top10)"
  },
  {
    "objectID": "posts/R2VBA2PPT2/index.html#the-for-loop",
    "href": "posts/R2VBA2PPT2/index.html#the-for-loop",
    "title": "Unholy Trinity of R, Excel VBA and Powerpoint - Part 2 of 2",
    "section": "The for loop!",
    "text": "The for loop!\nWe now have to load the Excel template with the data at appropriate cell locations for one region at a time. Since we have about 4 regions, we will create a vector of unique regions to iterate over.\n\nCodeunique_regions <- gp %>% distinct(region) %>% pull()\ncat(unique_regions, sep = \"\\n\")\n\nAsia-Pacific\nEurope\nAfrica\nAmericas\n\n\nAs our last step, we will create the for loop that will iterate over unique_regions , filter the datasets for each region, write them to the Excel Template, save the template with temporary name. We save the file with different name to prevent unintentionally corrupting the Excel macro template. Finally, we run the macro in the renamed file.\nThe code will look something like this\n\nCodefor (region in unique_regions) {\n  \n  # Step 1: filter the data sets\n  # Step 2: write the data sets\n  # Step 3: save the excel template with different name\n  # Step 4: load the renamed Excel file\n  # Step 5: run macro\n}\n\n\nLet‚Äôs populate the above for loop with the code we need.\n\nCodefor (curr_region in unique_regions) {\n  \n  # Step 1: filter the data sets\n  \n  # Slide 1\n  S1_title <- paste(curr_region, \"Population\")\n  S1_subtitle <- paste(\"Vishal Katti\",\"|\",format(Sys.Date(),\"%b %d, %Y\"), sep = \"   \")\n  \n  # Slide 2\n  S2_title <- paste(curr_region, \"Population since 1952\")\n  \n  S2_top4 <- top4        %>% filter(region == all_of(curr_region)) %>% select(-region) %>% arrange(desc(`2007`))\n  S2_others <- others    %>% filter(region == all_of(curr_region)) %>% select(-region)\n  S2_top5 <- bind_rows(S2_top4, S2_others)\n  \n  S2_table <- pop_groups %>% filter(region == all_of(curr_region)) %>% select(-region)\n  \n  # Slide 3\n  S3_title <- paste(\"Top 10 most populated countries in\", curr_region)\n  \n  S3_chart <- top10      %>% filter(region == all_of(curr_region)) %>% select(-region)\n  \n  S3_factoid <- paste(\"The population of\", S3_chart$country[1], \"is approx.\",\n                      round(S3_chart$population[1]/S3_chart$population[10], 0),\n                      \"times that of\", S3_chart$country[10])\n  \n  # Step 2: write the data sets\n  \n  # Load the template\n  wb <- loadWorkbook(\"path/to/template/XL2PPT.xlsm\") # relative to this R script\n  sht <- \"Sheet1\"\n  \n  # write data to coordinate (col, row)\n  writeData(wb, sht, S1_title,    xy = c(3, 3),  colNames = FALSE)\n  writeData(wb, sht, S1_subtitle, xy = c(3, 4),  colNames = FALSE)\n  writeData(wb, sht, S2_title,    xy = c(3, 7),  colNames = FALSE)\n  writeData(wb, sht, S2_top5,     xy = c(3, 9),  colNames = TRUE)\n  writeData(wb, sht, S2_table,    xy = c(18, 9), colNames = TRUE)\n  writeData(wb, sht, S3_title,    xy = c(3, 18), colNames = FALSE)\n  writeData(wb, sht, S3_factoid,  xy = c(3, 19), colNames = FALSE)\n  writeData(wb, sht, S3_chart,    xy = c(3, 21), colNames = TRUE)\n  \n  # Step 3: save the excel template with different name\n  saveWorkbook(wb, \"path/to/template/XL2PPT_edited.xlsm\", overwrite = TRUE)\n  gc(verbose = TRUE)\n  Sys.sleep(2)\n  \n  # Step 4: load the renamed Excel file\n  # Create Excel Application\n  xlApp <- COMCreate(\"Excel.Application\")\n\n  # Open the Macro Excel book\n  xlWbk <- xlApp$Workbooks()$Open(normalizePath(\"path/to/template/XL2PPT_edited.xlsm\", winslash = \"/\")) # Change to your directory\n  # its ok to run macro without visible excel application\n  # If you want to see your workbook, please set it to TRUE\n  xlApp[[\"Visible\"]] <- FALSE\n  \n  # Step 5: run macro\n  xlApp$Run(\"Create_Continental_Deck\") # Name of Macro to run\n\n  xlWbk$Close(TRUE) # save and close excel book\n  xlApp$Quit()\n  gc(verbose = TRUE)\n  Sys.sleep(2)\n}\n\n\nOnce the code runs completely, you will see 4 new PowerPoint Presentations in your working folder.\n\n\nFigure¬†6: Output Files\n\n\n\nYou can download the full R script from here."
  },
  {
    "objectID": "posts/R2VBA2PPT2/index.html#references-citations",
    "href": "posts/R2VBA2PPT2/index.html#references-citations",
    "title": "Unholy Trinity of R, Excel VBA and Powerpoint - Part 2 of 2",
    "section": "References & Citations",
    "text": "References & Citations\n\nJennifer Bryan (2017). gapminder: Data from Gapminder. R package version 0.3.0. https://CRAN.R-project.org/package=gapminder\nHadley Wickham, Romain Francois, Lionel Henry and Kirill Muller (2021). dplyr: A Grammar of Data Manipulation. R package version 1.0.7. https://CRAN.R-project.org/package=dplyr\nHadley Wickham (2021). tidyr: Tidy Messy Data. R package version 1.1.3. https://CRAN.R-project.org/package=tidyr\nGreg Lin (2020). reactable: Interactive Data Tables Based on ‚ÄòReact Table‚Äô. R package version 0.2.3. https://CRAN.R-project.org/package=reactable\nPhilipp Schauberger and Alexander Walker (2021). openxlsx: Read, Write and Edit xlsx Files. R package version 4.2.4. https://CRAN.R-project.org/package=openxlsx\nDuncan Temple Lang (NA). RDCOMClient: R-DCOM client. http://www.omegahat.net/RDCOMClient, http://www.omegahat.net http://www.omegahat.net/bugs.\nhttps://docs.microsoft.com/en-us/office/vba/api/overview/excel\nhttps://docs.microsoft.com/en-us/office/vba/api/overview/powerpoint"
  },
  {
    "objectID": "posts/tidyr-pivot-longer/index.html",
    "href": "posts/tidyr-pivot-longer/index.html",
    "title": "Pivoting your tables with Tidyr: Part I",
    "section": "",
    "text": "The wide one\nConsider the following data table. It has been created from the famous Gapminder dataset. This table shows the average life expectancy in each continent for 2 years. While some of you may say that Gapminder data contains records for a lot more number of years, here we consider just the latest 2 years for ease of explanation and visual purposes.\n\n\n\nFigure¬†1: Continent-wise Average Life Expectancy over last 2 years\n\n\n\n\n\n\nFigure¬†2: The wide one\n\n\n\nmy_data is in the wide format as we have continent names in column headers and average life expectancy values in each of those columns. To convert this tibble to the long format, we need to pull together the continent names in one column and their corresponding values into another column. See Figure¬†2\nThe long one\nThe long format of this table would ideally have only year, continent and average_life_expectancy columns and look something like the table below.\n\n\n\nFigure¬†3: The long one\n\n\n\nThe long format has repeated values of the column that are not gathered/collected. In this case, the year column gets its values repeated for each row.\nLet‚Äôs recreate the above transformation in R. First, we create the my_data table.\n\nCodemy_data <- data.frame(\n  year     = c(2002L, 2007L), \n  Africa   = c(53.33, 54.81), \n  Americas = c(72.42, 73.61), \n  Asia     = c(69.23, 70.73), \n  Europe   = c(76.70, 77.65), \n  Oceania  = c(79.74, 80.72)\n)\n\nknitr::kable(my_data)\n\n\n\nyear\nAfrica\nAmericas\nAsia\nEurope\nOceania\n\n\n\n2002\n53.33\n72.42\n69.23\n76.70\n79.74\n\n\n2007\n54.81\n73.61\n70.73\n77.65\n80.72\n\n\n\n\n\nTo convert this table into long format, we use the pivot_longer() function from {tidyr} R package. Let us see how to use this function.\n\n\n\n\n\n\nTip\n\n\n\nUse `formals` to view all the formal arguments of a function and their default values. `formals` returns a named list.\n\n\n\nCodelibrary(tidyr, quietly = TRUE, warn.conflicts = FALSE)\n\nformals(pivot_longer)\n\n$data\n\n\n$cols\n\n\n$names_to\n[1] \"name\"\n\n$names_prefix\nNULL\n\n$names_sep\nNULL\n\n$names_pattern\nNULL\n\n$names_ptypes\nNULL\n\n$names_transform\nNULL\n\n$names_repair\n[1] \"check_unique\"\n\n$values_to\n[1] \"value\"\n\n$values_drop_na\n[1] FALSE\n\n$values_ptypes\nNULL\n\n$values_transform\nNULL\n\n$...\n\n\nThe result of formals(pivot_longer) tells us that the minimum information needed to use this function is to provide values to the data and cols arguments as all other arguments have default values and hence, are optional.\nUsing only the minimum arguments with pivot_longer(), we get a long formatted tibble with the columns year, name and value.\n\nCodelong_minimal <- pivot_longer(\n                        data      = my_data,\n                        cols      = c(\"Africa\", \"Americas\", \"Asia\", \"Europe\", \"Oceania\")\n                        )\n\nknitr::kable(long_minimal)\n\n\n\nyear\nname\nvalue\n\n\n\n2002\nAfrica\n53.33\n\n\n2002\nAmericas\n72.42\n\n\n2002\nAsia\n69.23\n\n\n2002\nEurope\n76.70\n\n\n2002\nOceania\n79.74\n\n\n2007\nAfrica\n54.81\n\n\n2007\nAmericas\n73.61\n\n\n2007\nAsia\n70.73\n\n\n2007\nEurope\n77.65\n\n\n2007\nOceania\n80.72\n\n\n\n\n\nNotice that the continent names and their corresponding average life expectancy values appear in columns named name and value. These are the default column names. We can change these column names by providing our own names to the arguments names_to and values_to.\nSince the year column is the only one that remains as is, we can rewrite the above pivot_longer statement as below\n\nCodemy_data_longer <- pivot_longer(data      = my_data,\n                               cols      = !year,\n                               names_to  = \"continent\",\n                               values_to = \"average_life_expectancy\")\n\nknitr::kable(my_data_longer)\n\n\n\nyear\ncontinent\naverage_life_expectancy\n\n\n\n2002\nAfrica\n53.33\n\n\n2002\nAmericas\n72.42\n\n\n2002\nAsia\n69.23\n\n\n2002\nEurope\n76.70\n\n\n2002\nOceania\n79.74\n\n\n2007\nAfrica\n54.81\n\n\n2007\nAmericas\n73.61\n\n\n2007\nAsia\n70.73\n\n\n2007\nEurope\n77.65\n\n\n2007\nOceania\n80.72\n\n\n\n\n\nIf you are a visual person like me and wish to see this transformation with explanations, check out this GIF I made using good ol‚Äô Powerpoint.\n\n\n\nFigure¬†4: {tidyr} pivot_longer() explained\n\n\n\nConclusion\npivot_longer() is the successor for the great gather() function and has many advantages over the latter. pivot_longer() repeats all the values in the columns that are not included in the cols argument. Therefore, if your dataframe/tibble had a primary key prior to the transformation, the primary key of your transformed ‚Äúlonger‚Äù dataframe is your old primary key + the new column created by names_to. This function has many other arguments that allow some truly great transformations. Mastering this function (and its wide counterpart) is a great skill upgrade while massaging your data to make it ‚Äútidy‚Äù.\nHappy Gathering!\nReferences\n\nHadley Wickham and Maximilian Girlich (2022). tidyr: Tidy Messy Data. R package version 1.2.0. https://CRAN.R-project.org/package=tidyr\n\nYihui Xie (2022). knitr: A General-Purpose Package for Dynamic Report Generation in R. R package version 1.39.\n\n\n\nFootnotes\n\nLong vs.¬†Wide Data: What‚Äôs the Difference? https://www.statology.org/long-vs-wide-data/‚Ü©Ô∏é\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{katti2022,\n  author = {Vishal Katti},\n  editor = {},\n  title = {Pivoting Your Tables with {Tidyr:} {Part} {I}},\n  date = {2022-07-08},\n  url = {https://vishalkatti.com/posts/tidyr-pivot-longer},\n  langid = {en},\n  abstract = {This post demonstrates how to use `pivot\\_longer()` to\n    convert your wide data to long data. This is part 1 of the Pivoting\n    your tables with Tidyr series.}\n}\nFor attribution, please cite this work as:\nVishal Katti. 2022. ‚ÄúPivoting Your Tables with Tidyr: Part\nI.‚Äù July 8, 2022. https://vishalkatti.com/posts/tidyr-pivot-longer."
  },
  {
    "objectID": "posts/tidyr-pivot-wider/index.html",
    "href": "posts/tidyr-pivot-wider/index.html",
    "title": "Pivoting your tables with Tidyr: Part II",
    "section": "",
    "text": "The long one\nConsider the following data table. It has been created from the famous Gapminder dataset. This table shows the average life expectancy in each continent for 2 years. While some of you may say that Gapminder data contains records for a lot more number of years, here we consider just the latest 2 years for ease of explanation and visual purposes. We have added an extra id column for teaching purpose.\n\n\nFigure¬†1: Continent-wise Average Life-expectancy over last 2 years, in Long format\n\n\n\nmy_data is in the long format as we have continent names and year in their own column and average life expectancy values for each unique combination of year and continent. If we want to compare life expectancy across years for each continent, we need to have the life expectancy values for each continent side-by-side for easier viewing i.e.¬†we need to convert to the wide format. To convert this tibble to the wide format, we need to push the year values into the headers and the average_life_expectancy values under the corresponding year column.\nThe wide one\nThe wide format of this table would ideally have only continent and columns having each unique value in the year column as a header. In this case, the wide one would look something like the table below.\n\n\nFigure¬†2: Same as Figure¬†1 but in Wide format\n\n\n\nThe wide format has unique values of the column that are not pushed into headers. In this case, the continent column becomes unique for each row.\nLet‚Äôs recreate the above transformation in R. First, we create the my_data table.\n\nCodemy_data <- data.frame(\n  id = 1:10,\n  year = c(2002L, 2002L, 2002L, 2002L, 2002L, 2007L, 2007L, 2007L, 2007L, 2007L),\n  continent = c(\"Africa\", \"Americas\", \"Asia\", \"Europe\", \"Oceania\", \"Africa\", \n                \"Americas\", \"Asia\", \"Europe\", \"Oceania\"),\n  average_life_expectancy = c(53.33, 72.42, 69.23, 76.7, 79.74, 54.81, 73.61, 70.73, 77.65, 80.72)\n)\n\nknitr::kable(my_data)\n\n\n\nid\nyear\ncontinent\naverage_life_expectancy\n\n\n\n1\n2002\nAfrica\n53.33\n\n\n2\n2002\nAmericas\n72.42\n\n\n3\n2002\nAsia\n69.23\n\n\n4\n2002\nEurope\n76.70\n\n\n5\n2002\nOceania\n79.74\n\n\n6\n2007\nAfrica\n54.81\n\n\n7\n2007\nAmericas\n73.61\n\n\n8\n2007\nAsia\n70.73\n\n\n9\n2007\nEurope\n77.65\n\n\n10\n2007\nOceania\n80.72\n\n\n\n\n\nTo convert this table into wide format, we use the pivot_wider() function from {tidyr} R package. Let us see how to use this function.\n\n\n\n\n\n\nTip\n\n\n\nUse formals to view all the formal arguments of a function and their default values. formals returns a named list.\n\n\n\nCodelibrary(tidyr, quietly = TRUE, warn.conflicts = FALSE)\n\nformals(pivot_wider)\n\n$data\n\n\n$id_cols\nNULL\n\n$id_expand\n[1] FALSE\n\n$names_from\nname\n\n$names_prefix\n[1] \"\"\n\n$names_sep\n[1] \"_\"\n\n$names_glue\nNULL\n\n$names_sort\n[1] FALSE\n\n$names_vary\n[1] \"fastest\"\n\n$names_expand\n[1] FALSE\n\n$names_repair\n[1] \"check_unique\"\n\n$values_from\nvalue\n\n$values_fill\nNULL\n\n$values_fn\nNULL\n\n$unused_fn\nNULL\n\n$...\n\n\nThe result of formals(pivot_wider) tells us that the minimum information needed to use this function is to provide values to the data,names_from and values_from arguments as all other arguments have default values and hence, are optional.\nUsing only the minimum arguments with pivot_wider(), we get a wide formatted tibble but with missing data!\n\nCodewide_minimal <- pivot_wider(\n                        data        = my_data,\n                        names_from  = year,\n                        values_from = average_life_expectancy\n                        )\n\nknitr::kable(wide_minimal)\n\n\n\nid\ncontinent\n2002\n2007\n\n\n\n1\nAfrica\n53.33\nNA\n\n\n2\nAmericas\n72.42\nNA\n\n\n3\nAsia\n69.23\nNA\n\n\n4\nEurope\n76.70\nNA\n\n\n5\nOceania\n79.74\nNA\n\n\n6\nAfrica\nNA\n54.81\n\n\n7\nAmericas\nNA\n73.61\n\n\n8\nAsia\nNA\n70.73\n\n\n9\nEurope\nNA\n77.65\n\n\n10\nOceania\nNA\n80.72\n\n\n\n\n\nSo why did NAs appear in the result?\npivot_wider() creates unique combinations of all columns not included in names_from or values_from argument. Therefore, if your dataframe/tibble had a primary key prior to the transformation, the primary key of your transformed ‚Äúwide‚Äù dataframe is your old primary key + unique combinations of all columns not included in names_from or values_from argument. We do have id column as a primary key in the original tibble. This gives an unusable output with NAs for each combination.\nTo specify which column/s to be made unique, pass their name to the id_cols argument. Here we pass the continent column to the id_cols argument.\n\nCodemy_data_longer <- pivot_wider(\n                        data        = my_data,\n                        id_cols     = continent, \n                        names_from  = year,\n                        values_from = average_life_expectancy\n                        )\n\nknitr::kable(my_data_longer)\n\n\n\ncontinent\n2002\n2007\n\n\n\nAfrica\n53.33\n54.81\n\n\nAmericas\n72.42\n73.61\n\n\nAsia\n69.23\n70.73\n\n\nEurope\n76.70\n77.65\n\n\nOceania\n79.74\n80.72\n\n\n\n\n\nIf you are a visual person like me and wish to see this transformation with explanations, check out this GIF I made using good ol‚Äô PowerPoint.\n\n\n\n{tidyr} pivot_wider() explained\n\n\n\nConclusion\npivot_wider() is the successor for the great spread() function and has many advantages over the latter. This function has many other arguments that allow some truly great transformations. Mastering this function (and its long counterpart) is a great skill upgrade while massaging your data to make it ‚Äútidy‚Äù.\nHappy Spreading!\nReferences\n\nLong vs.¬†Wide Data: What‚Äôs the Difference?\nHadley Wickham and Maximilian Girlich (2022). tidyr: Tidy Messy Data. R package version 1.2.0. https://CRAN.R-project.org/package=tidyr\n\nYihui Xie (2022). knitr: A General-Purpose Package for Dynamic Report Generation in R. R package version 1.39.\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{katti2022,\n  author = {Vishal Katti},\n  editor = {},\n  title = {Pivoting Your Tables with {Tidyr:} {Part} {II}},\n  date = {2022-08-29},\n  url = {https://vishalkatti.com/posts/tidyr-pivot-wider},\n  langid = {en},\n  abstract = {This post demonstrates how to use `pivot\\_wider()` to\n    convert your long data to wide data. This is part 2 of the Pivoting\n    your tables with Tidyr series.}\n}\nFor attribution, please cite this work as:\nVishal Katti. 2022. ‚ÄúPivoting Your Tables with Tidyr: Part\nII.‚Äù August 29, 2022. https://vishalkatti.com/posts/tidyr-pivot-wider."
  },
  {
    "objectID": "posts/writing-robust-functions/index.html",
    "href": "posts/writing-robust-functions/index.html",
    "title": "Writing Robust R Functions",
    "section": "",
    "text": "Functions in R ( or any other programming language in general) allow us to encapsulate some lines of code that we want to run again and again. Functions are the natural outcome of the DRY1 principle. Functions group together a couple of lines of consistent logic making our code modular and consequently, easy to manage. However, when we write functions, we need to ensure that they behave exactly as we want them to and are able to handle whatever we throw at them. By whatever, I mean any and all kinds of inputs. The idea of creating unbreakable code is idealistic. I say this since creating robust functions requires additional code to handle the unwanted inputs and most useRs write functions during some one-time analysis. Hence we need to be pragmatic about how much time and effort we spend trying to make our functions robust. Maybe, we need our functions to be just robust enough! All I am saying is, if you are creating functions that will be used by you and only you i.e.¬†if you have absolute control over what inputs would be provided to your functions, then you can forego certain checks and the functions need not be unbreakable. But, if you intend to write functions that will be used by a larger audience, you need to ensure that such functions are able to handle all kinds of innocent and malicious intents."
  },
  {
    "objectID": "posts/writing-robust-functions/index.html#what-do-we-mean-by-robust-functions",
    "href": "posts/writing-robust-functions/index.html#what-do-we-mean-by-robust-functions",
    "title": "Writing Robust R Functions",
    "section": "What do we mean by Robust Functions?",
    "text": "What do we mean by Robust Functions?\nYou must be familiar with the Garbage-In-Garbage-Out philosophy of Software engineering. We can think of it in terms of functions, that, given garbage or bad input, you get garbage or bad output. For a function to be robust, it must behave in a consistent manner for known and correct inputs, however, more importantly, it mustn‚Äôt give us garbage for bad inputs. Rather, it must provide useful output (as messages or instructions) which can be further used to inform the end-user about possible problems in the inputs to drive proper usage. The useful output/s in case of bad inputs would ideally be a combination of clean early exit and easy-to-understand error messages. So we shall try to implement Garbage-In-Useful-Info-Out by looking at some ways we can build well-behaved and reliable functions.\nInput values passed to a function are more popularly known as arguments or parameters. A robust function must validate the function arguments before proceeding to implement the function logic. If this is not done, then the bad arguments will cause some errors in the logic and display error messages that the end-user may not be familiar with. Worst-case scenario is when the function doesn‚Äôt encounter any errors and just gives bad results!! Surely, we do not want this unpredictable behavior.\n\n\n\nSource: imgflip.com"
  },
  {
    "objectID": "posts/writing-robust-functions/index.html#our-sweet-innocent-and-naive-function",
    "href": "posts/writing-robust-functions/index.html#our-sweet-innocent-and-naive-function",
    "title": "Writing Robust R Functions",
    "section": "Our sweet, innocent and naive Function",
    "text": "Our sweet, innocent and naive Function\nConsider the following function make_date that takes 3 numeric inputs yyyy, mm and dd and returns a single `Date` object.\n\nCodemake_date <-  function(yyyy, mm, dd) {\n  \n  # main logic : Concatenate the values and convert to Date\n  as.Date(paste(yyyy, mm, dd, sep = \"-\"), format = \"%Y-%m-%d\")\n}\n\nmy_date <- make_date(yyyy = 2022, mm = 1, dd = 31)\nmy_date\n\n[1] \"2022-01-31\"\n\nCodeclass(my_date)\n\n[1] \"Date\"\n\n\nWe will use make_date to demonstrate a couple of scenarios where this function can fail and the methods to safeguard against such scenarios."
  },
  {
    "objectID": "posts/writing-robust-functions/index.html#scenario-1-missing-arguments",
    "href": "posts/writing-robust-functions/index.html#scenario-1-missing-arguments",
    "title": "Writing Robust R Functions",
    "section": "Scenario 1: Missing Arguments",
    "text": "Scenario 1: Missing Arguments\nThe most basic check we should perform before running the function logic is to confirm if all the required arguments are available. Think about how your function should behave if one of the arguments, suppose mm is missing.\n\nCodemake_date(yyyy = 2022, dd = 31)\nError in paste(yyyy, mm, dd, sep = \"-\"): argument \"mm\" is missing, with no default\n\n\nNote that the error message shown to the user, is triggered, not from our function make_date but from the internal paste function. We do not have any control over what error messages are shown when errors occur. In this case, we know specifically that this error is due to a missing argument.\nThere are two ways to handle missing arguments:\n1.1 Early Exit\nIf a certain required argument is missing, we can stop the execution of the function and show informative error message about which argument is missing. Your friends here are the missing and stop functions. The missing function checks if the given argument is missing or is set to NULL and returns TRUE, else it returns FALSE. The stop function stops the execution and displays the custom error message we provide. Using these functions inside an if condition will let us check for missing arguments. Let us modify our naive function to stop early when required arguments are missing.\n\nCodemake_date <-  function(yyyy, mm, dd) {\n  \n  # check missing arguments\n  if (missing(yyyy)) stop(\"argument `yyyy` is required.\")\n  if (missing(mm))   stop(\"argument `mm` is required.\")\n  if (missing(dd))   stop(\"argument `dd` is required.\")\n  \n  # main logic\n  as.Date(paste(yyyy, mm, dd, sep = \"-\"), format = \"%Y-%m-%d\")\n}\n\n# Calling the function without `mm` argument\nmake_date(yyyy = 2022, dd = 31)\nError in make_date(yyyy = 2022, dd = 31): argument `mm` is required.\n\n\nNote that here, we add three if-missing-stop statements, one for each required argument. We must do this if we want to display specific error messages for each argument. There is another way to do the same but we will look at it later. If we want to display a single error message, we can do so by clubbing the missing functions inside an any which will return TRUE if any one of the arguments is missing. However, providing clear error messages becomes challenging in this method.\n\nCodedummy_fun <- function(a, b, c) { \n  if(any(missing(a), missing(b), missing(c))) {\n    stop(\"One or more required arguments missing.\")\n  }\n  # Do something...\n}\ndummy_fun(a = 1)\nError in dummy_fun(a = 1): One or more required arguments missing.\n\n\n1.2 Sensible defaults with warnings\nIn some cases, we may need the function to use some sensible default value for the required arguments and continue execution. Here, we display a warning message instead of an error message. This is required when the argument value is either considered to be obvious or the argument is not necessarily the most important one and is used only in extreme customization. Providing default values to arguments makes them optional arguments. An example of default argument values can be seen in the paste function we have used earlier. The default value of the separator argument sep is a single whitespace character.\n\nCodeargs(paste)\n\nfunction (..., sep = \" \", collapse = NULL, recycle0 = FALSE) \nNULL\n\n\nSimilarly, we can provide some sensible defaults for the make_date function. Let‚Äôs modify the function further to provide defaults for the mm and dd arguments only.\n\nCodemake_date <-  function(yyyy, mm = 1, dd = 1) {\n  \n  # check missing arguments\n  if (missing(yyyy))  stop(\"argument `yyyy` is required.\") \n  if (missing(mm)) warning(\"argument `mm` is missing. Using default value mm = 1 instead\") \n  if (missing(dd)) warning(\"argument `dd` is missing. Using default value dd = 1 instead\")\n  \n  # main logic\n  as.Date(paste(yyyy, mm, dd, sep = \"-\"), format = \"%Y-%m-%d\")\n}\n\n# Calling the function without `mm` and `dd` arguments\nmake_date(yyyy = 2022) # here, only `yyyy` is the required argument.\nWarning in make_date(yyyy = 2022): argument `mm` is missing. Using default value\nmm = 1 instead\n\nWarning in make_date(yyyy = 2022): argument `dd` is missing. Using default value\ndd = 1 instead\n\n\n[1] \"2022-01-01\"\n\n\nThere are a few concerns about using warnings instead of error messages. Some are listed here in this article from RBloggers A Warning About warning."
  },
  {
    "objectID": "posts/writing-robust-functions/index.html#scenario-2-invalid-argument-data-type",
    "href": "posts/writing-robust-functions/index.html#scenario-2-invalid-argument-data-type",
    "title": "Writing Robust R Functions",
    "section": "Scenario 2: Invalid Argument Data Type",
    "text": "Scenario 2: Invalid Argument Data Type\nWe have defined make_date to accept 3 numeric arguments i.e.¬†all 3 must be numbers. What would happen if someone tried to call make_date with character, factor or boolean inputs?\n\nCodemake_date(yyyy = \"2022\", mm = \"5\", dd = \"20\") # works!! why?\n\n[1] \"2022-05-20\"\n\n\nIn this case, the function works because when the arguments are combined into a single string using paste , it matches the format argument of the as.Date function in the main logic of make_date which is as.Date(paste(yyyy, mm, dd, sep = \"-\"), format = \"%Y-%m-%d\")\n\nCodemake_date(yyyy = \"2022\", mm = \"May\", dd = \"1\") # works but shows NA !!!\n\n[1] NA\n\n\nIn this case, all the arguments pass the checks but since we pass 2022-May-1 to as.Date which doesn‚Äôt match the format = '%Y-%m-%d' thus giving NA.\nHow do we check if the values provided to the arguments are numbers or number-like? If the values are numbers, we let them pass. But if they are non-numeric, we must check if they can be converted to numbers i.e. we must check if they are number-like. By number-like, I mean, will coercing the value using as.numeric give us a numeric value or NA ? You guessed it right, we will pass the values through as.numeric and check if the output is NA or not.\nWhat are the various data types in R that are not numeric but can look like numbers? We have character, factor and boolean data types which can behave like numbers sometimes. Let‚Äôs see a few scenarios.\nCharacter arguments\n\nCodeYear <- c(\"2022\", \"TwentyTwo\")\nYear_num <- as.numeric(Year) # this should show a warning about NAs introduced by coercion\nWarning: NAs introduced by coercion\n\nCodeYear_num # must show the number 2022 without quotes and one NA\n\n[1] 2022   NA\n\n\nAs you can see in above example, when passed through as.numeric, the value ‚Äú2022‚Äù gets converted to the number 2022 but the value ‚ÄúTwentyTwo‚Äù does not. Hence we can say ‚Äú2022‚Äù is number-like but ‚ÄúTwentyTwo‚Äù is not.\nFactor arguments\n\nCodeYear <- factor(c(\"2022\",\"2021\",\"TwentyTwo\"))\nas.numeric(Year)\n\n[1] 2 1 3\n\nCodeYearX <- factor(c(\"2022\", \"X\"))\nas.numeric(YearX)\n\n[1] 1 2\n\nCodeYearY <- factor(2022)\nas.numeric(YearY)\n\n[1] 1\n\n\nAs you can see from above examples, factor values do get converted to numeric but do not give the right results. So we can safely say that factors are not number-like.\nI will ignore boolean data types hoping that useRs are bright enough to not use Booleans while creating a Date!\nFrom the above examples, we can conclude that numeric values and number-like character values are the only valid data types that should be allowed. Modifying our make_date function to include data type checks.\n\nCodemake_date <-  function(yyyy, mm = 1, dd = 1) {\n  \n  # check missing arguments\n  if (missing(yyyy))  stop(\"argument `yyyy` is required.\") \n  if (missing(mm)) warning(\"argument `mm` is missing. Using default value mm = 1 instead\") \n  if (missing(dd)) warning(\"argument `dd` is missing. Using default value dd = 1 instead\")\n  \n  # Check data types\n  if (!is.numeric(yyyy) & !is.character(yyyy)) {\n    stop(\"argument `yyyy` must be numeric\")\n  } else if (is.character(yyyy) & is.na(as.numeric(yyyy))) {\n    stop(\"argument `yyyy` must be numeric\")\n  }\n  if (!is.numeric(mm) & !is.character(mm)) {\n    stop(\"argument `mm` must be numeric\")\n  } else if (is.character(mm) & is.na(as.numeric(mm))) {\n    stop(\"argument `mm` must be numeric\")\n  }\n  if (!is.numeric(dd) & !is.character(dd)) {\n    stop(\"argument `dd` must be numeric\")\n  } else if (is.character(dd) & is.na(as.numeric(dd))) {\n    stop(\"argument `dd` must be numeric\")\n  }\n  \n  # main logic\n  as.Date(paste(yyyy, mm, dd, sep = \"-\"), format = \"%Y-%m-%d\")\n}\n\n# Calling the function with new datatype checks\nmake_date(yyyy = \"2022\", mm = \"May\", dd = \"1\")\nWarning in make_date(yyyy = \"2022\", mm = \"May\", dd = \"1\"): NAs introduced by\ncoercion\n\nError in make_date(yyyy = \"2022\", mm = \"May\", dd = \"1\"): argument `mm` must be numeric\n\nCodemake_date(yyyy = \"2022\", mm = factor(\"5\"), dd = \"1\")\nError in make_date(yyyy = \"2022\", mm = factor(\"5\"), dd = \"1\"): argument `mm` must be numeric\n\n\nNotice that the datatype check is lengthy and similar for all 3 arguments. We can apply DRY principle again and encapsulate that code into a small function is_numberlike which will return TRUE or FALSE . Note that is_numberlike has no checks because it is an internal function.\n\nCode# This function check if value is number or number-like.\nis_numberlike <- function(x){\n  if (!is.numeric(x) & !is.character(x)) {\n    # Early Exit 1 if value is neither numeric nor character\n    return(FALSE) \n  } else if (is.character(x) & is.na(as.numeric(x))) {\n    # Early Exit 2 if character value is not number-like.\n    return(FALSE) \n  }\n  return(TRUE)\n}\n\n\nThus our make_date function with data types check will look as below.\n\nCodemake_date <-  function(yyyy, mm = 1, dd = 1) {\n  \n  # check missing arguments\n  if (missing(yyyy))  stop(\"argument `yyyy` is required.\") \n  if (missing(mm)) warning(\"argument `mm` is missing. Using default value mm = 1 instead\") \n  if (missing(dd)) warning(\"argument `dd` is missing. Using default value dd = 1 instead\")\n  \n  # Check data types\n  if (!is_numberlike(yyyy)) stop(\"argument `yyyy` must be numeric\")\n  if (!is_numberlike(mm))   stop(\"argument `mm` must be numeric\")\n  if (!is_numberlike(dd))   stop(\"argument `dd` must be numeric\")\n  \n  # main logic\n  as.Date(paste(yyyy, mm, dd, sep = \"-\"), format = \"%Y-%m-%d\")\n}\n\n# Calling the function with new datatype checks\nmake_date(yyyy = \"TwentyTwo\", mm = \"5\", dd = 1)\nWarning in is_numberlike(yyyy): NAs introduced by coercion\n\nError in make_date(yyyy = \"TwentyTwo\", mm = \"5\", dd = 1): argument `yyyy` must be numeric\n\nCodemake_date(yyyy = \"2022\", mm = factor(\"5\"), dd = \"1\")\nError in make_date(yyyy = \"2022\", mm = factor(\"5\"), dd = \"1\"): argument `mm` must be numeric\n\nCodemake_date(yyyy = 2022, mm = 5, dd = \"one\")\nWarning in is_numberlike(dd): NAs introduced by coercion\n\nError in make_date(yyyy = 2022, mm = 5, dd = \"one\"): argument `dd` must be numeric\n\n\nOne of the most interesting features of R is vectorization! Due to this feature, our function make_date behaves in interesting ways. In some cases, it is desirable and sometimes it is not.\n\nCodemake_date(yyyy = 2022, mm = 1:12, dd = \"1\")\nWarning in if (is.character(x) & is.na(as.numeric(x))) {: the condition has\nlength > 1 and only the first element will be used\n\n\n [1] \"2022-01-01\" \"2022-02-01\" \"2022-03-01\" \"2022-04-01\" \"2022-05-01\"\n [6] \"2022-06-01\" \"2022-07-01\" \"2022-08-01\" \"2022-09-01\" \"2022-10-01\"\n[11] \"2022-11-01\" \"2022-12-01\"\n\n\nNote the above warnings. These warnings appear because the if statement checks if the condition provided results in a single TRUE or FALSE value. However, the output of the check is.na(as.numeric(mm)) is a boolean vector of length 12. But if needs only 1 TRUE or FALSE.\nThe output contains 12 date values since paste is vectorised, it recycles the values for yyyy and dd to give us 12 dates!\n\nCodemm <- 1:12\npaste(\"Month\", mm)\n\n [1] \"Month 1\"  \"Month 2\"  \"Month 3\"  \"Month 4\"  \"Month 5\"  \"Month 6\" \n [7] \"Month 7\"  \"Month 8\"  \"Month 9\"  \"Month 10\" \"Month 11\" \"Month 12\"\n\n\nWhat do we do if we want make_date to return just one date?"
  },
  {
    "objectID": "posts/writing-robust-functions/index.html#scenario-3-incorrect-argument-size",
    "href": "posts/writing-robust-functions/index.html#scenario-3-incorrect-argument-size",
    "title": "Writing Robust R Functions",
    "section": "Scenario 3: Incorrect Argument Size",
    "text": "Scenario 3: Incorrect Argument Size\nTo ensure make_date gives you just one date, we must ensure that the arguments have just value and is not a vector of multiple values i.e. length(arg)==1. Let‚Äôs further add a few checks for the data size of the arguments and rearrange the checks.\n\nCodemake_date <-  function(yyyy, mm = 1, dd = 1) {\n  \n  # check missing arguments\n  if (missing(yyyy))  stop(\"argument `yyyy` is required.\") \n  if (missing(mm)) warning(\"argument `mm` is missing. Using default value mm = 1 instead\") \n  if (missing(dd)) warning(\"argument `dd` is missing. Using default value dd = 1 instead\")\n  \n  # Check argument lengths\n  if (length(yyyy)!=1) stop(paste0(\"Length of argument `yyyy` is \", length(yyyy),\". Must be only 1.\"))\n  if (length(mm)!=1)   stop(paste0(\"Length of argument `mm` is \", length(mm),\". Must be only 1.\"))\n  if (length(dd)!=1)   stop(paste0(\"Length of argument `dd` is \", length(dd),\". Must be only 1.\"))\n  \n  # Check data types\n  if (!is_numberlike(yyyy)) stop(\"argument `yyyy` must be numeric\")\n  if (!is_numberlike(mm))   stop(\"argument `mm` must be numeric\")\n  if (!is_numberlike(dd))   stop(\"argument `dd` must be numeric\")\n  \n  # main logic\n  as.Date(paste(yyyy, mm, dd, sep = \"-\"), format = \"%Y-%m-%d\")\n}\n\n# Calling function with new data size checks\nmake_date(yyyy = 2022, mm = 1:12, dd = \"01\")\nError in make_date(yyyy = 2022, mm = 1:12, dd = \"01\"): Length of argument `mm` is 12. Must be only 1.\n\nCodemake_date(yyyy = c(\"2021\",\"2022\"), mm = \"1\", dd = 1)\nError in make_date(yyyy = c(\"2021\", \"2022\"), mm = \"1\", dd = 1): Length of argument `yyyy` is 2. Must be only 1.\n\nCodemake_date(yyyy = 2022, mm = 1, dd = c(\"1\",\"2\"))\nError in make_date(yyyy = 2022, mm = 1, dd = c(\"1\", \"2\")): Length of argument `dd` is 2. Must be only 1."
  },
  {
    "objectID": "posts/writing-robust-functions/index.html#a-little-detour",
    "href": "posts/writing-robust-functions/index.html#a-little-detour",
    "title": "Writing Robust R Functions",
    "section": "A little detour‚Ä¶",
    "text": "A little detour‚Ä¶\nSo far we checked for missing arguments, arguments with bad data types and arguments with incorrect sizes. We‚Äôve used the stop function along with if to check for all failure conditions and show appropriate error messages. When we use stop, we must specify all the failure conditions and the number of specific error messages goes up as number of arguments increases.\nIn case of our make_date, if an argument is not missing, it must be a number-like value of length 1. To reduce the number of error messages, we can combine the error messages for data type and length. for eg, the error message could be argument yyyy must be a number-like value of length 1.\nWouldn‚Äôt it be easier if we just specify what is the success condition aka the ‚Äúhappy path‚Äù, and show error for all other conditions? To do this, we can use the stopifnot function that let‚Äôs us specify all the happy paths. See example below.\n\nCodedummy_sum <- function(a, b, c){\n  \n  # check missing\n  stopifnot(!missing(a) & !missing(b) & !missing(c))\n  \n  # check argument values\n  stopifnot(!is.na(a) & is.numeric(a) & length(a)==1,\n            !is.na(b) & is.numeric(b) & length(b)==1,\n            !is.na(c) & is.numeric(c) & length(c)==1\n            )\n  sum(a, b, c)\n}\n\ndummy_sum(b = 2, c = 3) # a is missing\nError in dummy_sum(b = 2, c = 3): !missing(a) & !missing(b) & !missing(c) is not TRUE\n\nCodedummy_sum(a = NA_integer_, b = 2, c = 3) # a has NA value\nError in dummy_sum(a = NA_integer_, b = 2, c = 3): !is.na(a) & is.numeric(a) & length(a) == 1 is not TRUE\n\nCodedummy_sum(a = 1, b = \"2\", c = 3) # b has non-numeric value\nError in dummy_sum(a = 1, b = \"2\", c = 3): !is.na(b) & is.numeric(b) & length(b) == 1 is not TRUE\n\nCodedummy_sum(a = 1, b = 2, c = 5:7)  # c has length != 1\nError in dummy_sum(a = 1, b = 2, c = 5:7): !is.na(c) & is.numeric(c) & length(c) == 1 are not all TRUE\n\n\nNote the error messages above. They are not so user-friendly. Luckily, we can specify error messages in stopifnot by providing the error messages as the names of the ‚Äúhappy path‚Äù conditions.\n\nCodedummy_sum <- function(a, b, c){\n  \n  # check missing\n  stopifnot(\"one or more required arguments missing\" = !missing(a) & !missing(b) & !missing(c))\n  \n  # check argument values\n  stopifnot(\"argument `a` must not be NA, must be a number of length 1\" = !is.na(a) & is.numeric(a) & length(a)==1,\n            \"argument `b` must not be NA, must be a number of length 1\" = !is.na(b) & is.numeric(b) & length(b)==1,\n            \"argument `c` must not be NA, must be a number of length 1\" = !is.na(c) & is.numeric(c) & length(c)==1\n            )\n  sum(a, b, c)\n}\n\ndummy_sum(b = 2, c = 3) # a is missing\nError in dummy_sum(b = 2, c = 3): one or more required arguments missing\n\nCodedummy_sum(a = NA_integer_, b = 2, c = 3) # a has NA value\nError in dummy_sum(a = NA_integer_, b = 2, c = 3): argument `a` must not be NA, must be a number of length 1\n\nCodedummy_sum(a = 1, b = \"2\", c = 3) # b has non-numeric value\nError in dummy_sum(a = 1, b = \"2\", c = 3): argument `b` must not be NA, must be a number of length 1\n\nCodedummy_sum(a = 1, b = 2, c = 5:7)  # c has length != 1\nError in dummy_sum(a = 1, b = 2, c = 5:7): argument `c` must not be NA, must be a number of length 1\n\n\nUsing stopifnot in our make_date function to combine the datatype and length checks, we get‚Ä¶\n\nCodemake_date <-  function(yyyy, mm = 1, dd = 1) {\n  \n  # check missing arguments\n  if (missing(yyyy))  stop(\"argument `yyyy` is required.\") \n  if (missing(mm)) warning(\"argument `mm` is missing. Using default value mm = 1 instead\") \n  if (missing(dd)) warning(\"argument `dd` is missing. Using default value dd = 1 instead\")\n  \n  \n  # Check argument types and length\n  stopifnot(\n    \"argument `yyyy` must be numeric with length 1\" = is_numberlike(yyyy) & length(yyyy)==1,\n    \"argument `mm` must be numeric with length 1\"   = is_numberlike(mm)   & length(mm)==1,\n    \"argument `dd` must be numeric with length 1\"   = is_numberlike(dd)   & length(dd)==1\n  )\n  \n  # main logic\n  as.Date(paste(yyyy, mm, dd, sep = \"-\"), format = \"%Y-%m-%d\")\n}\n\nmake_date() # no arguments provided\nError in make_date(): argument `yyyy` is required.\n\nCodemake_date(yyyy = 2022, mm = 1:12, dd = 31) # Length mm not equal to 1\nWarning in if (is.character(x) & is.na(as.numeric(x))) {: the condition has\nlength > 1 and only the first element will be used\n\nError in make_date(yyyy = 2022, mm = 1:12, dd = 31): argument `mm` must be numeric with length 1\n\nCodemake_date(yyyy = 2022, mm = \"Jan\", dd = 31) # mm is not number-like\nWarning in is_numberlike(mm): NAs introduced by coercion\n\nError in make_date(yyyy = 2022, mm = \"Jan\", dd = 31): argument `mm` must be numeric with length 1\n\nCodemake_date(yyyy = 2022, dd = 31) # argument mm is missing but should work using default value\nWarning in make_date(yyyy = 2022, dd = 31): argument `mm` is missing. Using\ndefault value mm = 1 instead\n\n\n[1] \"2022-01-31\""
  },
  {
    "objectID": "posts/writing-robust-functions/index.html#scenario-4-values-of-arguments-that-result-in-invalid-outputs",
    "href": "posts/writing-robust-functions/index.html#scenario-4-values-of-arguments-that-result-in-invalid-outputs",
    "title": "Writing Robust R Functions",
    "section": "Scenario 4: Values of Arguments that result in invalid outputs",
    "text": "Scenario 4: Values of Arguments that result in invalid outputs\nFinally, what do we do when the arguments provided will definitely give us bad results despite passing all checks? In our case, make_date creates a date but if we give it values that will result in an invalid date, it will give us invalid results (remember Garbage-In-Garbage-Out?).\n\nCodemake_date(yyyy = 2022, mm = 13, dd = 1) # is there a 13th month?\n\n[1] NA\n\n\nWe get NA because as.Date returns NA for invalid inputs with no error messages or warnings! We can check the output and provide a generic error message.\n\nCodemake_date <-  function(yyyy, mm = 1, dd = 1) {\n  # check missing arguments\n  if (missing(yyyy))  stop(\"argument `yyyy` is required.\") \n  if (missing(mm)) warning(\"argument `mm` is missing. Using default value mm = 1 instead\") \n  if (missing(dd)) warning(\"argument `dd` is missing. Using default value dd = 1 instead\")\n  \n  \n  # Check argument types and length\n  stopifnot(\n    \"argument `yyyy` must be numeric with length 1\" = is_numberlike(yyyy) & length(yyyy)==1,\n    \"argument `mm` must be numeric with length 1\"   = is_numberlike(mm)   & length(mm)==1,\n    \"argument `dd` must be numeric with length 1\"   = is_numberlike(dd)   & length(dd)==1\n  )\n  \n  # main logic\n  out <- as.Date(paste(yyyy, mm, dd, sep = \"-\"), format = \"%Y-%m-%d\")\n  if (is.na(out)) {\n    stop(\"Invalid values provided. Please check your inputs.\")\n  }\n  return(out)\n}\n\nmake_date(yyyy = 2022, mm = 13, dd = 1) # is there a 13th month?\nError in make_date(yyyy = 2022, mm = 13, dd = 1): Invalid values provided. Please check your inputs.\n\nCodemake_date(yyyy = 2022, mm = 2, dd = 31) # are there 31 days in February?\nError in make_date(yyyy = 2022, mm = 2, dd = 31): Invalid values provided. Please check your inputs.\n\n\nDo you think our function make_date is robust enough?\n\n\n\nAs robust as Superman! Source: Imgur"
  },
  {
    "objectID": "posts/writing-robust-functions/index.html#conclusion",
    "href": "posts/writing-robust-functions/index.html#conclusion",
    "title": "Writing Robust R Functions",
    "section": "Conclusion",
    "text": "Conclusion\nMaking functions robust requires some prior thought about its intended use and audience. Based on this, we can decide what checks to implement, what to skip, whether to stop execution using error messages or to use default values with warnings. Checking for ‚Äúhappy paths‚Äù is simpler compared to checking each and every bad input and providing specific error messages. Too many different error messages for the same argument could become a source of frustration of the end user, so consider combining some checks and their error messages to be informative and precise. Robustness, like everything else, in moderation, is good and getting it ‚Äújust right‚Äù takes time and dedicated effort. Happy Coding!"
  },
  {
    "objectID": "posts/writing-robust-functions/index.html#citations-references",
    "href": "posts/writing-robust-functions/index.html#citations-references",
    "title": "Writing Robust R Functions",
    "section": "Citations & References",
    "text": "Citations & References\n\nTechniques for writing robust R programs - LexJansen\nR Programming for Data Science\nA Warning About warning"
  }
]